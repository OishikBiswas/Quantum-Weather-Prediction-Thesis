{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLLBQSi2e2vn",
    "outputId": "f1c71978-e425-4ce8-bb75-ec190df862d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit in /opt/conda/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from qiskit) (0.14.0)\n",
      "Requirement already satisfied: numpy<2,>=1.17 in /opt/conda/lib/python3.10/site-packages (from qiskit) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5 in /opt/conda/lib/python3.10/site-packages (from qiskit) (1.12.0)\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/conda/lib/python3.10/site-packages (from qiskit) (1.11.1)\n",
      "Requirement already satisfied: dill>=0.3 in /opt/conda/lib/python3.10/site-packages (from qiskit) (0.3.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from qiskit) (2.8.2)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from qiskit) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qiskit) (4.9.0)\n",
      "Requirement already satisfied: symengine>=0.11 in /opt/conda/lib/python3.10/site-packages (from qiskit) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from stevedore>=3.0.0->qiskit) (6.0.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.3->qiskit) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwIBVfBNfRq_",
    "outputId": "7312597e-eecf-4398-9751-4e07ec570ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit-machine-learning in /opt/conda/lib/python3.10/site-packages (0.7.1)\n",
      "Requirement already satisfied: qiskit>=0.44 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (1.0.0)\n",
      "Requirement already satisfied: qiskit-algorithms>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (0.3.0)\n",
      "Requirement already satisfied: scipy>=1.4 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (1.23.5)\n",
      "Requirement already satisfied: psutil>=5 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (5.9.4)\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (1.4.1.post1)\n",
      "Requirement already satisfied: fastdtw in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (0.3.4)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (65.5.1)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (0.3.6)\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from qiskit>=0.44->qiskit-machine-learning) (0.14.0)\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/conda/lib/python3.10/site-packages (from qiskit>=0.44->qiskit-machine-learning) (1.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from qiskit>=0.44->qiskit-machine-learning) (2.8.2)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from qiskit>=0.44->qiskit-machine-learning) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qiskit>=0.44->qiskit-machine-learning) (4.9.0)\n",
      "Requirement already satisfied: symengine>=0.11 in /opt/conda/lib/python3.10/site-packages (from qiskit>=0.44->qiskit-machine-learning) (0.11.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2.0->qiskit-machine-learning) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2.0->qiskit-machine-learning) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.0->qiskit>=0.44->qiskit-machine-learning) (1.16.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from stevedore>=3.0.0->qiskit>=0.44->qiskit-machine-learning) (6.0.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.3->qiskit>=0.44->qiskit-machine-learning) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install qiskit-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dItaSY4Teu1F"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from qiskit import *\n",
    "\n",
    "# External imports\n",
    "from pylab import cm\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.visualization import circuit_drawer\n",
    "#from qiskit.algorithms.optimizers import SPSA\n",
    "\n",
    "from qiskit.circuit.library import PauliFeatureMap\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_machine_learning.kernels import TrainableFidelityQuantumKernel\n",
    "from qiskit_machine_learning.kernels.algorithms import QuantumKernelTrainer\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-JVSWhbye8R5",
    "outputId": "224bc1f0-8ff4-4da8-fb90-c1a3695d4045"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Feel likes(C)</th>\n",
       "      <th>Chance of Prec.(%)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Visibity(km)</th>\n",
       "      <th>Pressure(hPa)</th>\n",
       "      <th>State</th>\n",
       "      <th>Real State</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Sunny</th>\n",
       "      <th>Fog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27-06-2023</td>\n",
       "      <td>08:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27-06-2023</td>\n",
       "      <td>09:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>86</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27-06-2023</td>\n",
       "      <td>10:00</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Rain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27-06-2023</td>\n",
       "      <td>11:00</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Isolated Thunderstroms</td>\n",
       "      <td>Rain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27-06-2023</td>\n",
       "      <td>12:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>90</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time  Temperature(C)  Feel likes(C)  Chance of Prec.(%)  \\\n",
       "0  27-06-2023  08:00              27             32                  21   \n",
       "1  27-06-2023  09:00              27             32                  22   \n",
       "2  27-06-2023  10:00              28             34                  23   \n",
       "3  27-06-2023  11:00              28             33                  30   \n",
       "4  27-06-2023  12:00              27             32                  53   \n",
       "\n",
       "   Humidity(%)  Visibity(km)  Pressure(hPa)                    State  \\\n",
       "0           87           3.0           1003                  Cloudy    \n",
       "1           86           9.0           1003                  Cloudy    \n",
       "2           90           3.0           1003                  Cloudy    \n",
       "3           85           9.0           1003  Isolated Thunderstroms    \n",
       "4           90           9.0           1003                     Rain   \n",
       "\n",
       "  Real State  Rain  Cloudy  Sunny  Fog  \n",
       "0     Cloudy   0.0       1      0    0  \n",
       "1     Cloudy   0.0       1      0    0  \n",
       "2       Rain   1.0       1      0    0  \n",
       "3       Rain   1.0       1      0    0  \n",
       "4      Sunny   0.0       0      1    0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Thesis IBM Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "OKXRX6J6frL5",
    "outputId": "0f4ef2d7-9af0-448d-901f-4700c1b493a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Feel likes(C)</th>\n",
       "      <th>Chance of Prec.(%)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Visibity(km)</th>\n",
       "      <th>Pressure(hPa)</th>\n",
       "      <th>State</th>\n",
       "      <th>Real State</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Sunny</th>\n",
       "      <th>Fog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>86</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10:00</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Rain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11:00</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Isolated Thunderstroms</td>\n",
       "      <td>Rain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>90</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>19:00</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1014</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>20:00</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>21:00</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>22:00</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>23:00</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4504 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  Temperature(C)  Feel likes(C)  Chance of Prec.(%)  Humidity(%)  \\\n",
       "0     08:00              27             32                  21           87   \n",
       "1     09:00              27             32                  22           86   \n",
       "2     10:00              28             34                  23           90   \n",
       "3     11:00              28             33                  30           85   \n",
       "4     12:00              27             32                  53           90   \n",
       "...     ...             ...            ...                 ...          ...   \n",
       "4499  19:00              20             20                   1           77   \n",
       "4500  20:00              19             19                   1           80   \n",
       "4501  21:00              19             19                   2           82   \n",
       "4502  22:00              18             18                   2           83   \n",
       "4503  23:00              18             18                   2           84   \n",
       "\n",
       "      Visibity(km)  Pressure(hPa)                    State Real State  Rain  \\\n",
       "0              3.0           1003                  Cloudy      Cloudy   0.0   \n",
       "1              9.0           1003                  Cloudy      Cloudy   0.0   \n",
       "2              3.0           1003                  Cloudy        Rain   1.0   \n",
       "3              9.0           1003  Isolated Thunderstroms        Rain   1.0   \n",
       "4              9.0           1003                     Rain      Sunny   0.0   \n",
       "...            ...            ...                      ...        ...   ...   \n",
       "4499           8.0           1014                    Clear      Clear   0.0   \n",
       "4500          14.0           1015                    Clear      Clear   0.0   \n",
       "4501          14.0           1015                    Clear      Clear   0.0   \n",
       "4502          14.0           1015                    Clear      Clear   0.0   \n",
       "4503          14.0           1015                    Clear      Clear   0.0   \n",
       "\n",
       "      Cloudy  Sunny  Fog  \n",
       "0          1      0    0  \n",
       "1          1      0    0  \n",
       "2          1      0    0  \n",
       "3          1      0    0  \n",
       "4          0      1    0  \n",
       "...      ...    ...  ...  \n",
       "4499       0      1    0  \n",
       "4500       0      1    0  \n",
       "4501       0      1    0  \n",
       "4502       0      1    0  \n",
       "4503       0      1    0  \n",
       "\n",
       "[4504 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Date'], inplace=True)\n",
    "#df.drop(columns=['Temperature(C)'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Feel likes(C)</th>\n",
       "      <th>Chance of Prec.(%)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Visibity(km)</th>\n",
       "      <th>Pressure(hPa)</th>\n",
       "      <th>State</th>\n",
       "      <th>Real State</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Sunny</th>\n",
       "      <th>Fog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>86</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10:00</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Rain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11:00</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Isolated Thunderstroms</td>\n",
       "      <td>Rain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>90</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>19:00</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1014</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>20:00</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>21:00</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>22:00</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>23:00</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4503 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  Temperature(C)  Feel likes(C)  Chance of Prec.(%)  Humidity(%)  \\\n",
       "0     08:00              27             32                  21           87   \n",
       "1     09:00              27             32                  22           86   \n",
       "2     10:00              28             34                  23           90   \n",
       "3     11:00              28             33                  30           85   \n",
       "4     12:00              27             32                  53           90   \n",
       "...     ...             ...            ...                 ...          ...   \n",
       "4499  19:00              20             20                   1           77   \n",
       "4500  20:00              19             19                   1           80   \n",
       "4501  21:00              19             19                   2           82   \n",
       "4502  22:00              18             18                   2           83   \n",
       "4503  23:00              18             18                   2           84   \n",
       "\n",
       "      Visibity(km)  Pressure(hPa)                    State Real State  Rain  \\\n",
       "0              3.0           1003                  Cloudy      Cloudy   0.0   \n",
       "1              9.0           1003                  Cloudy      Cloudy   0.0   \n",
       "2              3.0           1003                  Cloudy        Rain   1.0   \n",
       "3              9.0           1003  Isolated Thunderstroms        Rain   1.0   \n",
       "4              9.0           1003                     Rain      Sunny   0.0   \n",
       "...            ...            ...                      ...        ...   ...   \n",
       "4499           8.0           1014                    Clear      Clear   0.0   \n",
       "4500          14.0           1015                    Clear      Clear   0.0   \n",
       "4501          14.0           1015                    Clear      Clear   0.0   \n",
       "4502          14.0           1015                    Clear      Clear   0.0   \n",
       "4503          14.0           1015                    Clear      Clear   0.0   \n",
       "\n",
       "      Cloudy  Sunny  Fog  \n",
       "0          1      0    0  \n",
       "1          1      0    0  \n",
       "2          1      0    0  \n",
       "3          1      0    0  \n",
       "4          0      1    0  \n",
       "...      ...    ...  ...  \n",
       "4499       0      1    0  \n",
       "4500       0      1    0  \n",
       "4501       0      1    0  \n",
       "4502       0      1    0  \n",
       "4503       0      1    0  \n",
       "\n",
       "[4503 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Feel likes(C)</th>\n",
       "      <th>Chance of Prec.(%)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Visibity(km)</th>\n",
       "      <th>Pressure(hPa)</th>\n",
       "      <th>State</th>\n",
       "      <th>Real State</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Sunny</th>\n",
       "      <th>Fog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>86</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10:00</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Rain</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11:00</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Isolated Thunderstroms</td>\n",
       "      <td>Rain</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12:00</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>90</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>19:00</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1014</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>20:00</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>21:00</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>22:00</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>23:00</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4503 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  Temperature(C)  Feel likes(C)  Chance of Prec.(%)  Humidity(%)  \\\n",
       "0     08:00              27             32                  21           87   \n",
       "1     09:00              27             32                  22           86   \n",
       "2     10:00              28             34                  23           90   \n",
       "3     11:00              28             33                  30           85   \n",
       "4     12:00              27             32                  53           90   \n",
       "...     ...             ...            ...                 ...          ...   \n",
       "4499  19:00              20             20                   1           77   \n",
       "4500  20:00              19             19                   1           80   \n",
       "4501  21:00              19             19                   2           82   \n",
       "4502  22:00              18             18                   2           83   \n",
       "4503  23:00              18             18                   2           84   \n",
       "\n",
       "      Visibity(km)  Pressure(hPa)                    State Real State  Rain  \\\n",
       "0              3.0           1003                  Cloudy      Cloudy     0   \n",
       "1              9.0           1003                  Cloudy      Cloudy     0   \n",
       "2              3.0           1003                  Cloudy        Rain     1   \n",
       "3              9.0           1003  Isolated Thunderstroms        Rain     1   \n",
       "4              9.0           1003                     Rain      Sunny     0   \n",
       "...            ...            ...                      ...        ...   ...   \n",
       "4499           8.0           1014                    Clear      Clear     0   \n",
       "4500          14.0           1015                    Clear      Clear     0   \n",
       "4501          14.0           1015                    Clear      Clear     0   \n",
       "4502          14.0           1015                    Clear      Clear     0   \n",
       "4503          14.0           1015                    Clear      Clear     0   \n",
       "\n",
       "      Cloudy  Sunny  Fog  \n",
       "0          1      0    0  \n",
       "1          1      0    0  \n",
       "2          1      0    0  \n",
       "3          1      0    0  \n",
       "4          0      1    0  \n",
       "...      ...    ...  ...  \n",
       "4499       0      1    0  \n",
       "4500       0      1    0  \n",
       "4501       0      1    0  \n",
       "4502       0      1    0  \n",
       "4503       0      1    0  \n",
       "\n",
       "[4503 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if (col == 'Rain'):\n",
    "       \n",
    "        df[col] = np.where(df[col] == 0.0, 0, 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "T8soGqnIhlSy",
    "outputId": "e79fee2a-3a58-4384-bb9d-d580c1bddc82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Feel likes(C)</th>\n",
       "      <th>Chance of Prec.(%)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Visibity(km)</th>\n",
       "      <th>Pressure(hPa)</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Sunny</th>\n",
       "      <th>Fog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>86</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>90</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4503 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature(C)  Feel likes(C)  Chance of Prec.(%)  Humidity(%)  \\\n",
       "0                 27             32                  21           87   \n",
       "1                 27             32                  22           86   \n",
       "2                 28             34                  23           90   \n",
       "3                 28             33                  30           85   \n",
       "4                 27             32                  53           90   \n",
       "...              ...            ...                 ...          ...   \n",
       "4499              20             20                   1           77   \n",
       "4500              19             19                   1           80   \n",
       "4501              19             19                   2           82   \n",
       "4502              18             18                   2           83   \n",
       "4503              18             18                   2           84   \n",
       "\n",
       "      Visibity(km)  Pressure(hPa)  Rain  Cloudy  Sunny  Fog  \n",
       "0              3.0           1003     0       1      0    0  \n",
       "1              9.0           1003     0       1      0    0  \n",
       "2              3.0           1003     1       1      0    0  \n",
       "3              9.0           1003     1       1      0    0  \n",
       "4              9.0           1003     0       0      1    0  \n",
       "...            ...            ...   ...     ...    ...  ...  \n",
       "4499           8.0           1014     0       0      1    0  \n",
       "4500          14.0           1015     0       0      1    0  \n",
       "4501          14.0           1015     0       0      1    0  \n",
       "4502          14.0           1015     0       0      1    0  \n",
       "4503          14.0           1015     0       0      1    0  \n",
       "\n",
       "[4503 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Time', 'State','Real State'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Feel likes(C)</th>\n",
       "      <th>Chance of Prec.(%)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Visibity(km)</th>\n",
       "      <th>Pressure(hPa)</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Sunny</th>\n",
       "      <th>Fog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>86</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>90</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4503 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature(C)  Feel likes(C)  Chance of Prec.(%)  Humidity(%)  \\\n",
       "0                 27             32                  21           87   \n",
       "1                 27             32                  22           86   \n",
       "2                 28             34                  23           90   \n",
       "3                 28             33                  30           85   \n",
       "4                 27             32                  53           90   \n",
       "...              ...            ...                 ...          ...   \n",
       "4499              20             20                   1           77   \n",
       "4500              19             19                   1           80   \n",
       "4501              19             19                   2           82   \n",
       "4502              18             18                   2           83   \n",
       "4503              18             18                   2           84   \n",
       "\n",
       "      Visibity(km)  Pressure(hPa)  Rain  Cloudy  Sunny  Fog  \n",
       "0              3.0           1003     0       1      0    0  \n",
       "1              9.0           1003     0       1      0    0  \n",
       "2              3.0           1003     1       1      0    0  \n",
       "3              9.0           1003     1       1      0    0  \n",
       "4              9.0           1003     0       0      1    0  \n",
       "...            ...            ...   ...     ...    ...  ...  \n",
       "4499           8.0           1014     0       0      1    0  \n",
       "4500          14.0           1015     0       0      1    0  \n",
       "4501          14.0           1015     0       0      1    0  \n",
       "4502          14.0           1015     0       0      1    0  \n",
       "4503          14.0           1015     0       0      1    0  \n",
       "\n",
       "[4503 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rqKlg1nCh8iD"
   },
   "outputs": [],
   "source": [
    "def create_training_and_testing_data_sub(df_, DATA_SIZE_):\n",
    "    data_size = DATA_SIZE_\n",
    "\n",
    "    indices = np.random.choice(df.index, size=data_size, replace=False)\n",
    "    subset_df = df.loc[indices]\n",
    "\n",
    "    print(indices)\n",
    "\n",
    "    # get the values from the last column of the subset and store them in y_subset\n",
    "    y_subset = subset_df['Fog'].values\n",
    "\n",
    "    # get the values from all other columns of the subset and store them in X_subset\n",
    "    x_subset = subset_df.iloc[:, :-1].values\n",
    "\n",
    "    # spltting the dataset into train and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_subset, y_subset, test_size = 0.2, random_state = 31)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfWXYJs-h-Pv",
    "outputId": "1804803f-1aae-4ec4-ee46-427368d8dfe7"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Number of experiments to run:  100\n",
      "Size of dataset:  200\n",
      "Number of max iterations:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2029 2581 1511 1023 1262  531  430 2519 2915 1115  355  621 4014 4057\n",
      " 1651 3088 2302 4465 3617 4207 3587 3057 1398 3705 2689  881 1164 3904\n",
      "  596 3097  551 3031 3615 1418  408 1147 3154  559  235 2956 3966 2329\n",
      " 3301 1282 4046 3331 2555 3349 2178 4303 4141  302  371 2231 1043 3146\n",
      " 2293 4466 3700 2226 4224 2932 2000 4065 2744 3579 4129  901 1560 2809\n",
      " 3143 1011   21 1030 4266 2520  487 1237  592 3157 2053 4283 3909 1943\n",
      " 2152 4038 3253 2446 1673 1223 4048  591 2093 1338  115 2609  600  520\n",
      " 1674 1502 2305 2935 2913 3470 3604 1915  838  381 2064 3944 3829  353\n",
      " 3514 4176 4329  254  285  833 1244  839 1542 3451 1391 2783  644 4201\n",
      "  210 3373 2931 2527 2628 2906 2901 1371 4412  294 1047 2657 2855 1611\n",
      " 1954  344 4228   75 3812 1756 4123 4178  649 3866 2859 2042 2115   58\n",
      " 3055 4147 1754  377  311 1748 3174 3069  290  945 1631  361 2223 2278\n",
      " 1584  799 4229 1925 4417 3770 2300 3224 3772 3927 3467   33 4326 2969\n",
      "  748 4084 3821  540 2146  647 2649 3528 2273 1131  467  146 4124  972\n",
      "  123 1828 1385 1496]\n",
      "[2775 1782 1920 4154 2252 2913 2477 2389 2283 2234  360 2997 3316 3327\n",
      " 3214  291 3967 2084 4006  176 1182 2052 3378  517  751 3542 3739 3845\n",
      "  658 1247 3236  304 2520 1664 1684  973   32 1976 3699 3901 4290 3249\n",
      " 4326 2251 1915  933  612 3067 1162 1994 3475 2850 4250 3461 3176 4284\n",
      " 1191 2895 3713 3333 2593 1155 3492 1027  984  650 2386 3127   91  182\n",
      "  769 1003 2532 2393 2015 3231 3650 3613 3973  963 3080  731  746 3035\n",
      " 4387  722  197 3134 3095 1958 3968 3371  390 2862 2012 1476 1656 1283\n",
      " 2959 1779 2219  363 2825   95  187 1373 1991 4014 1384  233 3534  224\n",
      " 2156 2509 4242 4473  689 2611  823 4443 1921 4479 4060 3324 2992 3558\n",
      " 3146 1322  450 1279 1974 3270 1739 3292  930   49 1698 2884 1585 2886\n",
      " 2247 3710 4035 2753  601 4163 2597   27 1462 2019  135 2556  605 3535\n",
      " 1786  870 3321 4404  311 4321 1396  737 3605  915 1084 1693 1883 1611\n",
      " 1509   84   36 3526 2979 2827 2739 3563 3387 1045 4192 2966 2039 3905\n",
      " 3956 2623 4069 3435 4110 3132 2915 1748 4420   82  708 3433 2485 3742\n",
      " 1959 2406 3422 1745]\n",
      "[4396  956 3267 3313  587 1755  255  252 3534 2052 2808 3222 1768 1909\n",
      " 1103 3121 2827 1923 1191  155 1267 4112 2726  509 4394 3909 1194 3520\n",
      "  710  901  933 3494  627 2904 3706 2033 2851 3704 1342 3518   60 3772\n",
      " 2134 2950  957 2331 3621 3969 1893   58 2918 4318 2999 3653 1548 1518\n",
      "  443  333   11 2394 4443 3331 1350  976 2500 3965 2416 1640 1164 1697\n",
      " 4167  257 1846 3453 1968 1955 3813 4217 4157 2317  669  173 2874 4021\n",
      " 3558 1849 2387 4458 4256  982 3470 3592  357 2922   82 2578 2588 1965\n",
      " 2667 1541  319 3940  286 2778 3273 1309 3153 2199 1147 4372 3292 1775\n",
      " 1907 3192 3110 1521   61  247 1175 2306  235  330   79 3849  317  141\n",
      " 1579  480  614 2682 1208 3489 1084 1826  421 1104 4473 4155  724 4041\n",
      " 4108   49 3989  138  579 4105 3897 2308 2883 1181 3858 2141 3725 3678\n",
      " 3092 1752 1262  279 1075 4321 3051 2643  929 4268 2921 4123 3697 4018\n",
      " 1964  900 3854 3756 3912 2280 1230  729 2415  250 2388  183 2577  722\n",
      "  113  718  300 3593 1304 3717 2509 3553  843 3565 2755 2564 1951 1570\n",
      " 2116 3001 1722 1864]\n",
      "[2940  193 4251 1003   51   29 3000 1894   95 4232 2304 3441 1344   59\n",
      " 4233 1339 1595  526 3998 1579   28 4268 2193 2998  978  646 3777 3529\n",
      "  364 4029  311  507  740  473 3167 1844 1114 4499  126 2780 2494  253\n",
      " 1304 1424 3726  317 2817 1519 1951 2786 3862  176 2262 4300  709 1245\n",
      " 3243 1134  833 4127 3345  264  987   63 2679 1575 3240 1923 3398 1313\n",
      " 4405  381 3075 3245 4071 1035  587 1693 4145 4289 2980  550 3060  105\n",
      " 1434 2334  458 3845 1136  219 4169  968  423  647 1571  886 3485  341\n",
      " 4182 2085  733  367 1191 3915 3803 2041  238 3547 1050 3246 3820 1659\n",
      "    3 1002  970 4223 1834 3172 2055 3676 1996 1441 1904 2909  942 3742\n",
      "  368 3264  997 1243  602 1727  568  694 2415 1566 2346 3272 2921  525\n",
      " 4379  461 2931 2231 2690 4222 2203 2314  921 2705 4338 3101 1723 1764\n",
      " 2359 4067 1577  736 2299  777 3988 4244  543 2292  819 1603  538  682\n",
      "  633 3754 2032 3300 1755 1870 1157 3738 2488 3751 3766 2953  579  387\n",
      " 2807 1937 1758 4156 3219 1246 3181 1174 3443 2809 2846  254 2003 1112\n",
      " 2407 2521 3715 4074]\n",
      "[2182  774 3988 1185   66 2739 2264 2678 4299  983 1152 3224 1082 3905\n",
      " 2039 1392 1277 1066  239 3936 2481  209 3564 2438  444 1651  974 4305\n",
      " 3363 1093  836  168   30 2159 4467 3939  350 2342  408  127 4375 4480\n",
      "  783  378  338 1721 1583  828 1479  553 3135  474  198 3409 3894 4482\n",
      " 3867 2423 4248  245 3151 2884 1796 4079 2879 4016 4004 1034 3655  616\n",
      " 2390 3785 1456  697 1506 4139 2212 3529 1471 1883 1862 3761 1737 1825\n",
      " 2989 2166 1199 2065 1931 3719  313 1545  354  143 2041 3276 1369  157\n",
      " 2964    4 4339 4347 2508  213 2005 1337 1900 3955 1819  900 1342 3130\n",
      " 1238 1802 2001 2683 1886  511 1075 2134 2609  776 1208 1448  275 4056\n",
      " 3235  701 1873 1138  708 1064   97 2792  228  667 2934 1568 1225 1499\n",
      " 2004 3038  539 3768 4125 1013 1725 1836 3244  154   65 2133 2621 2278\n",
      " 1279  557 1221 1647 4426 2727 1461 3143  517 3203  524  467  458  403\n",
      " 2956 2850 1057 2443  368  741 1586 3000 3431   56 2223  732 3669 2472\n",
      " 2506 4484  794 2257 1874 2260 3600 3196  420 3881 3423  109 1584 2751\n",
      " 3502 2093 3289 1442]\n",
      "[3871 2577 4159  741 3263 3308 4028 3518 1265 1639 2988 3251  242 1566\n",
      "  546  363 1139 3613 2481 1927  947 2927 2532 3475 3570  821 3879 1571\n",
      " 3128 2889 3572   45  759 4241 2246 1112 2384 2420 2892 3776 4310 3134\n",
      "  101 2916  903  763  402 2949 1898 1300  920  152 2906 2673 3127 2245\n",
      "  910 2591 4309  398 3881 1248  207 3200  293  409 3508 3821  349 1439\n",
      "  496 1519 3698  652  638 4254 3933 3436   28 1481 1880   77 1004 3614\n",
      "  926 1343 3618 1256 1722 3095  299 2322 2628 3430  784 1757 4341 1428\n",
      " 1618 1497 2731 3534 3335  771 2297 3638 1281 2395  476 3068 1775 2671\n",
      " 4297 3451  855 4449 1161 4189 4415 1867 4475 1014  614  832 4169 1223\n",
      " 2426  307 4071 1543 3994 3104 2231 3131  528  495  206  789 3494 2801\n",
      " 2163 1216 1621 4091 3296 3342  940 1973 2038  358  202 2403 3951 1472\n",
      " 1025 2599 2851  260 4450  946 3106 4247 1043 1907 3431  286 1047  819\n",
      " 2809 2003 1240 2145 3668  754 3969  894  445 2138 2767 2369 3471  164\n",
      " 2334 1925 2806 3165 3669  898  896 2205  213 4106  246 3604 1091 2773\n",
      " 3090 2644 2862 2813]\n",
      "[ 521  612 3861 3574 2737  475  833 2279 1722 4404 1512 1184 3063 4389\n",
      " 1553 3408 3702 2041 2789  686 1219 1763 2140 2100 2410 1826  241  445\n",
      " 2312 4383 1346 1578 4128 2574  400 3430 1947 1769 4037 4497 2796  735\n",
      " 2242 3631 1803 1298 2326  407 3435  721 1845 2808 3487 1652 1071 3179\n",
      " 2477 2084 2825 2447 2322 3103 2342 1869 3477 3894  567 1334  593  182\n",
      " 1268 4265 4488 2252 3113 1586  508 1817  994  456  301  972 4337  389\n",
      " 2404  342  837 4191 2649 2021 1514 4396 3810 4107 2256 1519   64 1666\n",
      " 1386 2247  863 4148  756 2816 2782 4399 3723 3495 1802 4266 1967 4258\n",
      " 1749  568 3401 3079 3201 2473 3423  880 2081  621 4292 1046 3017 1235\n",
      " 3755 4342 2395  575  358 3988 2353 3420 3325   91  802 2452 4074  757\n",
      " 4485 1355 1113 3330 4133 1430 2705 2630 2265  152  556   21 1693 4425\n",
      " 4338 4244 2351 2766 2098 2860  503  775 3685  601 1621 2246 3142 4103\n",
      " 1382  135 1810 2558 4187 4243 3740 3748 1044 1891 4374  807 3582 1631\n",
      " 2128 4125  350  681 3890 1902 1695 2349  286 3981 3032 3619   31 2851\n",
      " 1848 3860 1414   99]\n",
      "[1271 4198  438 1213 3564 3148 4035 1748 3955 3504 2087 1255 1614 4066\n",
      " 4274 2548 2042 2331  625 2057 3142 4280 2022 1042 4234 2557 3916  652\n",
      " 4150 1701 4011  430 1493 1722  404 1467 1597 1989 2514 2759  381 3544\n",
      " 1548 3799  398 2689 1951 4468 4309 3153 1342  225 1695 2175 3791  317\n",
      " 3678  400  301 3980  703  597 1822 4098  178 1518  277 3567 4204 3128\n",
      " 1089 2640 3584  890  101 3653 4193 4146 2990 1380  316 2860 4061  889\n",
      " 4200 1527 2193  355  974 2823  561 1024 4188  342 2976 3626  151 3370\n",
      "  644 3274 1085 3629   60 3728 3774  605 2478  270 4295 3253 3443 1988\n",
      "  866 3060 4456 2922 2626 1742 3732 3427 4044 1106  458 2563 1688  845\n",
      " 3909 3194 4073 3366 4359  259 4167 2265 1216  672 2883 2569 1523 2676\n",
      "  920 3103 1630  214 3369  849 4256 1397 1828 3663 3003 2993 2849  778\n",
      " 2412 3325 4202 3437  969 2919 1940  814 2114 3699 3166 3534  184 4135\n",
      "  437 2448 1104 3465 1391 4373   96 4104  783 3296 1224 1112  795 3701\n",
      " 1668 3451 2900 3685 1738 3624 2452 3675  911  662 4300 2465   19 2258\n",
      "  160  111  680 2856]\n",
      "[2342 2446 3439 1723  982 2980 2072 1810 2506  548  121 3202 3027 1172\n",
      " 2374 3181 1674 1455  494  692 1052 4245  226  529  160 3662 2796 3693\n",
      " 1542 3180 1093 3386 2849 2734 4381  295  606   87 1626 1794 3649 4166\n",
      " 3723 1442  630 3307  258 3109 1814 4153  211 3492 2986 1487 2582 1483\n",
      " 3661 3750 1849 2573 3769  493 2529 2787 3698 3569 2416  194 1687 4405\n",
      " 2942 1225  777 4086   13  152 3968 1233 4083  144 1044 4078 4463 1361\n",
      " 4030 4347 2302 4075  902 2399 2015  882  635  114 3191 1088 2818 1293\n",
      " 2521 2727 1352 3721  246 4370 4241 2767  453 4321 2611 4045 3250 3913\n",
      " 2719 1708 2523 2939 2288 2345 4130  607 1832 2101 4248 2654  865 1157\n",
      " 2102 3984 1998 2280 3595 1602 3909 1087 3821  284 2850 2869 3837  656\n",
      " 4041  816 3185  270 2535 4466 2022  356 1485 1722  534 3494 1784  466\n",
      "  549 2944  443 1879  396 1367 2062  418  859  253 2397  931 3973 3670\n",
      " 4037 1608 1968 2972 1675 3976 3115 2605  658  487   22  698 2689 2973\n",
      "  536 3042 1339  312 2627 1057 4224 1934 3647  614 1078 1585 3110 2357\n",
      " 1842 4423 1682  751]\n",
      "[4487 1535 3062 4428  328 2777 2658 3422 2813 4037  845 3348 1672 1647\n",
      "  292 1743 4213 3831 2403 1809 1884 1135 2016  407 4316 1328  689 2051\n",
      " 1388  523 2254  954 1347 3574    1 2966 2808 1110 3997  448 2148 4346\n",
      "  722 1172 3493 2962 4051 2112 1297 3827  993 1442 3612 3295  138 4312\n",
      " 1554  275 4125 3152   97 3347 3958 4430   67 4110  579 3877 1458 1797\n",
      " 3415 1723 4049  256 3969 1448 1954 4204 2546 2076 3211 1658  499 2927\n",
      "  370 1034 3500 2040  235  227 1044 2605 3048  765 4326 1869  745 3741\n",
      " 3192 3443 3411 1847  207 1425 2846  791   54  542 1396  480  881 2688\n",
      " 4452 1421 3507 2982  179   77 3980 1090 1444 2647 3730 3697 2870 1976\n",
      " 3616 4205   34 1876 1155  271 1066 1788 4251 2712 1488 3503 3220 1061\n",
      " 3710 3069  119 4075 3368 4185 4349 1628 1576 2150  884 1264 3693 2341\n",
      " 1689 3161 2091 3184 1084 3975 4050 4400 3196 3142 1802 2120  655 2676\n",
      " 3082 2265  396 3555 2311 2111 3914 2632 2604 4036   57 1608 3572  669\n",
      " 2528 2545 1063  708 2354 2989 2550 2866 1859 2995 2952  951  607 1422\n",
      "  871 4113 3091 1623]\n",
      "[3522 1332  218   65 4198 2460 1277  704  509 4059 2966 1374 2193 4353\n",
      " 3721 2486 1937 4101 1824 3907 4337 3095 3679 2363 2542 3756 3850 4126\n",
      " 2692 2108  445  940 1168   36 2530 1063 3167 4099 3234 2454 2197 1375\n",
      " 4430 2239 3307 2418 1354 1078  463  758  122 2082 2871 3122 3696 3194\n",
      " 4228 4127 3879  909 3498 1186 4069 2314 3774 3685 4394 2631 2682 3000\n",
      " 4010 4442 1405 3785 3433 3236 2452 2582 2236 2506  829 2336  742 1860\n",
      "  577  540 3069 3775 2670 3956 4199 3645 1673 4276 2053 3517  874 2833\n",
      " 3561 1688  939 3002 2073 1658 3064 2858 2085 4493  726 3823 2560 2142\n",
      " 1188 1415 2322 2636  127 2627 3012  899  278  825  835 3104  169 4336\n",
      " 4420 3678 2183 2235  322 1343 2926 2159 4103 4144  184 2590 2113  358\n",
      " 2217 2337 1950 3004 3022 3790  348 2710 2822  434 3851  883 1171  956\n",
      " 3530 3151 2154 4437 1900  660 3996 4481 1429  546 2132 2401 1422 3594\n",
      "  572 2056 1700 1220  705 2140  165 1564 2872 3910 2846 2944 3401 3463\n",
      " 3390  674 4400 2479 1336 4036  976 1737 4339 4154 1993 3542  522 1322\n",
      "  740  469 4484 3277]\n",
      "[ 424 3868 1404 2426 1294   78  289 4223  935 3675 3431 2123 3327 1890\n",
      "    3 1340 2451 3287 3039 3960 3804 2963 3395 4148  648  749 2413 3113\n",
      " 4084 2218 3724 1278 2871 4276 1630 4254 4070 1898 4258 2388 1936 4251\n",
      " 1586  219 1303 3756  859  135 1255 2332 3391 3307 1216 2728  334 2571\n",
      " 4472 1573 2856 1144 2628 2952 2244 1320  339 3310  751  268  149 1537\n",
      " 3635  776 2836  469 1994 2742 2962 3562 4449 2009 4431  915 3651 4080\n",
      " 3896  493 3864 3423 2468 2061 3946 3244 2358  324 2163 1352 2680  426\n",
      " 4205 1975 4396 1273 1825 3880   49 1513 3452 3505 3087  970 3172 2951\n",
      " 2060 4328  715 2489  628 3148 4410 3479 3461 2458 3083 2285  115  438\n",
      " 4055 3384 3590 1917 3175   70  972 2970  551 1325 1289 3509 4103 4007\n",
      " 3124 3978 2419    7 1528 3744 1100 1764 4162 3597 1324 3574 1709 3855\n",
      "  896 1836 3249 3830 2821 2758 3093 2857 2311 3128 3219 4256  201 3525\n",
      " 3169 2291 3410 1341 3491  449  231 1985 1244  527 2740 2262 1561 1531\n",
      " 3117  980 1157 4481 1076 3419 2980 3836 3729 3185 3003 1816 2697 3909\n",
      " 3424  981 2033 1889]\n",
      "[1008 2617  491 2078 4347  762 1756 1548 2815  693 2476 2836 1212 1986\n",
      " 1575  726 2657 1057 1361 3488 2185 1654 1078  873 2281 1851 1289 2383\n",
      " 3326 2287 1158  853 3963 4193 4494 4260  785  494  862 1979 1349  558\n",
      " 2944 1337 1131 3829 3306 2760   91  826 3685  219 1162  452  257 3836\n",
      "  284 2445  840 1033  673  263 3452  875 3765 3184 3786 4403 1262 2032\n",
      "  869 3353 1868 2328 3336  740 4217 4268 2616 3070  964 3538 1333  170\n",
      "   66 3678 3899 3542  522  735  933  247 2299 2773 4023 2833  638 4152\n",
      " 1232 1047 4314  320 2648  196 4470 3022   49 4139 4071 3191 2493 3031\n",
      "   61 2184 1437 2394 3912  910  935 1358 3773 1383 3385 3214 1227   38\n",
      " 2450 4385  660 2584  356 2917 2780 1102 3303  950  541 3099 3653  388\n",
      " 3776  149  815 1717 2900 4239  456 3573 2341 1322 1558  696 4364 2419\n",
      " 1940 2519 1066 4399  529 1249  243  746 2433 3661  166 2746 2801 1144\n",
      "   57 2167 2535 4146 3060 3206 1769 2162  164 2396 2105   26 3005  681\n",
      "  327  805 3885 1943 1179 2895 4396 2701  532  895 3936 2562  349 2538\n",
      " 3553 2892 4258 4371]\n",
      "[3846  588  256  859 4009 2392  246  556 3859 2336 1982  148 2812 4434\n",
      " 3154 2259 2633 2871 1869 4285  855 3657 2753 4366  524 1316  432 2655\n",
      " 3989 3218 2141 3753 3060 3345 2616 2722  349 2328   15   89 4392 3552\n",
      " 1846 2025 3145  846 4384  411 1001 2395 2770 1308 3396 3645  483 3866\n",
      " 3055 3337 1967 1731 4449 2152 2497 2555 1762 1192 2761 4151 3252 1285\n",
      " 1418 2793   93 3487 3870  673 2329 2717 1310 2285 2854 2846 2694 2746\n",
      " 1597 1301  415 4356  162 1687  835 2760  136 1181 2232 2298 3826 1085\n",
      "  572 1559 1766  793 3307  265 3061 3691 1196  334 1813 3539 3930  648\n",
      " 2363 3231    1  715 1814 2495 2487 3400 2323 3834   44 2068 1745 3024\n",
      " 4437 2467 2198  632  727 3825 2765 3424  341 2686 3132   11 4339 1164\n",
      " 3230 3250 1126 3698 1243 4049 2175 2157   80 3830  876 2084 1673  547\n",
      " 2511 3084  225 2907 4024 2937 3035 3877  981 2997 1385  171 2178 4324\n",
      " 2503 3181  811 2268 1364 4136 1641  397 3943 2741 4223 2069 1580 3712\n",
      " 2446  698 1135 1679 2830   60 1753  189 2779 1260 3667 2979 2771 2811\n",
      " 2067 1121  218 4076]\n",
      "[4164 1111 1341 3728  134 2377 3733 2512 3818 3363 2811 4189  558 4268\n",
      " 3044 3154 2495 1321  787 2697 4222 1950 3170  120 3600  476 1288 4245\n",
      "  556 2229 1766 2581 2909 4289 1245 1853 1973 3465 2031 4322 1496 1371\n",
      "  933 4159 3190  813 3946 3989 1027 3102 1428 1581 4427 2119 1999 1477\n",
      " 3237 3534 1734  804 2894 3571 1528 2456 3773 2268  385 4350 1003 3665\n",
      "  286 3551 4290 1741  216   83  984 1854 4024 1386  207 1956 4273  746\n",
      " 1161 3034  772 1720 3393 2782 1244 1588 3854   11 1925 3410 4366  596\n",
      " 4498  430 1876 3532  871 1978 3706 2624 2920 1846 4471 2190 3956  234\n",
      " 2212 2646 2193 3799 4456 1264 2521 4173 2258  814 2288 2415 3151 2516\n",
      " 1344 3425 3885 2330 4265 4332  925 4384   76 1119 4317 1432 1816  161\n",
      " 2393 4431 4138 3166  256 4165 3059 2363 1056  712  445 1417 3504   45\n",
      "  485  948 2079 1454 1614 3230 1848 2169 4304  103 4144  854 2387 4500\n",
      " 2277 4146  386 3545 1636  594 3962  162 4276 3598 3928  994 2102 1990\n",
      "  963 1248  203 2579 1230  117 2759 3397 1622  377 3516  682 3784 1811\n",
      " 3374 2723 3690 4137]\n",
      "[ 264 1004 4399 4143  822 3333 1414 2879 2305 1915 2168 4380  955  481\n",
      " 1393 1407 3928 4393 2648  243 1301 3109 2664 2497 3829 3325 2703 2956\n",
      " 3355  485 2969 2350 1606 2930 3671 1352 3807 3500  673  147 1369 3390\n",
      " 1916 3860 1732 3231 4021   65 1521 1456 3526 3170  394   96 2917 2475\n",
      " 1421 1388  932 3601 2763  683  235 2673 2834 4460 4323 3330 2587  314\n",
      " 1482  213 1821 2510 3196   91 1217 1032  657 4118  307 3555 2026 1999\n",
      " 4444 2429 2041 3458 1636 4147 1848 4457 3589 3571  939 2184 3436 3344\n",
      " 2541 4166 2819 1721 2446 4468 2308 3114 1090   99 4239 2884  909 4486\n",
      " 1993 3900 1584 3447   35 3318 2791  417  531 3117 1031 4068 1640 4501\n",
      " 3384 4458 3806 3084  712 2265 1626 4477 3319 3099 1274 1197 1306 3593\n",
      " 2604 2600 3057 1300 3226 3546 1261 4296  446 3814 1479 1096 3822  327\n",
      " 4359 2179  757 3305 3313  134 4426 1790  793 3248 2121 3198 2830 2919\n",
      " 3716 3102 3579  666  180 4201 4122 3503 3334 1800 2415 1418 2660  788\n",
      " 3173  713 3121 2915 4360  195 2959   37  420 3400 2586 3288  603 3777\n",
      "  781 2130 4303 3785]\n",
      "[ 255 1134   48  967  825  942  458 1226 2484 4179  808 2389  289 2588\n",
      " 1783 1564  505 2791 1607 2567  494 2184 1721 3422  965 3227 3188 2325\n",
      " 4210 3932  767 1316 2616  213 3047 1585  831 4047   74 4176 2785 3935\n",
      " 4164 4495 4468 1906  560 2244 3843 3254  639 3221 3383 4310 1697 3082\n",
      " 1024   73 3539 2080  117 1890 2406 3189 1452 4220  612 3893 1802  948\n",
      " 2508  738 1692 1975 2622  718 1040  438 3174  886 4388 1250 4221 3441\n",
      " 1875 1855 3028  120 3971  727 1643 2870 2271 1637 4267 1077 2377 2549\n",
      " 2653 3725 3032 3306 3884 3524 2479 2115 1773 4477 1245 2476 1727  881\n",
      " 4114 4286 1065 4157 1848  419 2336 1000 4156  212 3445  355  351  425\n",
      " 2174 4280  592 3859 1333  870 2764  318    8 2533 3629  254 1575 3917\n",
      " 1776 3457 1391 1317 1625 1680 1183 2808 3557 3442 3470 1046 1153  200\n",
      "  380 3036 2384 1465 3741 4110 2337 2908 2037 3021 1429 2042 2168 2133\n",
      " 3742 2287 4141 3076 2690 2141 3940 1998  929 2765 3473 3792 1402 2068\n",
      "  138 1888 4474 3000  851  499 1094 3918 3335 1924 1763 3817 2367 3547\n",
      " 2685 4214 1799 4153]\n",
      "[3049 3037 1011 3274 2980 2633 4210 3112 2244 3156 3403 4458 1791 4231\n",
      " 3520 4208 1283 2723  359 1898  175 3778 1667 2889 4453 1463 3348 2962\n",
      "   45 1056 1715 2552  738 3101 3813 2311 1873 1136 1882  869   50 4278\n",
      " 3653 3715 4200 3201 1984 3203  270  775 2442  339 3646 2429  857 3562\n",
      " 3490  240 3232 3485 2536 2315 2462 4221 2516 2562 2403 3297 2355 2854\n",
      " 1639 1677 1510 1141  156  369 2865 1666 1019  261 3366 2015 3917 2830\n",
      "  783 1812  677 2992 3087 1319  312 3445 3166 1506 2053 2592 3550  105\n",
      " 2673 4416  197 2291 2006 2235 1691 4466  535  872 4180 2373   96 3434\n",
      " 2279 1938  307 3564 4450  333  520  653 4077  226 4501 1596  245 2968\n",
      "  879   41 3598  230 2726 2990 3468 1130 2127 4439 1827  342 1173   90\n",
      " 4097  454  606 1312 3133 2714 2814  498  981 4007 1290 2685  482 1142\n",
      " 4069 2023 2680 2416 3543 2563  655   83 2218  398 1535 2595 1451 3617\n",
      "  696  458 3517 3160 3199 2531 4062 2847 2103  615  705  348  419 2037\n",
      " 4365 2211  104  291 3052  899 3849  497 1849 3699 4274 1286 4245 1917\n",
      "  305 1566  905  850]\n",
      "[4371  501 4029 2997 2579 3261  484 3779 4328 4453 2933 1642 4121 4102\n",
      " 3607   19 3294 4186 3124  515 1995 4044  549 4467 2893 2183  271 2186\n",
      " 2478 2892  620 1459 1085 4185 2963 3993 2170 4128 1697  150  589 2197\n",
      " 2378  427 1440 1236 4237 1031 1622  948 1192 3611 2523 2618 4438 3514\n",
      " 3245 1250 1233 4222 3576  500 4340 4326 3116  644  564 4486  571 1170\n",
      " 1207 4046  906 4460 1402  455 1094 1332 3598  216 3550 3602  486  540\n",
      "  308 1456  718 2875  428  517 3257 1490 2274 1653 4345 2552 3687 3855\n",
      "   74 2784   10 2805 2344 2852  392  226 1894 2123  139 2434 4437  419\n",
      " 1326  130 2345   35 3248 1678 1783 1777 2942 3389 3920 1492  516 3644\n",
      " 2532 4452  170 2788 3311 1324 2927  633 1986 3484  164  174  949 2706\n",
      " 1782 3913  401 2368 3609  732 4226  266 3255 1715 3689 4260  579 1882\n",
      " 1946 2367 4241  958 4273  347 2277 2938 4346  213 1160 3704 3034  413\n",
      " 2297  138  331 4288 1884  722  423  893 3729 2358 1865 3897 2132  348\n",
      " 1923 2599 1740 2421 3782 2259 1044  229  121 2995  990  940 2483 4228\n",
      " 1859  339 4165 2611]\n",
      "[4330 1556 1350  938 3403 1878 1827 1218 2860 3615 1296 1004 2132  904\n",
      " 2685 1713 2819 3142 1714 3291 1346 3246 4426 2834 3772  393 3710 4050\n",
      " 2788  988 1927  201 3090  123 4313 1112 2305  797  661 3015  753  604\n",
      " 4155 2796 1620 3259 3252 3393 3512 3506 3269  137 1088 1198 2067 3949\n",
      " 2945 3979 2488 3546 3834 2809 1255 1707 2639 2070 1245 3829 4236 1802\n",
      "  415 1972 1308 2816 2937  770 2228 2138 1881 2233 1821 3514 1504 2103\n",
      " 2416 1359  802 2027 3001 1307 1706 2743 4071 4014 3196 3055  956 1968\n",
      " 2972 2446 4184 2059 4281 3039 2430 3570 2898 1908 1779 2140  399 2757\n",
      " 2263  330 4022 4335 1366   21 1570  963  834 3599 1052 2406  374 2765\n",
      " 1280 1262 4273 4004 2095 4357  563 3642  386 1654 2053  679 2405 3507\n",
      " 2711   49 2500 2271 4401 4354 2102 2700 3156 3510 1115 1773 3590 4491\n",
      " 2061 1479 1508   83 4471 2230 1429 3496 2414  811  888 1585 1609 1450\n",
      " 2522 3341 1734 2692 1651 3302 3368 4467 3611 1837 2661 3637 1007 2265\n",
      " 3889 2363 1379 4261 3878 2316  806 2329 1290  765 4311  115   51  306\n",
      " 2612  135 2480 1466]\n",
      "[3779 3483 1215 2567 1680 4411  779 1405 2993 2297 3237 2025 2159  709\n",
      " 1594 2481  930 1546  877 1501 4113 2569 2617 2672 3672  886 1224 4256\n",
      " 3062  928 3355  713 4098 2191 1807 1780 4064 2889 2043 2372 3699 1214\n",
      " 4012 3279 2985 2999 1149 3903 3728 3078 1155 2875 3662 1804 3905  612\n",
      " 1319 1669 3495 3838 2602 3533 3414    8 3341 2068 1430 3277 4255 1869\n",
      " 3209  698 3196 2309 2211 3520 1679 1868 1299   91 3917 1066 2523  696\n",
      " 2377  437 1529 2878  977 2904 2147  302  100 2328 1084 2383 3283 1157\n",
      " 4295 1273  542  577  478 1686 2009 1829  870  897 4236  900 2690 1939\n",
      " 3825  157 2940 4206  148 1570 1929 3501  874  607 1448  260 4086 3697\n",
      " 4043 4006 1346 1197  833 3324 3733 1088  929  219 3206 1377 3117 4001\n",
      " 1534 1189 2804 2249 1457 4441  723 1725  266  518  672 1854 1015 3595\n",
      " 3649  873 2058 3749  876  410  868 3849  279 3652 2256 2781 3259 3197\n",
      " 1064 2413  545   75 1373  240  458  132 1910  644 4134  158 4020 3580\n",
      " 2489 1005  624 2874 4395 2851 2807  560 1688 1818   92  224 1355  418\n",
      " 1356 2608 1904 4356]\n",
      "[3788  366  967 1000  814 2595 2608 1255 3799 2780 3449 3196 2984 4459\n",
      " 3646 3469 3232 2251 3825  330 2051 4121 1714 2474 1187 3260 3412 1456\n",
      "  487 1612 1476   87 1007 2408 2587 3902 1202 2604 1356 2324  750 4376\n",
      " 2709  571 1716 3130  187  603 1145 2141 1686 1793 3103 1166 1904 3716\n",
      " 3320 3068  170  166  848 1221 4217 3201 1349 1880 3956 3020 3030   47\n",
      " 1553 3513 2139 2836  888 1254 1606  706  601 1272 2332  406  984 4077\n",
      " 1384 2005 1479 1309 3360 1330 3099 1639 3419 3945 3659 1881 4341 3506\n",
      " 3875 2351 4326 2303  147 1206 1107  898 2376  508 3892 3079 3235 2148\n",
      " 4297 3032 2169 1675 1507 3494 3186 4274 2600 1679 2949 3333  349 1691\n",
      "  251 3076 1613 1652 2345 3087 1875 1545 2008  914   69 2403 3651 4008\n",
      " 2800  734 2626 1817  764 1814 2310 2774 1289 3431 1898 4491  788 3579\n",
      "  744  658 1680 2985 1633  935 1087   86  104 1631 4502 3024 3382 2959\n",
      " 4320  785 2445 4029  413 2584 1495 2954 3124  760 2225 2566 1906 3929\n",
      " 3527 3762 1752 3416 2583  117  792   81 2743  651 3647 3532 3160  950\n",
      " 3355 4353 3299 4009]\n",
      "[1644 3133 1692 2420 3885 3239 2881   77 3365 3262 2409 1246 2805 4345\n",
      " 3085 3937 1356 2541 4040 2865 2818 4024  689 3924 3717 2030 2748 1029\n",
      "  228 1770 1807 4308 2941 1505 2099 2966 3097  581 4166 2376 1923 1360\n",
      "  108 4272 1128    1 3459 2572 4472 4335 3905  445 2902 1072 1242  393\n",
      " 4324  813 1707 3351 3404 1922 3018 1267 1575 3298 1316  312  909 3441\n",
      "  538 2093  694 1920 2773 2054  313  650 2978 1861 3088 3090 4361  730\n",
      " 2073  484 4299 3661 1421  793 1741 4326 3831 4109   33  690   66 4378\n",
      " 1543 1322  734 3623  737  584 2797 3481 4486 2192  469 4467 3739 3595\n",
      "  442  928 1957 3881 3099 3816 1664  668 3792 1673 1530 1551 4313 1917\n",
      " 3564 4501  554  353 4006 3953 2595  482 1669 3516 1847 4348 1178 1580\n",
      "  667 3132 3780 3067 4372 4113 1678  427 2110 1118 1578 3726  848 1201\n",
      " 3802 3437 3790 3930 3442  336 2667  530  396 1300 2619 3140 2626 1100\n",
      "  337 3120 3820 2984 3027 3081 4312 1339 3566 1991 3183 3490  867 1358\n",
      " 2143   64 3127 2616 2195  798  625 1007 2435 3347 3887 4319 1487 3910\n",
      " 1460 3403 1153 4069]\n",
      "[ 519  110 2111 2998 3432  206 4247 3818  922 2343 1190 1818 2962 1423\n",
      " 4011 2299 3333 2419 1997  642 3041  497 4153 3448 4031  690 1125 1940\n",
      "  646  702 4125 4133 3674 2891 3929 4060 4073 2754 1792 4237 2275  825\n",
      "  242 4017 2559 3504 3637  955   69  655 3743 1970 3160 3253 2960  768\n",
      "  564  713 4088 4065  384 2641 3505 1421 2274 2648   49  105 1238 1587\n",
      " 3722 2306  377 2206 1484 4458  844 2723 1340 3866  431 2093 3923 2235\n",
      "  892 1998 2603 3512 3178 3292 2391 1547 2977 4475 2792 1754  728 3806\n",
      "  352 3212 2814  897 4256 4347 1217   19 2015 2183 3126  264 2858 2042\n",
      " 1462  210 3949 2887 3798  995 2669 4429 3645 2284 4477 4096 1222 3475\n",
      " 2180  927 2885 4150 4241 3617 4282  739 4189 3520  876 2523 1400 1606\n",
      "   84 4346    8 1744 1613  508 4465 1076 3867 1444  512  856 1213 3070\n",
      " 4255  869 2777 3163   89  548 1912 1808 3182 3446 2490 2824 1527 1420\n",
      " 1888 1229 2854  860 1681  868  174 3289 3009 3950   88  291 2386 1286\n",
      " 3565 1021 4307  323 1994 2040  688  720  757  451 3183 1147 1442  609\n",
      " 1158  543  212  722]\n",
      "[ 173 1204  861  430 1236 4306 2605 4378 2445 2726  488  182  404  139\n",
      "  543  733 3811 3929  998 1385  653 2779 3957 1864 3562 3416   64 2889\n",
      " 3216 2345 2148 3792   92 4085 1883   33 3081 3050 2852  907 3817 3478\n",
      " 1237 3925 1438 1752 3708 2161 4099 4082 3087 2337 2281 1627 1478 2978\n",
      " 3734 2461 1874 2571 1115 1512 2455 1414 1934 1909  698   30  662 1869\n",
      " 3184  654 1180 1992 4391  199 4092  316 4496 3277 1875 3782  767 1031\n",
      " 3362 3455 4294 2165  791 1923 2611 3453 3070 1805 1871  116 2027 2569\n",
      " 1613 3524 2699  119  575 1127 1126 1341 1154 3867 1008 2316 2756 1517\n",
      " 3764  897  392  498 3179 4303 1854 2351  735 4186 1677 1286 2521  261\n",
      "  462   67 3347  941 2057  358 1861 3672 2965 3222 3926 3916 3731  751\n",
      "   98  311 4447 3534 3433 1160  319 2787 3583 3537 4195  446  369 2839\n",
      " 2943 3922 2648 1810 1913 1647  661  207  250 2936 2470  878 4365 3270\n",
      " 1703 2901 4041 4275  203 1002 4116 1978 3198 1771 1506 1889 1374 2166\n",
      "   55 4406 4394 2033 1092 2301  634 1081 2469 1886 3134 3286 3845  281\n",
      " 1197 3434  560 4234]\n",
      "[2462  953 2371 2182 1004 2916  186 2547 2863 3968 3457 4014 4028 1279\n",
      " 2216 2192   64 4383 3044 1794 4076 3880  413 4071 4261 3380 3424 3737\n",
      " 1056 4029 3523  988 3791 2317  669 2262 3773 4000 4199 2646 3480  424\n",
      " 2046 3154   49  478 4316 1526 1478 4185 2852 1194 1239 4280   53 1508\n",
      " 4463 3332 4112 4431  718 2217  665 1704 1630 4245  379 2487 1408 4019\n",
      "  219 2924  138  657 2906 3271 2749  316 1375 4300 1013 2615 1696 2263\n",
      " 2156 2900 3156 3761 2566 3334 4425  347 1216 1166 1222 1335 3950  962\n",
      " 1387 1197 1754 4104  852   38 1987 1430 1960 4193  554 1361 1869 3169\n",
      " 1354 2188 2389 1616 1390  660 1804 2791 3476 3736 3402 3206 3041  332\n",
      " 2186 1049 2242 1008 1602 1326 3198 4085 1818 3050 3496 1822 3830   33\n",
      "  606 3443 3913 2588 3049 3238 4005 3006 2396 1569 2294 4153 1469 3233\n",
      " 1903 2529 1306  894 3588  546 4326 1695 1417 2449 1388 4479 2523  827\n",
      " 4211 3018 2808 2387 3744 2247 1407 1542   98  887 1360 4454 4041 4376\n",
      " 2132 1956 3785  500 2742  512 1786 1766 4355 3665  118 2866 1039 2438\n",
      " 3301 4013 3789 3245]\n",
      "[1163 2547 3216  689 2619 1368 3511 2734 2698 4167   38  293  941 3520\n",
      " 2153  179  205  520 3918  418 4046 3947 2851 1367 4062 2717 3636  772\n",
      " 3072 4186 2285 1056 1452 2264 3755 1911  266 4054 4367 2949 2230 2877\n",
      " 3973 1408 1462  120  679 3473  613 4043 4445 2034 3647 3186 2012 3525\n",
      " 3609 1580 2352 1324 1380 3957 2589 1837  751 1310 4219 2745 2428 1348\n",
      "  129  762 1135  252  807 1988 1694 2570  485   63 3606 2195 2612 1567\n",
      " 1591 3544 3499 1192 2675  452  947  580 1831 1186 2326 2297 3050 1254\n",
      "  626 1753 1087 3224 3223 4010  818 3431 1484 1874 2104 2332 4319 3330\n",
      " 3020 1292 3227  130 4161 3103 3374  758 1618 3232 1981  901 3190 1206\n",
      " 1504  285  522 4438 4061 1898 1026 1403 2214 1110 4021 1197 1019  216\n",
      " 2920  682  858 1375 2574 3325 4312 3490 3438 4326 1085 3686 2224 2683\n",
      " 2069 2940 2632 3471 4133 3803 4069 3064 1006 3566  906 3437 3414  675\n",
      " 2650 4033 3737  999  656  755 1931 1637 3614 3844  638 3855 2238 3553\n",
      " 1599 3653 1451 2972 3056 3099 4104 1457  417  348 3780  992  380 2402\n",
      "  816 3185  128 1750]\n",
      "[2122 4350 4112 1253  738 2002  115 2001  905 3962 3822 1039   84 2749\n",
      " 4347 3288 1515  701 3848 1665 3369 1445 3726 3290 2587 1494 2394 4212\n",
      " 2266 1822 1230  439 1250 3395   13 1472 3115 1215 2388   62 2106 2180\n",
      " 3973 3961 1327 3206  604  677 1591  584 3997 1649 3314  592  623 1685\n",
      " 2362  307  886 4005 2839 2361  859 1757 4484  965 3746 2998 3146 1828\n",
      "  213 4230 3882  556 2791  642 2141 4368 2011 1272 4385 2715 2602 3056\n",
      " 3720 1042 2010 4012 1775 4065 1690 3938  425 2558 1637 2603  791 4448\n",
      "  310 3613 2064 2795 3499 2117 1617 2367 1145  823 2255 3052 3256  513\n",
      " 3649 2216 3214  817 1320 1498 4114 2655 3192 1024 1762 4049  383 3864\n",
      " 1487  247 4345 1170 2462 3199 2738 3463 1655  262 1672 4260 1938 1375\n",
      " 3566 4492  807 2016 2875 4176 3643 3635 3653 4055 1283 3079 1551 1586\n",
      " 1310 3228 1025 1477 1243 2478 3580 2607  263  538 2992 1459  440 3803\n",
      "   70 1966 3304 1994 2904 2753 3661 2025  384 1495  471 1467 1851  160\n",
      " 2922 2095 2743 3899 2872 2654 3437  561 2967 2458 1348  118 1639 2634\n",
      "  359   91 1756  876]\n",
      "[3468 1036  300 2945  477 3006 3683 3819 1512 3495 4163 4083  610 3236\n",
      " 2509 3035 2780 2414 2693 1119 4472 3178  498  186 1440 3897  861 1426\n",
      " 3972  729 2762 2567 3538  947  293 1325 4275 2882  463 1369 4080 4075\n",
      " 3082 2543 1354 3112 4168  642 4389 2832 4316 2217 3911 2743 3098 3412\n",
      " 2596 3634 2951 4452 3876 2447 4255  337 2927 2047 3674 2569  546  497\n",
      "   87 3456 1667  791  830 3979 3205 1938 1192  997 3392 1893 3550 3261\n",
      "  178 2455 4323 1599 2649  339 1781 1205 3729 2130 1004 1811 3234 1784\n",
      "  375 1432 2812 3885 3985 2201  384 2749 2323 3317 1626  630 3649 2521\n",
      "  141 3032 3954 1069 2015 1623 1911 2406 1281  888 3478 2515 2353  176\n",
      " 4129  803  200 2480 4442  182 3530 1756 1612  508 2241  161 1425 3142\n",
      " 2536 2625 2042 1102 2661 2512 1675 4358 4049 1383 1227 4050 1602  751\n",
      " 3138 2922 1447  247  872 4048  552  479 2517 2640 2756 1540 2228 3659\n",
      " 2637  274 3997 3074  345  984 3070   88 1215 3162 1830 1197 4062  976\n",
      " 2129 2591 1720  777 1882 2684 1130 2492 3010 3769 3537  132 2183 1239\n",
      " 1047  202 1430 3095]\n",
      "[2596 3546 1896 1521 3437 3485 2607 4215  303 1376  205    2  358 2374\n",
      " 3250 3472 2078 3163 4261 3123 1776  222 2417 3864  555 3429 4399 3822\n",
      " 1249 3019 4373  612  342 2560  605  241 4021 3033 1793 2295 1008 3130\n",
      " 3133 3961 1911 2694 3757 2895 3086  621 3439 2348 3026  292 2352 2361\n",
      " 1037 3001  653  747 3464  617  434  414 4105 2656  312  795  854   82\n",
      " 1831  474  543  910 1487 3018 2610 3265 2338 3278 1788 4406 1585  818\n",
      " 1457  259 1118 1121 3219 2574 1358 2087 2479  306 4044 1024 3125  776\n",
      " 2124  242 4123 2791 3459 1595 3398 4222 1694 2393 1724  489 1812 3406\n",
      " 3544 2646 2426  281 2158 2732  227 3615  689 1062 4098 3015 3256 2320\n",
      " 1383 3725 1900 1947 1108 3630 2488 3500  872 3201 2622   22 3025 3856\n",
      " 1746 1794 1399 3131 1567  145  748 3536 3189 3660 3888  274 1129 3747\n",
      " 3752  943  899 3473  798 1238 3707 4183 1637 3373 2046  784 1075 1500\n",
      " 1940 3886 2236 1295 3327 3067 4043 3552 3622 4461 1343 4333 2340 3668\n",
      "  635  986 3851 1332 3259 4204 3655 1432 1862 3196 3059 1247 2598 1322\n",
      "  574 1877 1014 1838]\n",
      "[3455 2757  705  157 1734 2974 3553 1515 3175 3488 1572 3937 4168 3348\n",
      "  450 4402 2548 3836 1200 2554  994 3147 4339 1372 2922  770 3174 3860\n",
      "  560 1584 1761 1612  993 4425 2454 2201 3251  399  999 2858 2797 2759\n",
      " 1088 2422 1290 3003  258 4211 2227 3647 3720 3709 1029 1812 1041 1943\n",
      " 3505 2707 3609 3121 1643 1907 4230 3706  164  555 4164 1013 1436 1994\n",
      "  933  117 2999 2561 1408 1419 2257 4134 4250 1204 2077 3365 3385 3346\n",
      "  694  583 2667 3752 3882 4301 4169 2124  371 3386 4405  510 4406 4270\n",
      " 4198  874 3143 1723 3316 1710 4092 1295 3530 2906 1004 3056 4217 2544\n",
      " 1373 1869 4362 3091 1946 1616 3696 4032 3039 1133 1395 1123 2828  355\n",
      " 3914  531 2989  238 2239 1880 1499  958  482 3027   15  820 1307 4144\n",
      "  350  155 2009 1128 3992 3883 3012 1061  561 1691 1848 1910  141 3314\n",
      " 4327 1071  572 2950  295 2213 2229 4012 3146 2078 3747 3189 4268 2659\n",
      " 2280 2777  803 3594 1047 4447 3692  798 3536  506 1577  980  867 3283\n",
      " 3751 4027 1471 1099 1120 3885 1803  643 4019  615 4374 1486  668 2691\n",
      " 2006 1148  243 2520]\n",
      "[1461 1941 2080 2158 3929 3353 3279 3793 2292 1181 2342  748 1456 1427\n",
      " 1125 3700  879 1170 4500 4094  797 4430 1320 1048 2221   10 4110   63\n",
      " 4498  869 2227 3349  979  248 1089  275 2447 1113 4481  718 3435 4167\n",
      "  932 2015 1021 3919  730 3125 1998 1628 2438 2943  150 1299  590 1143\n",
      "  351  866 2820  241 3756 1045 1005 2522 4127 2005  931 3003  890 3960\n",
      " 1198 4437 3037 1049 3625  276 4131 3859 1542 2210 4463  127 3473 2619\n",
      " 2996  451 3499 2317 1233 2267 3280  375 4163 4268 1541 1510  772 1639\n",
      " 2424 4286  318  781 4097 4215 2825 1898  671 2717 2723 1019 3924 1037\n",
      " 1554 2566 1207 3855 1632 2361 4071 4392  555  251 1032 2196  567 2929\n",
      " 3893  798 2833 4205  220  735 3503  432 3476  279 2169 4197  238 1168\n",
      " 3059 2822 2504  513 4340 1380 2150 2069 4300 3519 3709 2577 3181 3336\n",
      " 2031 1677 3228 2627 4252 4246 3805 3183 4412 3744 1435 3382 1236   78\n",
      " 2598 1626 1146 4123 2016 3421 3138 3389 2934 1205 4154  819 2412 2364\n",
      " 1876 1232 4178 3482  698  968 3028 2692 1943  307  933 2089 3136   25\n",
      " 2224 2973  830  395]\n",
      "[ 515  738 2513  697 3580 1024 2640 3487 2545 1060 2795  197 1535 1541\n",
      " 1400  840   52 4339 3053 2793 1827 1935  346  267 1784 2833 3491 3631\n",
      " 3188 3377 2087  420 2056 4015 3704  806  647 4081 3553  118 2432 3944\n",
      " 3408 3391  488 2048 3728 2677 1854 4487 4462 1480 3307 3899 1942  615\n",
      " 3688  571 4254 3470  449 3325 1809 2928  881  306 3568 4090 4493 1411\n",
      "  171  369  236 2003 4062 3531  802  525   61 2633 4407 1309 4204 3772\n",
      " 2684 4502 3149 4051 1735  559   30 4077  686 2454  703 3412 4130  871\n",
      " 4171 1906 3218  554 3217 1025  483 1099 1559  110 4119 2981 4501  537\n",
      " 3646  113 4472 1450 3492 3600 3415 2715 4329 1423  245 2528 3340 1977\n",
      " 2150  723  397 4305 2021 1192 4152 1429 4484 3980 1711 2850  524  699\n",
      " 2219 4311 2288 2579  374 4393 3625 2646 2419 1936 2532 3722 1444 3330\n",
      " 2909  434  678   16 4068  295 4497 3690 4169  954 4085 4286  339  705\n",
      " 1374  103 3090 4147 2304 4203 4300 2580 2294 3698 3371 4349    2 2190\n",
      " 3450 4193 3403 3508 1086 2953  876 1011  781  657 2914 3429   60 1375\n",
      " 3078   62  304 3765]\n",
      "[1072  191  636 3580 3421 2930 3427 4245 1203  429 3306 3862 1845  245\n",
      " 2962 2834  300 3621 3607  181 3132  971 2024 1251 1277  555   65 2362\n",
      "  398 3393 2513 2521 4077 2856 2021 3145 1348 4185 1968 2908  169 2448\n",
      " 3148 1294 3720 2923 3058 2450 4191 4069 2181 1596 3185 1052 4454 1270\n",
      " 3269  729 1838   68 1684  163  886 1118 1017 3523  985 3074 1060 3843\n",
      " 1633  811 3252 3638 2363 2772  541 1933 1133  901 3193 3706 1180  141\n",
      " 4479 3789  319 4206 2690  239 1471  716 1871  854 3203 2727   29  526\n",
      " 3669 1990  679 2601  558 3108 3992 2878 1190 3426 3583 2049   81 4259\n",
      " 1777 3138  146 2588 3758 4004 2631 2990  823   70 3936 2189 2672  736\n",
      " 2354 2552 1573 1213 3571  512 3958 4255 4119  782 1418 1157 1894 4395\n",
      " 4306  859 2611 4222 3566 1498 4284  654 1687 4342  609 2659 2789 3459\n",
      "  549 1295 3762 1430 2522 2839 3361  487 4352   90 2038 4196 2413 1752\n",
      " 1626 2389 2871 4137 2848 1555 1832 3846 2350 2117 1592 3991 2071 2154\n",
      " 1980 2886 2745 2974 3096 3559 1068 1254 3882 4463 1505  755 1740 1858\n",
      " 1851  451 4445 4483]\n",
      "[3518 1723 1749  366 2175 1088 1121 3871  885 4013 3863 1146 1152 1931\n",
      "  192 2638 1449 3950 3592 2200 2479 2165  951 1275 1170  681 1246   90\n",
      "  149 1153  521 2301  832 1854 3130  868   47  515 1356 4214 1094  462\n",
      " 1442 2038   25 1836 3858 1037 3351 2664 1055 3260 1888 1364 3404 2678\n",
      " 2040  641 3638 2073  645 4352 2006 2580 1443 3934 1821 1832 2688 3998\n",
      " 3945 1500 1110 1934  117 3529 4060 3265 2077 4187  664 2457 4155  898\n",
      " 1895  923 1462 1683 2139 1920 1001 4024 1243 1264  266 1688  731 3378\n",
      "  551 4310 3941  847 1572  627 1139 3826 3833  227 2370 3462 2472 2789\n",
      " 2202 3948 3127  979 3591 3576 2859 1248 2208 1970 3958 2269   33 1476\n",
      " 1026 2312 2696 1165 1998 4171  618  205 3963 2525  291 2363  397 3219\n",
      " 4225  746 3895 3048 3034  125  506 4256 3022 4344 4057 2620 1814 1039\n",
      " 4262 1456 2611  508 3128 1803 2486  389 4056  650 1295 1092 1939 2195\n",
      " 3653  328 4356 1904 3461 3428 3335 1977 1100 2318   81 3976 2981 4068\n",
      "    3 4434 2654 4125 2075 3802 1501 1023 1824 1123 1235 2465  582 3911\n",
      "  399 2885 3330 4362]\n",
      "[2335 2379 2762  887 1947 1725 4190 4262  822 1364 2743 1033  770 3927\n",
      " 2264  656 1195 3073 4446 3691 2322  106 3688  586 2758 4256 1496  795\n",
      " 2768 4086  393 4454 4424 3641 3022 3753 2739 1902 3906 1656 3452 1086\n",
      "  826 1002  197 3894 3639 1906  388 3161 3907 2339 2626 4223 2124  110\n",
      " 4098 2297  107  568 2714 4471 2374 2332  767 2248 3493  330 2800 3686\n",
      " 2852   31 1320 4405  339  651 1202  771 2034 2527 4080 4025  433 2041\n",
      " 1509 1369 3540 3861 1534 1380 3529 2578 2144  709 3295 3329 1004 4078\n",
      " 4121 4124  931 3429 1564 3029  223 1034  574  527 2128 3908 2251  604\n",
      " 2233 2747 2719 1374 2228  508 2765 3372 2278 2528 3325 2901 2729 3887\n",
      " 4029 2007 2845 3911 1527 2485 3070  253 3657 1791 2893 1412 2910 3550\n",
      " 2092 4154 2862 1362 4246 3060  371  904  317 2214 1590 3710 1903 1794\n",
      " 4414  907 2475 4401 1076  617 1316  975 4163 2559 4070 3005 3358 1354\n",
      " 1219 3465 2805   63 1557  576 4432 3273 2807  833 4176 3311  729 3770\n",
      " 3767 3829 1425  138 3619 1233 1882 3890 2645 2879  547  453 2947 1840\n",
      " 2452 4094 1455 2091]\n",
      "[2360 3214  561 4061 3878 2766 3843 4389  243 3884 3517 1331 3103 4382\n",
      " 3035  186 2078 3392 1069 1785 2641 4272 1693 1635  174 3393 1678 1777\n",
      " 2979 3612 1803  145  522 3730 4313 1734 1492 4253 3212   18  667 4108\n",
      "  456 1663 2938 4373  162 2033 1975 4119 1717 3235 2037 4416 1001 1521\n",
      " 1259 1988 1730 3419 2152 4467 3606 2838   32 4408 3990 2702  974  299\n",
      "  708 1708 2629 3790 2330 4247 3158  172 4291 2473  121  686 3995 1794\n",
      " 1408 3719 2155 2328 1330 1539 3333 3328  644 1272 1267  394   54 1230\n",
      " 3117 1167 2491 2687 1240  948  584  475 1316 4277 1350 3464 2818 2158\n",
      " 2862 1802  864 3861  328  731 3381 1601 2391 2105 1345 2217 4083 1411\n",
      " 3506  444 3970  657  302 2163 2222 3443 4452  364  515 1899 4381 1911\n",
      " 4375   73 2959 2744 2227 3671  371 3812 4081 3999  262 3087 1515 2662\n",
      " 4070 3667 3051 3361 4490   23  678 4432 1235 1649  128    4 2108 1576\n",
      " 1076 2948 2691 1206 2969  540 1377 3839 2703 1563 3899 1063 2842  231\n",
      "  721 1579 2657 2257 2502  874 1950 2888   16  257 2345 1325 2638  692\n",
      " 2677  938  756  545]\n",
      "[2114 1251 2366 4370  833 4051 2549 3795  271 2003 2933  858 2910 3223\n",
      " 1119 2956 3921 4164 1246 3956 4031 3486 3603 1388 2833 2173 1307 1269\n",
      " 2921 2779 1570  773 1411 2176 1139 4362  500   48 2952 2439  236  126\n",
      " 3615 2510  991 3331 1916 1343 1072 3664  123 2279 4257 1110 2401  662\n",
      " 2601 1342 2882 3242 2617 1856 3285 4006    2  743 2691 2688 3862 2022\n",
      "  367 3358  243 4479  687 2306  231 4002 4411 2821 1209 3395 3164 1250\n",
      " 3057 2433 2770 3943  326 4132 3872 2992 1449 3613 3844  290  523  497\n",
      " 1378 1509 1609 2911 3371 1118 1241 1312 3568 1959 2249 1496  301  520\n",
      " 2076  977 1625 2113 3239 1707 2331 4087  154 3097 4459 3405 1248 3399\n",
      " 3258 2562 1608 4360 1306 4005  511 2175 3224 2311 1213 2763 1221  667\n",
      " 3012 3276 1166 1007 1375 3495 2309 2034  418  477 4239  381  262  808\n",
      " 4369  540  576 1673  793 3995  863 1797 3769 2043  771 2418   92 2330\n",
      " 3410 4299 1696 4420 2290 2443 3230 1507 3623  633 2415 2946 2272 1524\n",
      " 2635 3955 2602 2939 1045  190 1480   35 1672 2420  359 2082 1069 3445\n",
      " 3062  788 1155 2746]\n",
      "[2029 1132 2447 3795 3101 1788 1527 3146  117  845 3716 2380  590 3942\n",
      " 3697 3886 3872 1703 2483  445  188 4148 4202 4473 1549 1702 3856 3887\n",
      " 1970  283 3072 3548 2908 1728 3127  957 4003 3453 2471 2413 1036 2791\n",
      " 1695 4225 2728  316 1880  712 3755 2270 2358  862 2962 2951  119 3923\n",
      " 3125  161 2993 3612 3013    7 1737 4429 1397 2783 3896 2882 2870 1060\n",
      " 1688 1484 2702  760  460 1586 1742 2650 3613 1029 2759  128 1787  475\n",
      " 1675 2581 2098 4218 1180 2569 3569  487 1378 3031 1251 1346 3643 2125\n",
      "  769  813 3497 3696 3395 3030 1798  198 1464 3094  944 4086 2741 1638\n",
      " 4336 2926 2454 1140 3350 3984  965 2544 3504 2767 1701 1126 4378 2916\n",
      "  986 2209  773 2049  829 2127 1982 1402  913 1801 2226 2692 1016  377\n",
      "  732 2526 2920 2493 4345 3782 1354 1963 3188 1692 3288 3705  547   65\n",
      "  292 4401 3951 3484  662 4275 1816 3490 1892 3659  772 3677 3641 3701\n",
      " 1028 4158 3992 1907  700 3174 1353 1204 2291 3499 4027 4060   30 4440\n",
      " 1030 1582 4265 2516 4383 1276 1881  136  368 3232 2213 3976 3460 4079\n",
      "  271  586 4048 1859]\n",
      "[3297 3370 3274 1970  989  612 2734 2770 1347 1899 1394 1506 4210 1507\n",
      " 4334 3501  560 3679 4046 2524 2259 3869 1461 1786 1157 1107 2284 1254\n",
      " 1445 4263 1330 3776  324 2222 2536 1325  710 4213 3394  813  721 3497\n",
      " 1991 1733 4370 2921 1711 4305 1349 3438  684 2215 4464 3976 3308  464\n",
      " 2703  636 3621  802  654 2893  787 4063 3199 2798 1460 1047 4220 2678\n",
      "  812 1133 3059  730 4201 1448 3626 3462 4175 3269 2354 3179 3212 3521\n",
      " 1477 2496 4461 4193 2834 1771 1657 1557 3428 4172 4215 2196 3838 1282\n",
      " 4357 2776 4053 1185 3159 3323 2053  414  753 2687 2288 3321 3913 3567\n",
      " 2355 1455 4481 1848  733 1286 1576 2132 2393 2889 3289 2800 2904 4350\n",
      "  577 2572 3800 2762 2097 1150 3502 1049  624 3970 3544 1560 3537 3916\n",
      " 1247 4150  338  973 3355 3745 2388 3200 2337  421 4023 4005  898 3251\n",
      " 3465 1727  428 1803 3891 4050 3178 1987  637 1955 1746 2482 1693  853\n",
      "  364 2553 1306 3188 2458 1799 4231 3939  510 2769  232 1318 3027 2282\n",
      " 2726  420 4179  192 2278  726 3423 4103 3810 3718 3816 1640  586 1003\n",
      " 2737 3451   21  432]\n",
      "[1211 2455  764 2551 2755  760  233 2291  331 4036  285 2082  787 2998\n",
      " 1073 3844 3824  469  161  268 3317 1049 2253 3503 1787 4021 2862  255\n",
      " 2224 1000  852 2514 3018  114 2279 3537  279 1357  652 1285 4340 1279\n",
      " 3686 2854 3097 3220   97  860 2512 2611 4281 3323 2292  620 2697 1333\n",
      " 3096 3581  419  799  738 3002 3051 1327 3972 3101 2844  624 4031 4484\n",
      " 4140 4369 1988  221 1790 2196 1175 3815 4259 3520 1798 3472 3542 3960\n",
      " 2127 2128 3294 3912 2674 3845 3212 3086 2319 4185  985 3089 1420  277\n",
      " 1674 2960 2126 1809 1138 1827 3496   49  752  260 3653    2 4466 2579\n",
      " 2600 3897 1318 3410  887 1859  682  706 4485 2778 3666 2878   85  397\n",
      " 1587 1364 2890 3054 1533 1453 3627 3916 4230 4192 1253 4361  855 3527\n",
      "  402 2434 3643 3868 2466  956  736 2043  637 3064 2650 1847  810 3078\n",
      " 3467 3113 2820  830 1644 3266  447 4016 2048 4212 1076 3110  578 4458\n",
      " 2025  654 1494 1526 1808 2192 2234 1394  535  495 3302 1806 1518 1131\n",
      " 3037 1003 1389  339 4339 2311  474 1476 2894 3055 3224 2738 4119 1248\n",
      " 2110 1026 2429  653]\n",
      "[3978  507 4082 1751 1795 1286  817  517  228 2672 3546 2867  375 3982\n",
      "  399 2098  624  197 2128 1299 1443 3426 1275  976 4006 1919 2945 1568\n",
      " 2203 2100 3073  593 1807 4028 3356 3585 1360 4209 2890 1603 1635 4116\n",
      " 3292  449 2558 2857 3593 3126  769  487 3222 3333 1818  832 4229 2607\n",
      " 3152 1721 3121  592 1228 2101 2716 1155 3896 2034 1631 2967 2320 1187\n",
      "  701 3393 1510 1041 1886 3162 2198  496 4389 2688 4468 3481 4442 2133\n",
      " 1995 3874 1193 1580 3151 3526  112 2847 2359 2791 2724 3911 2762 4408\n",
      "  994  714  859 1503 4049 1136 1095  666 3577 3742  378 1055  366 3167\n",
      "  561 3879  606 3785 1643 2388  118 2540   17  448 2502 3421 1770 1716\n",
      " 1068 1011 2694  589 2577 2859 3238 2990   22 1341 2588  993 3572 1066\n",
      " 4030 4233 4454 3852 2476 4232 3824 2448 4347  670 2441 1247  554 4402\n",
      " 1086  656 2491 1110 2405  835  525  830  601 3438 2788 3091 4077 1255\n",
      " 1124 2136 3251 4179 4369 2845 3410 3996 3956 1116 1804  538 3719 1857\n",
      " 3229 2210 2773  612 1992 2823  985 1621  304 2169 4327 2114  691 2173\n",
      "  655 1834 1025 3337]\n",
      "[3886 2931 2730 3214 4228 4165 3217 2722 3125 4263 1584 2102 4147 1650\n",
      " 1182 1157  655 3611  462 1055  470  287  491 1328 3034 1177 1588 1700\n",
      " 1634 2394  267 2747   92 1770 1322 4319 3881 2599 3325  244 2272 3248\n",
      "  583 2952 1981 4251 3272   17 4287 3684 4478 2079 2667 1806 2784  944\n",
      " 3609 3347  575 1914 2231  568 4369  331 3240  624 1829  922 4463 2641\n",
      " 3013  144 2304 2713 1041 3173  423 1214 4274 1211 3163 2168 1115 1279\n",
      "   60 3909 1935  882 3963 2906 3158 3984  614 3900  864   18 1491  765\n",
      " 4400 2681   48  815 1825   96 3222  760 4485  780 1596  440 3317 1980\n",
      "  187 1435 1020 2587  989 2038 2416 4154 2470  554  258 3270 3908 2500\n",
      " 2873 1580  826 3126 4199 1632  830 4217 3110 1723 3949 3445 1365 3725\n",
      " 2151 1726 3709 3921 2321 1893 4333 4344 3162  581 1748 2920 2803 3582\n",
      " 2983 1515  895 3534 3526 2244 1071 1562 1042  367 1467  615 2369 2885\n",
      " 1164 4297 3409 1283 2955 4430  365  733 4395 3273 2670 4476 2957  222\n",
      " 3870 2939 2799 3178  691 2149  914  135 2509   22 3060 3044 2431 2909\n",
      "  804 2699 4436 1899]\n",
      "[2717  598 1030 3192 4290 1103  166 2855 3588 2707 2619 1021 2788 1714\n",
      " 1776  866 2883 3867 4109 3657 2557 2176 1452  561 2916  403  965 2167\n",
      " 3935  344 2183 4238  266 2321 1362 2777 4067  378 4289  852 4275 4318\n",
      "  300 2430  384 2313 4057  119 1223  646 3586 1317 2723 3022 1832 2212\n",
      "  855  176 1737 2930 3155 3819 1575 4336  576 1898 1785  131 2158 1988\n",
      " 2360  539 3217 1034 3318 3372  280 3578  491 4181 2105 2418 3252 4073\n",
      " 3038 1052 3697 3848  272  605 4279  125 3479 4026  829 3710 1631 4440\n",
      " 1308 2826 3793  717 3885 2913 4363 2205 2718 3122 2947 2104  873 1739\n",
      " 2453 3319 2490  638  935 1821  362 1653  917  309  216 2464 2280  694\n",
      " 2586 3399 1097 3861  165  930 2802 4499  796 2096 1784  723 3533 1310\n",
      "  749 3481 2893 1847 4201 3353 4177 2077 4097 2214 2605  168 2748 3064\n",
      " 2424 1314 2753 4422 1485 1970 1720 3838 2402  433 3154 3502 1885 1404\n",
      " 2642 1252 1639  509 4438  466  239 1001 3344 3243  895 2941 2302  417\n",
      " 3074 1431 3933 3262 1775 3684  597 4259 1381  477 2355 2460 2687 1421\n",
      " 1710 2266 2194  588]\n",
      "[1845 1427 3606 2642  289  891  390 1183 1986 3474 2610 3645 3520 1693\n",
      " 3739 1164 2819 1597 2580  681 2471 2014 2853  797 4285 3365 2150  583\n",
      " 4443 4089 4120 1071 3194 1557 3997 1123 2354 4165 2036 1452 3651  802\n",
      "  119  737  961 2701  862 2831 3551 2880 3805 2347 2885  163  866 4418\n",
      " 3918  375 4064  766  907 1935 4234 2525 1542 3720 2957 1369 1219 2250\n",
      "  320  790 2240 1724 2440 2465  133  233 3524  982 3385 1137 2306 3582\n",
      " 2852 2477 2734  947 4009 3963 2294 3072  591 3236  106 3044 2744 1989\n",
      " 2035  675 1834 2157 2284 3617 3103 3523 3767 3860  290  749 3039 1925\n",
      "   66 1397  896 2763 3237   77 3173 3200  775 1264 3821 2382 3832 2903\n",
      " 4384 1757 3210 2258 2251 3257 4353 3978 1686 3608 1893  574 3150 1958\n",
      " 4175 1269  531  784 1952 4044 2351 4484 1870 3649 4235 3171 3787 3230\n",
      "  822 1978 4043 2068 4057 1905 3530 2460 3847 3279 3362 1689 4432  876\n",
      " 3879 3293 4220 2095 3968  130 2554 2650 3012 2991 2817 1527 3825 1876\n",
      " 2310 2675 1835  803 3868 1604 3005 4077 1016 4401 2762 1669 1790 2916\n",
      "  502 1696 4294  868]\n",
      "[ 567 3960 1989  786  239 1010 1322   63 3438  706 4098  382  967 2760\n",
      " 2675 1120 2110  287 2822 1000  776 1621 2379 2016 3732 1490 1121 2705\n",
      " 1313 1952 3230 2155 1879 2806 2125  885 2336 1070 2839 1808  416 2926\n",
      " 3547 1542 4134 3367 3322 2214 3109 4424  334 1669 3010 2382  421   53\n",
      " 3118  188  758 1082 3999 3520 2149 2376 2875 2473 2132 4166 2322 1495\n",
      " 1685 3583 2311 4371 3769 1898  283  404 2917 3185 1071 3214 1113  693\n",
      " 4410 1270 3698 1986 2704 4204 1665 2550  491 1218 4471 3330 2073 3546\n",
      "  441 4151 1060   85  762 2896 1533  913 3042 4087 3166 4474 3950 2220\n",
      " 2927 3254  452 1040 4367 1522 1442 3421 1790 1959  171 2751  158 4100\n",
      " 1311 1353 2597 2802  858 1429 3662 1607 3022 4077 3097  317  316 3454\n",
      "  564 1713 2277 3015 3264  702  596 4214 1029 1117 3899 4324 4329 3366\n",
      " 3398 3701 3267 1558 2516 3478 1234  259 4113 2851 2892 1328  952 4473\n",
      " 1831 3605 1622 4351 1915 4401 4092 2235  417 4464 3027 3334 3936 1458\n",
      " 2293 3817 4058 1148  325 3152 1229 1753 3781 2731 4380 1385 3775 1413\n",
      " 3285 1481 2178 3765]\n",
      "[1222 3539  670 1693 3482 1835 2003 2263  190  177 2185 1403 3078 1982\n",
      "  990 1617  306 1945 4343 4001 4145 3257 4136 1289 3630 1506 1684 4424\n",
      " 3599 1439 3654 2901 3974 1963  578 4297 2817 1953 1036 1657 4271  803\n",
      " 2650 2133 4469 2816 3881 1159  227 2796 1369  148  613 2228 1999 3695\n",
      " 3878 2684 2342 3918 3965  717 4322 1526  243 4302 2271  442 3451   97\n",
      " 3328 2896 3023  437 1646 2131  774 1248   69 1796 4273  864 3721 4008\n",
      " 3095 1153 4458  812 4073 4400  731 4399 1765 3439  512 3191 4209 3687\n",
      " 1344  162  254 1173 3040 2186  925  370 3416 4440 1387 3481 3093  136\n",
      " 1734 1305 2890 1147 4114  396 2767 2494   17  539 4128 3324 1637 3689\n",
      " 2612  978 2429  813 2361 4020 1104 3938 3426 2513 3025 1267 3117 1119\n",
      " 2059 2602 3244 1816 3122 4310 3105 2074 1145 1580 3726  652 1149 2706\n",
      " 3552  756 4385 1651 2568 2740 1114  543  665 1158 3175 3853  927 3959\n",
      "  620 3712 4089  945 4326 3968 1570 3871 2849 3950  637  323 3731 3632\n",
      "  143 4056 2990 1903  924  934 1355   35 4016  847 4401 2889 2574 1997\n",
      "  836 2911 2863  414]\n",
      "[2267  975 1344 3668 3963 1359 3869 3755 1579 4263 3323 2972 2674   37\n",
      "  978  249 3580 2367 1592 3585 3029 3919  952 1433 4189 3849 3824 1872\n",
      "  305 2485  192 2039  229 1780 3894 2382  632 2066 1912  330 2709 2156\n",
      "  387 4289  919  275 1461 1065  271 1925 2200 1278 3181 3341 1402 1740\n",
      " 1146 3736 2374 3248 1100 3886  585 3109  535  550  346 1283  723 3800\n",
      " 2768 4373 3562 4362 2948 3246 1768 3310  318 1578 1905  724 1164  513\n",
      " 4218 3773  339 2765 2512 3053  444 2867 4031 3041 2659 2944 1961 2599\n",
      " 1155 3990 3413 1285 1524 4158 2203  814 3425 1795 3997  941 2247  160\n",
      "  942 1986  958 3051 1743 1217  484 2846 2345  374 2325 3581  557 2368\n",
      " 3636 2238 2278 3734 4367 1736 2549 3291 2818 2843 3737 1136 3706 1361\n",
      " 1894 2915  716 1983 1530 3030  299 3620  553  286 2968  289 1340 1414\n",
      "  769  538 2410 4279  196 4231 3848 3953 3078 1801 3402 3685 4277  940\n",
      " 1937 3154 1953 2033  155 2586 3123 3112  912 4151 3117 4473 3230  204\n",
      " 3814 2904 1566 1472 3485 1663 2479 2508 1431  515 1064 1788 4500 1744\n",
      " 2668 3902 1934 2395]\n",
      "[4440 2884  221 2978 1992  828 4385 3512 4056 3532 1311 3600 2052 4262\n",
      " 4083  215 2904  251  691 4103  330  380 3845 3451 1107 1567 1888 4382\n",
      " 2996 1134 1639 2011  469  323 2423  834 3446 3670 4480 2241 2451 2488\n",
      " 1464 3255  398  751 1559 3636 1396 1403 1726 3521  822 3401 1368 3230\n",
      " 1678 3181 1167  103  872 4221 1628 2484 1024 3078 1066 4184 2456 3203\n",
      " 3287 1540 3916 2381 4349 4133 4142 1619 1007  968 1002  549 2937 1046\n",
      " 3948  801  632  876 1379 3420 4045 1466    9 2303 3915 3393 1519 1961\n",
      " 3582 3624 1042 1748 4155 1526 1982 2717 2111 4052  534   80 2127 3555\n",
      " 4156 2498 2461 3631 3070 3680  717  680  944 1822 2283  291 2477  477\n",
      "  216 4189 2732  720 2464 3293   59 3467 4162 2803 3470  974 3957  979\n",
      "  653 3857 3657 1980 2078 4452 3806  418 3156 4235  439 2354 4186 2497\n",
      " 1228 2216 1137 1153  916 4170 3175 3921 3587 2094 1178 2696 2027 1861\n",
      "   82 1468 2505 1513  343 1436 2508  954 2221  638 3239  761  667 1515\n",
      " 4031 4443 1113 2751 4102  728 3919 1299 1904 2656   20    3 3510 1081\n",
      " 2931 1607 1076 1588]\n",
      "[1070 1500 2937 1084 1454 1447 1901  622 4334 1255 3761 3537 4302 4054\n",
      " 1469 4492 1388 1563 4186 1589 4005 3962 2816 1504 1707 3038 4145  223\n",
      " 2223 4122  892 3852 3701 3522 2875 1418  678 2133 3130 2166  226 1778\n",
      " 1352 2926 2675  971 2909 3849 2733   97 3132 3796 1676  234 1162 2652\n",
      " 3690 3265 2604 3058 4489 1765   83 2212  166 3470  528 1095 2658  655\n",
      " 1148   64 3675 1165  547 3464 1714 2811 3063 4139 4479 2833 4410  330\n",
      " 1094   36  375 2870  785 2805 2761  854 1129 1093 2862 1149 3584 3686\n",
      " 3736 2906 2260 1826 3658 4389 2908  174 3229 4027 1171  149 4162 2069\n",
      " 3902 1039 1376 1404 1960   20 4020 1809 1138 2042 4282 3096  553 3942\n",
      "  635  379 3714  694 3920 2165 1103 2201 1123 1024 4015   47 1982 1800\n",
      " 1584 4444  211 4193 4175 3159 1027 3353  628 3549   10 3969 2964 2476\n",
      " 3337 2139  486 3461 1106 3280  456 2873  150  636 2106 4098 3389  645\n",
      " 2487 4257 1192  481 3392 2856 3534 2888 2072 3655 3362  433  221 4304\n",
      " 2523 3186 4097  196 2999 3068 3400 2547 1244 3258 3312 2536 2169  899\n",
      " 3519 3930 1573 3107]\n",
      "[2048 3407 4206 3678  572 2281  597 3825 1939 1440  748 1997 2146 1967\n",
      " 4459 1226 3838  509 2908 2383 2026 2582  202 4166 3585 3154 3302 1490\n",
      " 3219 4482 4281 3160 3111 2711 2574 1889 2856 2035 4001 2807 1791 4226\n",
      " 2007 3541 1552 1589 3857  400  655 1321 2575 2535 2219 3549  480  266\n",
      " 1983 3048  371 3832 2226  332 1916 3404 2318    6 1935 2262  184 3675\n",
      "  334  381  829 3767 1017   74 3931   56 2117 3796 2164 2210 4361 1727\n",
      " 2639 2948  946 2737  835 2340 3414 3406 2308  218 1664 2706 4173 4371\n",
      " 3921 1682  490 2551 1534 2411  141 3794 3603  520  296 2836 4297  140\n",
      " 1190 2669  496  910  731 3076 3094 3047 2384 1137 2816 2181 4262 1677\n",
      "  881 3280  485 3022 3423 1746  216 1488  816 1565 3619 1948 3260 3448\n",
      " 2925 1562 1351 4253  774 3965  619 4088 3403 4451  162 2563  201 1360\n",
      "  566  305 3755  110 2064 3576 1332 3491 2057 2042 3050  247 2539 3814\n",
      " 3395 1797 2863 3805 2688  534 1165 3860 2456 3162 2875 2741 3511  100\n",
      " 4480 1955 3925 2782  958 4303 2502 4070 4027   33 1894  513  198 2765\n",
      " 2887 4205 4031 2983]\n",
      "[1419  412 3886 1636 2756 4295  179 1547 1781 2675 2227  844 4071 4088\n",
      " 3300 3906 3409  707 2948 4287 2167 3734 1049 4325 1218 3577 2025  833\n",
      " 4275 1273 1213  662  311   66 3984 3610 1681 3931  220   72 1626 3854\n",
      "  518 4375  495 4490 3743  211 2900 2162 1001 4457 2929 1559 1210 1574\n",
      " 1403 1243 2600  562 2311 1785 2641 2326 2920 2171 4344 1272 1943  895\n",
      " 1122   61  505 3824 1095 2611 3085 2631 3475 2934 1738 1010 2964 4368\n",
      " 3574  744 4183 2259 1751 2623 1601 1429 2434 4160 2042 2231 2661 1856\n",
      "  301 1473 3736 3438 1302 1212 2380  862 1593 1885  817  379 4231 2256\n",
      " 1494 3037 3284 4085 4205 1475  396  613 1439 3688 2556 1477 1141 2741\n",
      "  620 3155 1208 1074 1472 1202    1  537 1532 3163 3434 3428 1710 3676\n",
      "    3 3924 4017 3507 1296 2739  530 4407 1114 3517 3578 2279 2771 1259\n",
      "  257 4093 2894 1569 4298 3099 2424  527 2989  705 3689   33 1252 2968\n",
      "  893  621 3572 1354 1424  755 1425 3248 3027 2667 1098 4256 4486 2961\n",
      "  931 1118 4192 2447 2570  995 4327 1147 3794  355 4378 2070 3444  716\n",
      " 3715 2246 2615 3006]\n",
      "[  82 1284 1929 4027 4236  199 4286 3727 2338 4214 4308 3129 3142 1416\n",
      " 1400 4434 2439 3290 2434  871  677 3139 4300  941 4132  250 3958 2114\n",
      " 2671 2979 2531 3813 2349 1707 2233 2856 2221  404 4048 2615 3150 3059\n",
      "  907  556  134  896 1261 4326 3702 2723 3868 1412 2266 4021 2345  569\n",
      " 1340 2782 3626 3977 1474 2997 1242 3087 3498  482    9 1331 2694  657\n",
      " 1991 4330 2421 3116 3492 3270 1752 2885 1228   52 2162 1835 4019 2097\n",
      " 1493 4032  979  753 3511 3233 2598 3772 4178 2146  944 2486 1049 3021\n",
      "  804 3356 4432 1831 3530 1989 2357 2037 1922  730  599 3436  551  934\n",
      "  872 1852  921 1789 1124 3353 1857 1882 1825 3162 3957 2763 4199 3420\n",
      " 3746 2609 2274 2995 1921  102 3096 2387 1656 3872 1452  647 3301 3951\n",
      " 1238  266 2832  381 4187  138 2171 3211 3361  777 1506 1862 3447 2549\n",
      " 2121 2685 2002 2215 3891 4151  672 1967 2379 2016 2641 2643 1469 2224\n",
      " 4029 1599 1773 2993 3370 3106 3824  375 3612  189  306 2884 4127 2199\n",
      " 2270 2936 1956 3043 1512   33  494   49 1757 3168 3561  465 1197  695\n",
      " 3663 1502  939  607]\n",
      "[2229 1060 3700 2144  676 1777 1106 3210 2683 1636  525 2824   62 3591\n",
      " 3778 3656 4225  438  778 2559 3594 3536 3311 1920  841 1110 2137 1049\n",
      " 4098 2255 3082 1008 1918  759 2677  686 1495 1872 3106   66 3372 2961\n",
      " 3456 3319  482 1604  474 2468 1735  394 1212  680 3891 3111 1122 2047\n",
      " 3792 2027 2910 1059  540  307 2048 3860 2728 1930  412 2094 3821 4102\n",
      " 2814  827 2989 3339  963  319 3256  824 1695  919 3718 2285 3593 3174\n",
      " 1430 3431  244 1138  951 3336  333 1896  554 2863 1775 4016 2594 2363\n",
      " 1692 3668 3773  448   45  322 1707 1773 3023 2078 1710  194 3947 2251\n",
      "  522 3201 2721 2471 2003 4247  511 1051 3191  597 2753  747 2622 1175\n",
      "   43 3268   63 4485 2659 3687 4093 2724 1633 3323 2365 1302  837 1096\n",
      " 3344  835 3096 3808 3342 3846  644 3929 3670  253 3386 2159 2772 4063\n",
      " 3840 2811 1885 3983 1431 1294  463 2936  144 1230 2164 2666 1034 2603\n",
      " 1397 1359 3954 4359 2861  605 4193  603 4011 1468 3780 1295 1061 4318\n",
      "  256 2815  771 2790 1057 1109 2283  530 3894 4410 4061  672 2341 1806\n",
      "  273 2005 3721 1764]\n",
      "[4006 2113  320 1919 1629 1489  149  138   42  982 1268 1237 2654 3804\n",
      " 3673 2994 2131  865 3060 1103  239 1113  401 3540 2271 4130 3951 3720\n",
      "  507  635  823 4191 1426 2238 3278 1668 2282 1939 3645 3947 3555 3131\n",
      "  706 1890 2531  285  785  607 3208  794 1875  316 3711 2617 4473 3754\n",
      "  891 4186 2749 4225  104 1855  780 1885 2074 3327  697 4068  792  626\n",
      " 2810 1310  311 4092 3366 3531 3026 1480 1151 3833 2502  650 2002 2090\n",
      "  603 1539  384 4079 3256  511 3275  822 3938 3668 1549 1340 3359 4418\n",
      " 2041 2986 3589  596 3075 2807 4450 4007 2698 3680 1850 4074 2322 1774\n",
      " 1098  119 3118 2528 1589  659  181 2605 4178 2412 2016 3249 3714 4425\n",
      " 4201 1368 1020 3430  740 2413 1328 3759 2077 1713 2700 2960 4083 1078\n",
      " 1056 4428 3301 3081 2522 4170 2683 2816  656  925 2560 1997 4496 3313\n",
      " 3246 4111 3529 1641  291 3475 4491   64 1795 2418  681 1298 2091 2842\n",
      "  171 3331 2158  216 3896 3993 2813    5 2826 3124 3240 4103 2638 2472\n",
      "  463 2430 1400 1329 1750 1498 1269 4031 2515 3105 3883 1903 1404  128\n",
      " 3434 3335 1557 3080]\n",
      "[4068 3418  105 3615  855 1249 3209 3893 2064 3866 2077 3470 3218  357\n",
      " 1920  510 2218 4432  657 2476 1339 4484 3729  977 3676  344 2934  545\n",
      " 3514 3054  555 1479 3469 1258 1099 2437 4072 2635  938 4019 1217 1499\n",
      " 3865 2407 2006  541  793 2274 1970  333 1518 3880 4425 3230 3239  296\n",
      " 2824 3518 2622 1188 2112 1882  956 3082 4393 1660 1441  851   32  563\n",
      " 3616  246 2002 3479 3533 3445 4469 1800 1817 1751  388 2001  999 2670\n",
      " 4082  684 4009  498 1712 2322 1914 4306 3701 1062 4441 2166 1922 1223\n",
      " 1721 1584 3178  347 1162 2888 1397 4048 2021 1622  317 2939 1144 3170\n",
      " 1296 1994 3608 2662 1349 1517 3385 3791 2501 3326  240 2247 2020 3919\n",
      " 3157 4350 1949 3534 1515 3619  940 3542 3440  157 4501 4273 4165 3553\n",
      " 2545 3471   72 1939 3156  490 2581 2868 3716 1348 3263  402  790 3889\n",
      " 4190 1066 2945 3029 3195 3166 2623 3498 4050 1603  764 4252 1179  479\n",
      " 3249 1823  426 1404  893 3582 3372 4091 1323 2773  351 2691  290  286\n",
      " 3563 4343 1458 3908  142 3145 1932 3673 1431 3340 3927 1829 1288  261\n",
      " 4025 2538 4461 2953]\n",
      "[2635 2830 1664 1882 1681 2888 4050 2646  871 2679 3621 2359 3869 3965\n",
      " 3845 3524  125 2163 2391 2184 3296 3103 1599  933 4347 2988 4330 1406\n",
      " 1320  449 3580 3566 2878 4448  186 1430 2121 1922  665  415   92 2347\n",
      " 2851 3186 2319   77 2361 2275  253 2397 4264  781 1587 1385 2604 4103\n",
      " 4119 1335 2016  612  476 1541  833 2330  793   78 3672  519 4086 1617\n",
      " 4437 3242 2681 4075 1515  659 2654 2164 1500 3511 3866  393 3631  760\n",
      " 1993 3964 1625 2931  878 2828 3089 2827 3940 1974 1535 1956 2591  634\n",
      " 1008 2338  538 3394 1085  379 3423 2883 1237 1563 1881 1764 1151  284\n",
      " 1715  237 3387 1719 2003  979 4501 1966 1039 3861 4433 1252 4450 3853\n",
      " 2045  940 3250 1228  714 1655 2596 4248 3096  732  863 3002 1673  977\n",
      " 3666 1846 1366 3843   86 4499 3436 1127 2117 2813 1865 1054  704 4250\n",
      "  271 3086  420 2031 2440  929 4208 3438 2334 3547 1326 2599 2454 4435\n",
      " 3903  156 2243 1067 1188 1225 2253 4438 2147 2695 2843 3098 2505 2773\n",
      " 2729 1634 1401  684 1495  581 3298 1995 1289 4128 2818 2668 1087 2183\n",
      "  676 4023 3094  293]\n",
      "[3034  743 2321  293 4092 1063  248 4479 3260 1276 3539 1227 4379  658\n",
      " 3059 2021 3010 2053 1648 1045 4300  989 2750 2125 1613 2684 1091 3631\n",
      " 4474 2793 3102 4493 1938 2949 2997 4450 3709 2434 1353 3922 3206 2801\n",
      "  717 2754 1778 4137 4102 1667  897  925 1321 1455 1973 4070  578 1372\n",
      " 2158 2546 2381  660  277 2302 4047  276 2964  302 2391 2833  373 1186\n",
      "  619 1727 1059 1541 3226 2301  119 2858 1081  142 3189 1795 3486 1636\n",
      " 4176 2939  574 1895 2572  734  372  656 1851 2056 3331  451 1900  729\n",
      "  681 2968 3356 2367  423 1260  847 2681 2432 3560 3547 3862 3152   33\n",
      "  298 3955 1082  168 2203  510 2229 3210 2289 2827 4069  336 1299 4237\n",
      " 1510 2523 2240 4184 4455 2092 2286 3186 2363 3684 2315 3080 4304  825\n",
      " 2786 1870 2088  932 4373 2913  922 2642 1226  472  667  894  282 2573\n",
      " 3712 3156 3153  301 3436 2755 1466 2349 2015 4441 4287 3261 3047 3812\n",
      " 4341  542 2729 1257  671 4191 4442 2042  152 2030 2675 1100 3506 2951\n",
      " 2175 1199 1981 1827 4309 1758 1679 3554 1232  868 1555 2845 1421  631\n",
      " 2022 2001 1553 4039]\n",
      "[2969 3673 2527 1540  101  359 1002  954 3769 1736 1822  915 4027 2554\n",
      " 1437  429 3248 3466  872 4202  464  849 2894 3878  364 3777 3451 3012\n",
      " 1546 1870   42 3504  708  389 1647 4355 2669 1262 1383 3864 1792 1799\n",
      "  249  949 2463 4492 2688 4272 4074  767 1260  403 3211 3202 1448 1079\n",
      "  991 3808 2012 2332 3299 3223 3936  641 3203 2412  741 3196 1534 3367\n",
      "  649 2556 1462  913 1228 3297 2394  819 4117 1319 4291 4375 2046 1942\n",
      "  503 3345 1497  148  974 2206 2781 3015 2801 2544 4258 1956 4498  610\n",
      " 4317 1251 4223  355 2699  607 1920  353 3401 3529 1965 4288 3783  620\n",
      " 2682 1181 3631 3518 1750 1615 4115 3674 4052 1720 4458  759  727 1026\n",
      "  312  970  100 2783 3680 1118 2402 1472 3959 4273 2666  287 3059 3129\n",
      "  428 3399 4184 4457 3540 3364 4305 1568 3474 2739 2619  408  480 3974\n",
      " 3919 1274 3845 1294  104 1368 3298 2692 2185 1979 4474 1948 4033  382\n",
      "   80 1598 1810 4473 1485 2192 3987 3598 4357 3392 1747 1512 2064 2059\n",
      " 3656 2642  278 2475 3259  800  262  921 2431 4250 1300 2874 2076  687\n",
      " 3405 4194 3925 4391]\n",
      "[4242 4089 1203 1345  911   80 2049 4407 1107 3236 2487 4436 1362 4341\n",
      " 4378 3700 3902 1361 3809  622 3896 2598 3647 3807 2350 2568 4138 4184\n",
      " 3609 1572 1932 1839 4001 1057 1976 1781 4308  286 3472 3467 1427 3021\n",
      " 3231 4015 1919 1815 1118 2075 3018 3336 2853  900 1584  300 2459  443\n",
      "  713 3766 1515  498 2420  631 3589  322 4233 2698 1644 3748  603 2214\n",
      "  983 4059  303 3206 1466 2842 4276 2157  450 2411 2880 1680 3990 1297\n",
      " 3783 3195 3974 2295 2319 3290 3067 1603 4186 3709 1424 1542 4023 2935\n",
      "  173 1771 2008 2512 3007 1035  786 2262 2641  688  953 2905  613 3907\n",
      " 4052 1236 1260 2901  550 1606 2228 1890 4000 1369 1683 1244 3505 2396\n",
      " 2851 1866 1770 3071  860   88 2356  559 3584  919 2727   83 1733  320\n",
      " 3356 1419 2432  753 4297 3163 1417  222 1780 3484 3694  125  448 1015\n",
      " 3120 2742 1433 3905 3718  280 3972  920 1410  521  133 3860 1374   95\n",
      "  708  705 2910 3402  390 1741 3921 4330 1215 2494 2519 4220  642 3409\n",
      " 3825 4347 1146 3462 1135 4155 2536 3811 4088 3095 3187  282 1956 3780\n",
      " 2588 3136 3237 2337]\n",
      "[4266 1500 2139 3963 3454 3642  300  350  872 4140 2225  188 4404 3199\n",
      "  310   74 3385 3226 2275 3934 2371 1310 4071 2857 1589   66 3986 2519\n",
      " 1209  227  629  812 2116  566 3748 1700  814 1525  120 1225 2516 3653\n",
      " 2318 4152 2796 4354 2809 1470 3126 1612 3261  240  653 3398 1276 1895\n",
      " 1808 3529 3606 2409 1671 2875 3592 4333 1117  441   96 2947 3575 3275\n",
      " 1709 2044 1734 1817 2151  983  177 3117 4315 3265 1158 4362 1816 1861\n",
      " 3768 2975 2601 3386  470  301 3988 1746 1774 1111  987 3742 3857  642\n",
      " 4181  550    9 2101  921 3964 1840 1553  110 2053 1054   37 2100 3301\n",
      " 3564   19 3285 1624  572 3207 2666  365 3549 2015 2583 2368 4029 1189\n",
      " 1021 1731 2843 3799 2131 1463 4255 1241 1006 3064 2285  387 3831 3218\n",
      " 3544 4313 3082 1859 3166 2834 3993 2050 2818 2633 2171 3933 3037 4439\n",
      " 2919 2261 3700 3862 4379 1854 1725  358 3488 2402 4330 2615 1233  822\n",
      "  571 3211 4421  261 2087 2142  764 1517 2163   92  949 1433 2041 1766\n",
      " 1290 3112  119 1867 3919 1304  820 1467 3570  500 2888 1801 1088  953\n",
      " 2452 1010 3278 2726]\n",
      "[1832 1339  975 4215 2036 4329  951 2059 3810 3884 2191  134 3655 3563\n",
      " 1485 2302  563  407  148  685 1153 1109 1591 3019 2307 3667 1702 1465\n",
      "  774  607 4407   67 2289 1379 2026 2798 1110 3615 3111  251  118 2190\n",
      " 1588 3714 1253 3965 1701  610 2490 2344 1377 4174  998 4108 4126 2411\n",
      "   15 2323 3165 2857 1338 3214 1720 2830 3371  172 1306  654 1214 3754\n",
      " 1350  396  898 3758 1523  799 3473 2214   99 3510  433 3117 2374 1310\n",
      " 2815 1266 2430  175 1125 2619 2003 2999 3297  620 2462 3045  889  967\n",
      "  964  551 4123 3423 1101  605 3545 1329 1655 2304 3934 3497   66 2893\n",
      " 1235  657  108 3215 3932 3628 3383 3185 3504 2507 3877  429 2029 2478\n",
      " 3017 4501 1312 1918  606 4322 3922 3115 1281  298 1335  163 3886  841\n",
      " 3643 2900 1741 1271 1367  417 3534  138 2979 3663 2413 1194 1957 4448\n",
      "  397 1592  836  848 3852 1163 2061 1421 1262 1825 4156 1157 2284 2041\n",
      " 2213 2959 1648 4463 3688 1089  826  716 3225 3674 2096 1017  344 2000\n",
      " 3768 1869 1477 1431 1420  589  834   26 3864  295 1176 3900 1907 1851\n",
      " 4410 2327 1935  413]\n",
      "[3763  349 2368 3574  491  159 2261 3639 2654 4106 2044  946 2970 1711\n",
      "  334  498 4271  538 2935 2234 1088 3274  812 3754 4004 1342 3331 3959\n",
      " 3651  151 3493 2652 1697  202 2493 1915 3966 3242 3700 1670 1141 2535\n",
      " 1214 2631 1647 1876 1952 4181   60 2921  450 2083 2229 4241 1216 3293\n",
      " 1323  235 4286 3973 1412  259 1414 4465   72 1440 4424 1089  528  757\n",
      " 4412 3809  218 3979 2152 2134 1785 4373  570  557 2040 4136  312 1229\n",
      " 1791 2578 2606 3368  260   38 2704 3776 4088 1083  113 3527 3174 3417\n",
      " 4332 3370 2602 2462   29 1867 4386 1513 1539 1693 3062  537 3701  886\n",
      "  131 3236  472  525 3679 1190 1097 4219 2379 1703 2922   42 3346  598\n",
      " 4015 3452  380 4415 3547  412 3695 2569 1912 1723  560 3362 3877 4078\n",
      " 3057  271 1510  661 3548  756 1297 4216  839  381 3386  104 3318 2836\n",
      " 3534 2415  133 1125 2664  213 2037 1482 1665  925 4456 1834 4355 1040\n",
      " 3047 2100 2035 3858 3087 3001  632 2365 4400 4102 2342  741  687 1304\n",
      " 3805 1663 1592 4445  376 1246 3252  452 1473  134 2094 3750 3967 3425\n",
      " 4235 2209 2828 3139]\n",
      "[ 864 2224 3093 1271 1613 1988 1918 3523  106 2147 3711  656 1601 1888\n",
      " 4327 4455  500 3517 1719  703 1933 3476 1752  918 2410 1040  804  498\n",
      " 2873  565 4069 1911 3375  912 2394 2360 2908 4391 3556 1540 1688 1146\n",
      " 1001 4170 2141 3853 4015 2223 2709 2876 1966 2920 3262 1889 3940 3878\n",
      " 3105 4331 2435  220  590 2204 2904 1996  860 4091 3242 3751 2025 4408\n",
      " 2946 3513 3214 4067  146 3665 2831 2209 2945 1114 2378  604 1900 1872\n",
      "   76  221 3872  285 3823 2879  739  271  901  249 4202 3113 4470 4345\n",
      " 2179 2612  505  347  636  287 1403 3369 2834 1154  537  647 4303 4201\n",
      "  797 4322 2962 1297 1647 1825 1522 3060 2262  892  255 2563 3929 2781\n",
      " 1806 1817  150  880 2132 1036  766  634 1906 2507 1914  732 4092  637\n",
      "   72 1501 3308 4130 4329 1352 4133 3821  173 3056 3070 4382 3040 2518\n",
      " 1792 3186 2567 4451 2004 3451 3948 1269  945  372 3590 2864 4375 1326\n",
      " 3634  375 1735 3442 2342  943  975 2618 3167 4286  416 1107 3307 2606\n",
      " 1309 2697 2636 2226 1179 3019  900 3718 4088 1913 4165 2857  240 2593\n",
      "  665  938 4079 1644]\n",
      "[1553 1539 2664  450 1944 1940  439   83 1857 3412 3672  862 4065 2384\n",
      " 4210 3985 2437 2731  636   81 3399 2976 1617 3185 2762 1408 1301 4236\n",
      "  656 4233 2992 4094 3061 1609  136 1899  819 2037 1880 3981  584 2515\n",
      " 3805   32 2921 1068 4071  194 4362 3949 2452 3813 1228 3467 3029 3348\n",
      " 3640 2882 2128  543 3033 3855  953 4441 3964 2188  605 3208 4401 1679\n",
      " 1328 2955 3375  266 1372 4351 1262  849 3675 4278 4040  413 1484 2614\n",
      " 1731 3874 2498 3649 1580 1714 2009 4300 4057  965 4263 2607  839 4327\n",
      " 3320 2039 2202  348 3821  830 3516 1865  804  832 1094 1769 2079  465\n",
      "   22 3307  395 2535 2397 2720  362 1771  772   76  216 1041 3000 3715\n",
      " 2275  878 1195 2004 4150  328 4493 2148 3616 3436 3267 4296 2931 2593\n",
      " 3563 3577 4368 2169  375 3596 4384   75 2714 2625 3110 2003 3931 3756\n",
      " 3400 2387 1784 2405 3915  206 1270 3536  485 1636 2489 1674 1065 2406\n",
      " 1193 3624 1092  301 4403 3586 1917 2595 1733 3172 1555 1819 2481 2598\n",
      "  868 4369 2888 2445 3868 3950  943 3006 1751  618 2703 2748 3708 3986\n",
      "  412 3229 2733 2869]\n",
      "[1542 2802 3497 1591  605 2575 3694 4360 4222 3968 3426   71 2664 1050\n",
      "  523 2550 1456 1183 1041 2415 3057 1233 3061 1109 2366 1412 3471 4308\n",
      " 3068  143 1950 3925 3304 4181  821 3038 1148 1931 4320  777 3687 1998\n",
      "  832 3075 3578 2896 4416  989 1737 2906  674 3689  483  380  481 1443\n",
      " 1389  725 2368 1814 1406 2460 3823 3388 1714 2114 2325 4078 3525 3597\n",
      " 1455  128 2652 1889 3416 3735 1954 3138 1138 4235 2198 2699 3723  540\n",
      "  158 3249 2581 1402 4388   74 2422  212 4344  136 2976 4383 1460  838\n",
      " 3819  688 1419 1329 3027    8  594 2723 2755 2403 2465 1211 2350 2889\n",
      " 3844 3662 4173 1113 1825 4407 2234 3261 3432  639 4489  283 2025  735\n",
      " 1768    1 2367   89  430 2983 3101 4192 2347 3786 3211 1972 2385 2063\n",
      " 2261 1466 1728 2031  295 4126 1333 3437 2592 2643 4017 2710 1906  998\n",
      "  892 4161 3498 2137 3346 2316 3254 1923  352 2080 3796 3268 4242 1031\n",
      " 3667  721 1852 4340 3088 3732 2084 1215 1638 1574 4460 3826 3511 2033\n",
      " 1133 2298 3230 1209 2348 3798 2377 1135 2677 1448  667 2421 3066 2674\n",
      "   75 4491 2579  431]\n",
      "[1404 2463 3857 4026 4294 1038 2158 4228 1434  399 1422 4121 2976 3383\n",
      " 4042 2207 3271 1223 4164 2094 4411  612 1568 2918 3516 1747 1730  961\n",
      " 2736 4403 3406 4490 3295 2293 4417 2424 1329 2613  499 3211 2899 3090\n",
      " 2578  501 3484 2660 1928 2545 3087 2754 2192 2476  170 2058 3619 4464\n",
      " 1126   93  391 3056 2942 3684 3418  196  710 2812 2852  446 2813 2713\n",
      "  802 3122 2242  613 3388  788 2929  794 2292   75 3749  729 3292 1873\n",
      "  844 3123 2824 2939 3781 3355 2157 3421 4071 2309  723 4024 2521 3473\n",
      " 1637 3588 3025  894 2862 3074 1194 3164 3992 2583 2050  342 3285  946\n",
      " 1786 2688 3759 3146 4357 4154 3647 4085 1520 1915 4069  494  892 3250\n",
      " 3221 4157 3887 3125 4341 3735   89 2433 1385  862 4298 2084 2448  810\n",
      " 1753 1851  756 2880 2228 1621 2679 2016  832 1894 1810 3095  364  349\n",
      "  801 2811 4163 1459 1125 2810 1086  313 3094 2475 3611 2524  920 4148\n",
      "  247  958 2027 4036 2794 2445 3062 1470 3058 4400 2510 4408  687 4130\n",
      "  856 4205 3671 2776  789 1122 1020 2193 4316 2288 1017 2871 1057 2023\n",
      " 4496 1888 4398 3872]\n",
      "[ 525 2367 3718 3160  243 2174 2420 3100   97 1053 3288 2802 3957 2020\n",
      "  137 3351 1009 2221 2839 3146 1215 3165 1453 2337 1862 3427 1716 3218\n",
      " 1588 3186 2672 2868 1697  247  915  475 4449 3454 1333 4263 2078 2131\n",
      " 2426  451 1620 1728 1599 3948 2368 1937 1799  651 1597 1487 3376 3362\n",
      " 2820 2514 1686 1043 1480 1152 2185  103 2138 2336 4141 3629 2347 1674\n",
      " 1793 4106 3699 1193 4305 4170 3927 3522 2115  960 2074 1348 1603 2273\n",
      " 2621 3064 4282 2293  754 3851 2528 1695 1179 1859 2086 1154 1912  487\n",
      "  708 4198 2262   94 1343 1383  548 3557 3198 2731 3484 1058 3442 4249\n",
      " 3714 3896 1303  408 2123 2848 2419 1106  196 3664 4447  461  793  245\n",
      "  198 3566 3902 2532 1513 1754 2306 3411 2707 3776 3945 3898 1456  468\n",
      " 2661 2890 1017 3809   22 1711 2503  635 2136  884 1910  215 3060 1047\n",
      " 1244 3666 3447 2498 4172 1304 3743 1853  692 3070 1060 2090 1147 1187\n",
      " 2466 1066 1682 4159  545 3317  698 4057 4261 3332  514 3106 2111  384\n",
      " 3194   71  912 3337 2126 3981 1498 1904 3726 1415 3716 2992 2542 1323\n",
      " 4332 3395 2155  267]\n",
      "[3595  717 3603  638 4389  135 1566 2840 2699 2961 1720   57 3019 2381\n",
      " 1741 3623  767 3531 1208 1547 4450 2589 4425  645 3291 3129 2344  737\n",
      "    8 1089 1233 2401  524 3871 2679 3227 1623 2544 3201 1346 1006 1928\n",
      " 1983 2667  215 1627 2114 1664 1088   14 1867 2440  835 1649 2158 1429\n",
      " 3965 4346 2327  230 1882 2823 4078 3107 2212 4464 2459 3617 2981   25\n",
      " 1957 1451 2272 1332 3705 2747 1322 2365  811 2444 2221 3677 2991 3620\n",
      " 1279  440 3167  660 3740 2438 3879 1246 2582 4364 3914 2664 1147 2856\n",
      " 4339 2119 3506 2947 2731  845 1678 2869  834 4075 2906 1642 3544  839\n",
      " 2449 3186 1277  899 2686 3518 2126  882 2859 1931 2884 1433   77 1855\n",
      " 2369 4297 1391 3791 3261  942 1930  806  130 2074 4302 2716 2383 4117\n",
      " 3119  746 1036 2996 1365  843 3534 3040  276 3883 1066 2576 2148 4188\n",
      " 2812 4461 3166  720 2762 3832 4174 3584 2498 4237 2712 3664 2257  334\n",
      " 4435 3790 3350 2845 2350 1714 2044 3234 2629 2650 1924 1103 2301 1393\n",
      " 4456 1012 4443  295  106 2706 1474 2470 1840 3959 1170 3449 1974  769\n",
      " 3148  324 1280  593]\n",
      "[1077 3866 2731 2040 3694 1534 3080 4354  192 3509 3904 4356 3393 1798\n",
      " 2370 3519  216 3627 3374 4416 1626 1211 4083 1217  195 3549 4078   78\n",
      " 1972 4223 3983 1085 4431  366 3617 2023 2679 4204 2001 1779 1401  302\n",
      " 1128 4090    2 1093 2640 1549 1052 4157 1554 3725  272 2095 2076 1724\n",
      " 1347 3897 1200 2336  967 1965  203 3383  336  391  910  683 2933  563\n",
      " 1887  261 2606 2641 2998 2047 4327 1500 2444 4195 1445 3847 2905 2068\n",
      " 3868 3480 1904  295 3949 3999  869 1805 2300 1911 2202  630 1859 1748\n",
      " 2415 2274 1028 3562   77  810 1126  817 4306 3144 1399 1675 2261 4114\n",
      " 3826 3883 1180 4297 2922 1475 4142 3442 3899 1761 1116 2841 3525 3373\n",
      " 4492 4279 1294  108 2516   93  931  264 4363 3254 2545  351 3538 1050\n",
      " 2899 4230 1286  258  805  213 3134 2367 3843  656 4209 1630  612 2479\n",
      "  283 2178 2119 2263  120 3990 2079 2642  707 1335 1493 2839 3171 3748\n",
      " 1913 2091 3962 1199 2182 3952  288  359 3993  411 3294 2357 1358  790\n",
      " 1902 4483 1334 2408 1523 2252 3263 2020 2963 2686 3462 2465 2270 3142\n",
      " 1114  750 3389 1161]\n",
      "[3684 2909 3463 3710 3400 2791 2604 2246 3803 1423 2082 2015 3802 4290\n",
      " 1835 1044 1825 3065   50 4241  897 1701 3054  444  992 4098  451 3475\n",
      "  491  362    3 3663 3232 3576 1918 3769  488 3459 1862 3409 2924  930\n",
      " 2371 2609 1220  941 3217 2964  344 4177 3156  321  678 4074  402 4000\n",
      " 1658 1681  295 1290 3885 3109  271 2037 2375 2391 4300 2295 2414 1043\n",
      " 4416 4460  705 2167 2126 2419 4151 2638 3218  909  717  343  944 2511\n",
      " 4138 2644 1581 2351  734 1814  623  188 3166 1092 4278 3878 3836 1574\n",
      " 4231 2221 1214 2122 2392 3087 2950 4418 2121 1156 3517 1614  635 1121\n",
      " 1072  830  675 2694 4285 2333 2090 3519 2508  292 3920 1412 1308 1128\n",
      "  452 2552 1874    6 4053  902 1164 1422 1075 3599 1852 3310 2352 3294\n",
      " 2133 1248 3586 1759   26 3755 2425 1233 4094 4267 2422 2248 4046 3083\n",
      " 1799 2274 4362 4197 1851 3075 2995 4216  116 1077  825  480 4343  599\n",
      " 2576  837  680 3991 2080 1105 1790  412 3527 4412  544 1981  222 3976\n",
      "   33 3393 2690 3668 2802 4437 2083 2734 3191  810  278 4428  150 3578\n",
      " 2226 1114 4286 2827]\n",
      "[3092  421 1370 3082 3116 3560 1203 2734  113  423 3688 3834 2077 3976\n",
      " 3516 1003 4443 4205  811 4063 3158 4238 2145 3736 1932 2744  363 2406\n",
      " 2443 4347 4326 3925 3207 2796 3218 2576 3597 1416 4206 3738 4176 2453\n",
      " 3556 3196   27 2229 2885 1721 2811 4329 3066 2581  651  356 3301  581\n",
      "  902 2420 4454 1318 3147  894 1900 2004 4290 1037 2687 4180 2681 1082\n",
      " 2559 3801 2915 1096  609 2178  829 2801 4473 2087 3428 1619 2865 1304\n",
      " 3912 2194  193 1055  768  337 1765 2493 1047 2900 2808 2617 1384  163\n",
      "  799 2600  596 3259 3953 1376 4283 4360 1819 1157 1525  625 1225 3815\n",
      " 1297  411 3022 2557 2662 1222  330 1374 1585  668  129  184  544 3041\n",
      " 1772 4066  401  915 4148  620 2704 1748 3940 3878 3027 2250 3983 4345\n",
      " 3744 2574 3844  355 1481 2908  607  536  653 1604 2568  939 2709  213\n",
      " 3175 3062 2028  714 3826 2800  942 3348 4334  456 3846 2607 2861 2037\n",
      " 3909  205   47  992 1404 4253 4004  617  728 3646 1148   79 4070  912\n",
      " 1782 3438 2025 2041 3684 3547  280 3477 3898  203 3828 1808  873   62\n",
      " 1684 2874 2203 3868]\n",
      "[4408 4148 4211 3268 2928 2382 4125  657 3642  282 1171 4180 4063 2601\n",
      " 2581 3335 1511 3362  515 2962 1787  277 2948 1454 4075 4322 3720 2163\n",
      " 1105 2661 1838  193 1930 3383 3911 4008 3111  653  733 1240 2338 1179\n",
      " 2818  384 3230 4153 1574 1519 1845 1223 3952 2648  798 3932 3337 1343\n",
      "  218 4232 2545 1894  897 2916 1736 4464 2505 1114 4203 3557 1384  300\n",
      " 1234  926 4088 2550  436 2824 1125 1482 2606 1842 4032 2877 3061 4065\n",
      " 4067  468 3871 1277  788 4100 2609 2214 2134  316  474  786 2458 1863\n",
      " 1164 2097  803 3705 4233 2223 2745 1211 2119 1140 3343 1118  614 1402\n",
      " 2345  820 1627 3278 3406  381 1308  341 3417 4227 3059 2950 4372  350\n",
      " 1771  594 4441 4261 3074 2740 1528 1378 3915 2894 2543 1995 3876  291\n",
      " 1036 3846 3875 1581  152 1625 1174  560  514 2098 2472  588 2532 3234\n",
      " 2257 1451  197  652 1193 2299 3631 2293 4109    5 3717 1135 3767 3921\n",
      "  166 1057 1694  668 1977 1932 1239 2866 2626  744 2826 2354 1331 1801\n",
      " 4401 1665    0 4402 2304 2477 1126 4421 1081 2122  761  564 3944 1931\n",
      " 3386 3360 1855 3401]\n",
      "[3101 4352 2647 4489  753  649 1639 3106 2506 4480 1960 1079 1999 4309\n",
      " 2559 3303 2978  402    9 3960 2603 4147  916 1969 3690  990 1727 2044\n",
      " 3654  816  931  686 1775 2915  968  294 4403 1923 3484  340   73 2981\n",
      " 1780 2763  392 3767 1552 2411 3868 1876  115   88 1967  182 4133 4355\n",
      " 1476 3056 1522 4015 2936  695  551 2333  969 1930  530 2135  879 2016\n",
      "  777  326 3075  942 1004 1600 1713  486  899 2663 3749 2723 4194  752\n",
      " 3260 2273 1482 2397 2226 3063 1094  575 3342 1110 2766 1015  994  894\n",
      "  673  352 1835  731 2889 3125 4109  826 1235 2296 1581 2789 2141  117\n",
      " 2148 1898 2489  190 2640 1691 3262 3912 3441 3194 3059 2079  977 1315\n",
      "  732 2775 2518 3245 2708 4363 3486 1920 4199  509  425 3419 2353 3442\n",
      " 1612 3831 3057  613 1797 4431 2799 2903  497 2369 4458 1412 2944 3002\n",
      " 2073 1032  822 2874  933 2629 2167 2265  105 3753 4420 1312 3994  173\n",
      " 1064 1872  892  925 1913 3253 3291  594 3116  146 2233 1474 3861  736\n",
      "  327 4413   22 3687  368 4410  694 1087 2653 2159 2668 1228 4405 3838\n",
      " 1408  541 1832  337]\n",
      "[3481   83 3658   37 1928  227 4282  869 1298  148  328 4469 2646 1530\n",
      " 1747 1014 1716 2471 4253 4206 2034 2875 1728 1382 1356  700  940   63\n",
      "  898 3510 3152  299  250 3407 3408 1723  958 4183 2191  349 3699 2795\n",
      " 1116 2618  444 3967 3327 3674  262 2538  755 2295 1969 1822  178 3607\n",
      "  459 3153 1700 3886  765 3696 4111 2851 2474 1111 1418 1949 4416 1963\n",
      "  340 1329  222 3963 2695 1600 4311   76  133  534 1550 4438 4310  632\n",
      " 3144 3907 1797 3048 2748 1891  781 2378  111 2751 3273 3814 3134 3132\n",
      " 4225 3875 2672 2070 2563 2252 3548 1324 1578 1201 3205 1556 1414 1910\n",
      " 4492 3949  188 1942 2497 2558 1996 3513 2249  266  339 2950  977 1750\n",
      " 2223 1402 1208 3414 3014   80  513  128  922 1697 2298 3796 4224 2257\n",
      " 3184  542 3934 3108 2629 3537 3736 2977 3216 3311 1846 4421 1047 3231\n",
      " 3189 4228 4165  754  405 1877 2307 2126 2711 1661  504 3693 1292 3157\n",
      " 1328 1021 1381 2373 3268 3598 3365 1253 2353 2738 1428 1783 1263 1782\n",
      " 2779 4125 3196 3647 1090 3306 1758 4162  171 3496 1043 3274 1451  244\n",
      " 3627 1294 2363 2214]\n",
      "[2666 2999 1332 2536 1513 2902 2553   14 1231 2989  185 3325 4392 1897\n",
      " 4327  658 3699 3465 2795 2431 4052 1013 1849  966  614   46 3394 3564\n",
      " 3279   29 3748 3260 3577  785 2392 4095  437 4363 1634 2316 3207 1929\n",
      " 2280 2366 3895 2417 2892 4294 3495 4075  151 2314 3772 2591 2782 2758\n",
      " 3411 2065 1620 4323 3300 1679  654 2162 3320 2636 3598 3350 3466  528\n",
      " 1569 2720 1318 2287 4494 3566 3276 4182 1476 1997 4211 1829  318 2136\n",
      "    9 1356 1059 3436  648 3602 1484 4472 3371  413 2340  236 2492 4443\n",
      "  333 1918 3622 3533 4258  761 2672 2446   74 4280 2660 2530 2973 4393\n",
      " 4112 2884 3829 3104 1637 1670  802 3014 3426 1547 1276 4165 2697 3195\n",
      " 2376 2945 3313 2661 2345 2899 4289 3095 1487  805 1288 3236 1278 3586\n",
      " 3597  959 1445 3178 1104 1183 2548  449  448 2524 2372 2370 1854 1167\n",
      " 3614 4313 1350 4191 2797 1486 4212  530 4084 2561 3914  376 1646 1398\n",
      " 4028 1414 1815 3795 1481 3916 2025 2781 1151 4351  769  356 1893 4207\n",
      " 3013 2312 1116 3307  624 4265 4464 3235 1669 3948 1968  866 4044 2888\n",
      " 3074 1233 4395 3571]\n",
      "[1676  946 1642 4037 2659 3104 1990 3182 1310 3209 4285 1002 4324  347\n",
      "   96 3163 3657  150 1895 1945 1181  153 1882 2736  897 1867 2349  899\n",
      " 2855 3952 2067 4256 2832 1443  975  228 1861  645 2657  269    0 2979\n",
      " 3938 3347 1187 2622 1123 4144 2370    7  568 1457 3429 2578 3862 1269\n",
      " 1228 3613 1139 4460  887  214 4130 1039 4368 3535  562 1941 2363 1240\n",
      "   37 3360 3697 1208 1612  789 4386  664  935   53  932 1763 2770   49\n",
      " 1821 1014  511 2046 2715 2548 3949 4305 1260 2443 2685 3180 4502 3208\n",
      " 4122 2712 3667 4434 1143 3381 2959 2456 1379 4359 1383 3746 4027 2574\n",
      " 2435 3936  329 1556 4017 2072 4311 2779  200 3232 1236 3377   56 2725\n",
      " 2803  310 2831 1185 1964 3277 2036 1148 1420 2867  673 1649 3588 2651\n",
      " 4212 3638 2319 4115 1767 3402 2259 2663 2996 1097 2931 3546 2454  718\n",
      " 3176 3221 4257 4406 1298  460 3491 2026 2873   79 3410 2964 3343 3761\n",
      " 2179  578  998 2936 3652 1133 3368 2386  550  403  452 4430 1668 2991\n",
      "  289 2759 2001 2980 3093 3625 3336 2731 2629 4456 4003  958   43 1573\n",
      " 2655  356  135 1431]\n",
      "[3815 4118  500 3720 1636 4378  316 4019 3866 3652 2484  378 2590 1267\n",
      "  950 3059  243  919 1765 3684  637 3333  696 2013 1584 1433 2692 2022\n",
      "  711 3383 2519  324 3356 1401 1245 2199 2383 3500 2935 1301 3001 3923\n",
      "  512 3945 3104 1929  841 4216 1325 2776 4160 3089  475 3800  559 2214\n",
      " 1936 2430 2344 4389  885 3216 3120 2506  481  308 2709 3200 4321 2296\n",
      " 2968 1659 3515 3237 2310 4356 1557 4099 1319 2604 1208  934 2610 1024\n",
      " 2456 3738  570 1049 2830  669 3048 1131 2031 2142 3579 3699 1748 3447\n",
      " 2949 2005  561 2853  458 3640 1969 1933  206 1792 1909  697  659  842\n",
      " 3778 4195 2207  657 2292 2509 3335 4239 3195 3260 2400 1440 3903  878\n",
      "  936 3117 2650 2106 3512 1243 1999 2097 2627  965 2678 1114 4323 2570\n",
      " 3586 3911 2295 2546  488 4187 2694 3371 2281 2642 1840 3438 1052  526\n",
      "  900 4046 4025 3937 4404 4089 4147 2036 1262 1879 4274 3884 1785 3806\n",
      " 2415 3317 1066  390 4212 3137  387 3436 1904   40  342 4431 1369 1580\n",
      "  489   70 1568 2587 1810 3484 2320 2313  479 1211 1064 4288 2342 3725\n",
      " 3583 2103 1469 2802]\n",
      "[1295 3364 1681 2815 3429 4360 1012 1436 2938   27 2637 2813 3501 3788\n",
      "  839 1977 3019 2923  943  810  193 2721 3974  103  955 1376  167 2535\n",
      " 3901  532 3510   12 2224 2660  349  831 1637 4353 4213 1496 3531 1323\n",
      " 3345  694 3650 2033 1366 2626 4449  566 1676 1935 1514 1155  886 3665\n",
      "  901   20 2608 3820 3689 3375  125 1054 1662 3245 3212 1149 1073 1632\n",
      " 1571 3100   53 1477  137  631  658 4123 1594 2822  815  214 3509 3697\n",
      "  983  118 1469 3279 1321 2959 1040 3737 1751 4188 3156 4262 2619 4279\n",
      " 3952  331 4480 2672 3320 2253 4041 3226 1946 3642 2814  666 3837 1251\n",
      " 1556 3435 1657 4133   46 3462  308 3420 3511  489 2879 3386 3358 2847\n",
      "  509 4406 1398 1572 4371 3519 1365 2693 2223 3658  323 4447 2036  927\n",
      "  689 1349 1652 2575 4085 4217 2442 2788 3186  825 3166 3311 3688 1539\n",
      " 3883 4189  696 3971 2166 4443 2744 3953 2787 2376 1047 3869 3551 4031\n",
      " 4429 2082 3976 1731 2474 3917  974   90  766   23 4499 4456 2671 4287\n",
      "  556 2674 3388 2066 1270 2834 2182  143 2280 4376 2540 1565 3455 4201\n",
      " 4294  862 2054 1424]\n",
      "[ 222 3789 2939 4154 2684 4382  209  793 1686 1409 1643 4145  406 2339\n",
      "  306  614 2471 3203  550 1732 2011 3222 1205 4343 1824 2962 3026 4140\n",
      " 1255 2615 4291 3610 4186 2791  517  313 2757 4206  696 1852  248 3804\n",
      " 4255 2493 3421 3759 2191 3349 4166 1182  719 1837  533 3592  702 4321\n",
      "  997 1274 1938 3539 2043 3135  959 2020 1188 3023 3762 1510  826 2930\n",
      " 4263 4259 4314 3929 2436 2208   88 4346 4016 4114 3668 4228 3398  854\n",
      " 4357 3048 1081 3160 4142 1432 3496 1284  569 1295  583 4476 1876 2612\n",
      " 1330 2670 4336 2701 1688 2817 4068 3336  699 3269 2271  277 3992  984\n",
      " 1474 4225 1097  809  204 3990 1877 1679 3275 3399 2263 3110 1981 3548\n",
      " 2706 1397 4502 3507 1265 4157 3483 1024 1310  373 2341 1414 2571  989\n",
      "  850 3353 3223 1648 1483  522 1281 3001 3568  686  705 1084 2722  356\n",
      "  221 1196 2535   27 4468 2142 1575 1496 3192  707 4362 1418  672 4438\n",
      "  643 4185  840 2539 1444    8 1267  504  251  414  655 1046 2198 2714\n",
      " 3328  290  180 3124 3965 3532 4035 1388 1812 1238 3784  716 1058 1816\n",
      " 3800 2219  268 4101]\n",
      "[2577   24 3326  563 1080  507 4328 4348 1873   66  278 1357 4474 4352\n",
      " 3975 2790  487 2248  216 1600  452 4343 4012   71 2489 2382 2620 1888\n",
      " 2073 3721 2994 2694 1895 3260 1337 1239 2808  703 2806 1961 4140 3363\n",
      " 1414 1310 4038 4104 4173 1395 4112 1962 2961 2671 1547 3979 2271 4282\n",
      " 1098  284 3768 1804 1062 3864 3415 1470 1084 1486 1508 2529 4028  811\n",
      "   81  149 2361 2581 4029   28 2331 4139 1881  818 3746  919 2197 3749\n",
      " 4425 1720 4443 3425 3400 3805 4086 1842 2303 4465 2527 1506 2187 4113\n",
      " 2718 2681 2391 3108  964 3226 2888 1044 2166 2209 3138 1919  261   29\n",
      " 2993  721 4397  822 3866 2494 4065 3918 3259 3735 2649 2895 3367 1283\n",
      " 3252  882 1176 1548  414 2146 1850  868 3696 3055 2587 4185 4175 2800\n",
      " 2112 1678 3526 3200 1975 1841  553 2874 4280 2483 1054  841 3336 3775\n",
      " 1140  254 2538 1440 2728 2557 2869 1509  873  495   35 1113 3641 1864\n",
      " 3996 1085 1702 3416  572 3541 1026 4333 3568 4189  835 4190 3362 3795\n",
      " 3774 4063  516 1287 2268  321  712  285 1498 3983 2356  253 2562  212\n",
      " 3369 3939 3759 3849]\n",
      "[3489 1328 1164 2347 2385 1697  243  746 1529 2884 1246 1806 1939 1349\n",
      "  862  362 2030 3879 3666  214 1709 3769  800 4376 2729 4434 1598 2939\n",
      "  310 1214  949 2767 2142 3530 1368 2215 3994 1829  498 2738  691 2734\n",
      " 2279 3643 2297 3320 3338 2695   50 2301  386 1031 1000  814 4462  761\n",
      " 2921 4450 3640 1836 1796 2516 1753  706 2453 1503 2060  408 2986 3731\n",
      "   99 3109  374  518 3094  255  860 2090 1659  822  717 2057 1565 2996\n",
      " 4163 3085 4028 3820 4047 1105 2288 2383 3215 4331 1921 2233 2340 2271\n",
      " 2209 1155 3584 1986 3858 1916 2531 3233 1855 2146 3379 1106 3364 2632\n",
      " 3708 2575 1200 1189 4188 4141  675 3555   75 3414 1414  968 2854 1026\n",
      " 1298  490 3013 1501 1475 3589  679 2918 1570 4488 2619 4026 4098 2634\n",
      "  776 2448 1486 2983 4038  869 3106 3093 2211 4083 2067 1425 1861 3600\n",
      " 1555 2765  160 2816 2714  192 4096 1980 3869 4487 1754 4438  953 3707\n",
      " 1654 1506  853   91  182 4417 2491 4307 1653 4463 2245 1685 2942 1690\n",
      "  465  216 4115 1437 2210 1206 3369 3403 1886  452 1909 2684  238 4171\n",
      "  596  493 3702 3089]\n",
      "[3494 2352 3856 3338  843  124 3214 4101 1699 1862 3577  536 3688  579\n",
      "  788 2059  567  431 3123 1401 4430 4456 3199 4127 2213 2043  423 4070\n",
      "  690  803 1408 1276 4306 2093 1799  614 4168  432 2472 3554 1152 3204\n",
      " 3029 2348 1237 4435 1291 2108 2968 2174 1074 3588  428 4004 3194 4310\n",
      " 3675  958 1652  702 4372 2353 4483 2598 3781 2965  906 2816 4415 2099\n",
      "  156 3171 1728 2812  480 2197 2040 3984 3691 2959 4163 1587 4026 1263\n",
      " 1469 2928 4489  162 1093   63 3765 2513 3729 1577 1266 1644 3426 4190\n",
      " 4345  450 1912 3969 1761 2038  805  448 4021 2372 3327 1457 2283 1143\n",
      " 3893 1198 2502 3256 4303 1735 1736  219 2051  598 2424 3438 4102 4215\n",
      " 1339 4023 3229 1837 2297 4479  570 3545 3309 3656 3963 4496 2485 3471\n",
      "  379 1441  925 3008 3142 3535  584 1922 1930 1040 1659 3657  585  463\n",
      " 1958 4173 3409  464 2650 1141 3917  833 4330  168 3116 1954 4262 1476\n",
      " 3503 2866 1119 3480 4220 2916 3128 3102 3679 2333  771 2788  913 2544\n",
      " 1572 1753 1297 3987 3825 1062 2416  286 2991 3964 1672  283 1830 4307\n",
      " 2504  612 2418 2069]\n",
      "[3930  742 2982 3338 1381 1475 4038  726  338 1634 1076 2697 4470  329\n",
      " 3717  529 1053  584 1783 2266 1548  932 1956 3226  378  746 3689 4045\n",
      "   21 1189  270  744 3929 2204  902 3262 3111 1480 1711 1567  368 1872\n",
      " 3414 2313  541 2824 3246 1193 2633 1746 1676  755  331 3420 2362  654\n",
      " 1758 4090 3998  609 3413  412 1966  101 4452 1342 3321 4131 1293 3085\n",
      "    7 2168 4012 2072 1224 2466 3415 3080 2126 3181 3864  601 3875 3561\n",
      " 3367  635  765 1703 2505 2308 1606 2131 4359   63 1037 2643  517  211\n",
      "  917 1033   45 1159 2684 3371 3697 1063 3925 1753 4424 4113 2671 3212\n",
      " 1791 2032 3932 1238  256  850 4206 1469 2245 1601  697  953 3884 3534\n",
      " 2365 4417 3071 4224 4144 2964 1529 2992 3240  916  704 3652   10  498\n",
      " 4176  623 3775 2734  977  565 3480   96 1240 1246 1061  424 3082  459\n",
      " 1818 3499  848 1884 4460  930 3235  734 2690  316 4383 1870 1474 2129\n",
      " 3728 4125 2015 4396 1691 2392  998 3777  616 2197  761 3830 3428 1700\n",
      " 4050 2039 1628 3199  286 2636 3941 3043 1853 1769 4047 4324 2293 1692\n",
      " 3442  373  488  467]\n",
      "[2008 2922 4276  776 3824 3364 2605 2037 3865 2026 1263 1518 1965 2056\n",
      "  648 4278 1399 2505  384  717 1796 3557 4483 2805 3737 2378 2523 1634\n",
      "  309 4105  885 4085 1863 1721 2627 1653  550 1165 2287 3547 2495  156\n",
      " 2704 4368   43  396 1341 2794 3748 3911 1693 3739  573 3062 1353 2163\n",
      " 3047  227 2447 2696 3456 3540 3253  922 4430 2622  163 2902  325  314\n",
      " 3333 1522 4138 2462  129 1687  419  965 2798 2809 2711 3887  305 1005\n",
      "   25 4228  934  783 2142 4007 1598 4080 4489 1725 2388 2878 3452 1872\n",
      " 3136  283 2236  672 1828 1041 2853  612 2242 3614 3248 1713  798 4472\n",
      "  148 2256 4257 3164 1820 2543 3646 4036  350  821 3129 4261 3068 2401\n",
      " 2333 2258 2301 3086 4140 1887  768 1771 3875 1348 2513 3230 1578 3424\n",
      " 2864 1051 1657 1841 2889 2375 2146 2758 3173  658  450 1871 3678  300\n",
      "   70  676 1894 2442 1515 2996 1145 3212 3765  218 3996 3360 2566  625\n",
      " 1004 2508 4420 2076 2868  557 1413 3843  981 1806 1701 3703 2356 3403\n",
      " 2282 1346  594 1783  284 2683 2156 3625 1855 3692 4459 2177 1956  427\n",
      " 3252 1844 1307 1873]\n",
      "[3499 1045 3571  362 2590 3028 3330  553 2007 1812 2734 1817  417 1258\n",
      " 1350 2839 2333 1945 1545  851 1591 2565 2229 4182 4065 3358 2290 4034\n",
      " 2213 2700 2224 4422 2180  863 2532 1273 1050 2065 1623 3502 3726 3343\n",
      " 2582 1957 1444 2519 3997 2743 3373 3294 3025  413  168  605 3046 4490\n",
      "  185 1790 2889 2912 1653 3654 3213  951 3594 2077 1274 1571  613 4245\n",
      " 4417 3392 1758 2704  957 2512 2646 1543 2850 2481 3065 2756 1667 2767\n",
      " 4383   99  713 2642 1624 3754 3770 1931  688 1450  320  544 4293  531\n",
      " 1463  131 3244  701 3979 4003 3189 4163 1195  515  905  725 1445 2621\n",
      " 3041 1642 3715 4005 2432  322 1283  136 4242  630 3636 3736 1485  388\n",
      "  303 1948  557 3447 1304 2976 4089  364 2899 2935 2127 1275 2954  860\n",
      " 4426 3280 1658 3565 2712 3409 1429 1091 3401 3437 3049 3333 2936 1060\n",
      " 3285 2360 4336 2908  221 2144 1939 1414 3356 3617 3318  316 3890 3779\n",
      " 3707 1209 2547 1803 3889 3295 1186 3059 1431 3831  271 2253 4084 1579\n",
      " 3746 4222 2195 3149 3011 2146  660 1461 4316 3513 3051  691 1938 3098\n",
      " 4119 1145 2726 2925]\n",
      "[2536 3388 1823 3231  307 3751 4462 2136 2415 1480 4105 1034 1720  542\n",
      " 2161 1131 1307 3758 3726 2377 4488 3139 2790 2591 1969 2188  581 1269\n",
      " 2040 2285 4353 4244 2426 4195 4327 3082   26 2163 3295 3030 3603 3184\n",
      "  654 3746 1429 3095 2962  260 2908 2170 2549 2677 4234 3639 4377 2882\n",
      "  400   95 4099  135 3672 3961  537 4395 3480  373  351 4224  775 3552\n",
      " 1542 4033 2429 3992    9 1338 1757 3088 4470 3274 4138  355 1806 1537\n",
      "  153 2863 2008 1111 1743  544 2941 3345 2785 2280  924 1609  156 1081\n",
      "  401 1014 3666 1738 1672 4435  290 4219  692 2444  412  414  352 1549\n",
      "  230 1644 4212  661 1339 4370 1475 4282  517 2434 2283  569  184 2275\n",
      "  357 3138  619 1856 3469 1843 1705 1636 2070 2802 2482 1530 1594  722\n",
      " 2111 4151 3302 2376 4076 4405  618 2659 3284  562 2612 2818 2243   68\n",
      " 3864  360 1227 4465  327 2543 3099 2856 1904 2782 1311  762 3765   78\n",
      "  312 2735  157 1216  735   38 3979 1717 3108 2465 3399 1139 3156  973\n",
      " 4375 1656 4080 1284  699  968   71 2254 1812  119 4052   70 3731 2775\n",
      " 2253 4382 4114  679]\n",
      "[ 661  787 2500 2806 2485 3068 1245 3756 2410 1240 3634 3394  918 4122\n",
      " 3454 1787 3409 1691 2415 1427 2223 4033 2908  565 2210 1119 1730 2684\n",
      " 2159 2365 1571 1266 2612  834 3837  393 3489   89 2156 2139 3802 2475\n",
      " 2290  529 1791 2403 3382 2833 2206 1885  474 4486 3743 4051  457 3900\n",
      " 3356 2188  949 2892   99 2470  591 3051 2173 1417 3983 3674 2222   85\n",
      " 1708 3156  790 3977 1927 3599 3003  632 3711 2572 3851 2044 1453 1750\n",
      " 2289  667 1793 3254 2367 1716  518 2828 1006 1147 3778   54 3124 3775\n",
      " 1566   51 2923 2204 3109 2384 3004 3705 3842 3044 3224 2551 3841 2246\n",
      " 3252 1475 2529 3423  126  585   31 3708 1359 1938 1048 3863 4351  878\n",
      " 1011 1465  414 3370 1874 1412 1819 1242 1233  167 1520 1346 1714 3366\n",
      " 1966 3515  291 1219 3466  383 1160 3694 1849 2311 2707 3033  452 2155\n",
      " 3518 3910 3457 2704  511 1126 3818 3461 1207  210 3733 1542 3497  598\n",
      " 1290  406 3784 3905 2495 3297  328 4214 1497 3428   91  777 2571  981\n",
      " 4325  144 1379 2726 2640 1615 3783 2913 4395  318  553   57 1666  258\n",
      " 3459 4276 2348 3636]\n",
      "[4352 2266  942 4300 3137 3824  592  956  606 1672 4098 3931 4066  152\n",
      " 2227 3163   58 2941  729  375 2912 1072 1179 1836 1850  987  810 2261\n",
      " 2438 1579 1326  451 1130 1885 1577  671  400  438  863 1429 3457  522\n",
      " 4016 3856 1312 3368 2692 4238 4371  300 3623 3794 4214  586 4303  925\n",
      "  393 4229  299 1198 1837 1876   61 2748 3632 1619 2892 3937 1919 3249\n",
      " 1962 1949 3752 1005   13 3713 2425 2319 3682 2959  881 3851 2500 2446\n",
      " 2886 1422  286 3799 3600 4063 1391 1762 2808 3887 2709 1049   27 1585\n",
      " 2371 3624 4044 3304 2794 2848  103 3862 3269 2654  601  480  176 2416\n",
      " 2581 1635 2353 2518 4275 3613 3326 3129 1408 3580  579 3444 1578 4119\n",
      " 2817  837 2531  547 3870  195  198 2308 1217 3604 4245 2844 4359  777\n",
      " 2228 2797 3236 1633 4251 2315  252 4422 1905 1416 3906 2134 3363 2936\n",
      " 2154 1808 1228 4487  120 1045 2547 3707 2330 2222 2035 4051 3576 2852\n",
      "  197 1701 4190  663  322 2410 2679  605  830 1024 2608 3370  330 2468\n",
      " 4084 3479 3390 3997 2249 2644  648   26 4358 1712  452 3357 1967  836\n",
      " 1444  336 2238 1442]\n",
      "[  54 2389 2656 1424 3831 2814 3216 1223 1183 2635 2065  641 3027 2947\n",
      " 3965 3091 1707 1725  482 3378 2812 1213  999 2775 3045 3768 1171 2357\n",
      "  658 4486 2670 4428 4156  166 1874 3104 1061  949 2971 3966 4376 1260\n",
      " 4427 3480 4478 2869 2258 4211  659    7 1771 1178 2168 3143 3822  932\n",
      " 2265 2380 4404 3925 3960 1078 4028 3308 3042 2904  468  794  461 1935\n",
      " 2545 1649  474 1051 1973  515  358  289 1366 2417 2195 3815 1441 3083\n",
      " 3546 2104  528   31 2737 3444 1943 2022 1881 1670 1418 1547  835 2227\n",
      " 3043 1703  102 1924 3999  369 1763 4374 2308 4056  208 3218 2906  753\n",
      " 2194 1825 1727 2844 3798 1635 4010 1320 1064  940 1334 3630 1339 2923\n",
      " 3600  294 2471   29 2382 2560  336 4257 2619  897 4432 3090  425 1971\n",
      " 2181 3980 2418  728 2990  221 1396 4179 3165 1685 2406 2393  981 4200\n",
      "  117 1785 3728 1400  925 2527  483 2243 3285 1895 1952  499 1776  862\n",
      " 3465  183 2370  555 3519 2629 4185  146 1731 2979 2136 1985 3818 3253\n",
      "  901 2423 1328 1866  320 4208  941 4395 2575 3800 3362 2475 1218 4348\n",
      " 2364 3874 3094 3099]\n",
      "[1802  343 2753  175 1082 3894 3193  480 1980 2336 4127 2572  544 2373\n",
      " 2729 1056 1169 2629 3721 3149 1845  198 2717 4058 2813 3505 2965 3901\n",
      " 3620 3867 3734 3305 3883 1140  219 1751  759 2080 4137 2777 3581 3860\n",
      "   87 1522  349  458 3463 2440  556 3617 3261 2167  705 2513 4154 3940\n",
      " 3956 4207 3846  347 1944 1883 3863 2251   81 2470 3674 3277 2602 2795\n",
      " 1722  417 3200  161 3461 1626  827 3095 3157 1700  148 4438 3004 2784\n",
      " 4071 1673 2678 3885 3258 1155 1149 1711 1016 3044 4194 3059 2413 2245\n",
      " 2118 3858 2812 3379 3382 1925 1810  353 2665 4082 1719 3151 2381  929\n",
      " 3508 1683 2088 1031 2209 3841  450 2423 3405  301 1215 1129 3921 2881\n",
      " 3758  984 1741 4405 1433  505 2738 2825 2007 1145 1142 3299 4172 1952\n",
      " 3236 3011 1003 1682 2980 3612 1257  698  631 1401 3849 2132 2149 2293\n",
      " 2757  391 4332   65  853 1575 4331  812 2266 3401 3061 4434 2695  733\n",
      "  214  111 4230 4083 2037 2890 4425 4485 3625  337 2873 1713 3234 2997\n",
      " 3601 3001 4424 1450  750 4461 1723 3688 1001 3527 1426  595 1965 1191\n",
      " 3224 3269 2273 1441]\n",
      "[3691 3183 1066 4056 4074 3432 4102   46 1581 3043 3522 1704 1706 2178\n",
      " 3089 1974  256  924 2305 3640 3953 1032 1755  754 3495 1715  377 3809\n",
      " 1546 1645 1031  207 3614 2675 2490 1027 4393 4303  770 2392 3978 3843\n",
      "  161  378 4473 1592 2167 1509  883 2477  730 3718 1257 1311 1616  970\n",
      " 3837 3184 3453  967 2187 2576 1017 1538 2409 1466 2226  851 2300 1846\n",
      " 1109 3610 2086 3015 3789 2610   13  218 1529 2400 1324 4456  844 1147\n",
      " 2975 2687 2746 1262 3046 3392  220 3024  948 3310 2629   88 2929 2327\n",
      " 1465  327 2711  877 1925 2145 1287 1331 1427 1094 1170 2369 2899  663\n",
      " 1218 1649 2192  707 1054  375 2173 2585 2582 4442 1076 2546  492 4165\n",
      " 2049 1523 3977 2468 3659  199 2112 3647  538 4469  889 2696 3826 3408\n",
      " 3833 3214  716 2945 2299 3291 4232   18 3993  497  231 3082 3988 2074\n",
      " 4187 3445 1544  729 3452 3788 1848  565 2552  824 1598 2266 2000 3690\n",
      " 2974 2015 4462 3899 4420 2666 2429 4426   10 3258 3815  811 2978   27\n",
      " 3737 2924  247 1658 3663 2342 2116 1118 1793 1152  110 1052 3110 3885\n",
      " 2051 2209 4310 4121]\n",
      "[4187  209 1768  514 4350  141 1012 4481  369 2637 1304 1752 1475 4227\n",
      " 1915 3924  399 4110  453 1667  776 4158 1276 2742 4378 3997 3910 2624\n",
      "  665  840 2787 4319 1416 2089 4000 3843 3298 3427 4069  319 1960 1662\n",
      " 1938 4011 3706 4226  205 1929 3530 4430 2898 2993 3065 3634 3807 1736\n",
      "  446 2927 4470 3873 4280  975 1557  599 4268 1270 3134  882 2585 2212\n",
      " 2695 3601   61 2164 1807   24 2603 2228 1250  564 3036 3399 2156 2390\n",
      " 2415 4418  367 2647 2572 4295 3215 2299 2294 1748  980 4121 1647  570\n",
      " 1637 3526 4151 1229   99 2505 4341  873 3558  859 1673 2672  260 1996\n",
      " 3478 2395 4138  508 4321 3296 4386 1166 2550 1084  832 2923 3262 3759\n",
      " 2394  395 3663 4334 1664 3115 1797 3737 2121 4196 4300 1686 2150 4346\n",
      " 2048 1862 2475  517  562 2630 2169 2189 1159 1437 3079 1890 4269 1832\n",
      " 2696  908 1464  853 3724 1848 1680  513 3829 1844 2634 2713 3518 1260\n",
      " 1934 3614 2141 1000 2120 2948 4186 2488 4106  198  427 4393 3925 1242\n",
      " 1076  870 3203 3278 4007 4429  604 2991 1759  858  689 3803 1635  814\n",
      " 4057  538  387 2437]\n",
      "[1615 1584 2146 1168 3719 4402 1877 1788 3137 2169 1534 2009  495 4164\n",
      " 3100 2022 2849  198  606  155 3864 4312 3049 1545 3175 2116 1456 2314\n",
      " 3724  119 3011 4469 3072 2726  420  705  744  883 2238   29  182 3845\n",
      " 4329  857 3718 2469 1017  308  468 3028 3608 4464   64  419 1053 3927\n",
      " 3113 1955  496 1335 1858 2197  208 3112 1740 3844  369 4319 3973 3829\n",
      " 3448 2069 2171 3628 1169 1035 1228 3664 4241 2514  874 3187 1109 2158\n",
      "  455 2971 1047  498 2369 4408 2705  523  655 3354  865 2270  361 3456\n",
      "  348 2255 1621 4465 1046  824 2347  330 1128 4291 3512  517 1285 3588\n",
      " 2029 3880 2014 4409 3405 2470 1980 2528 1516 3956 1288   10 3701  461\n",
      " 4398 1114  355  424 1445 2755 1592 3753  375 2129 1825  486 3765 2079\n",
      " 1441 2953  378 3979 3523 4445 2880 1058 4065 2983 1989  916 1745 3575\n",
      " 2751 4487 1616 2526 2237 4176 1408  806  261 4102 3254 3704 2487 4146\n",
      " 4147 1599 4277 3838 2122  850 1807 2251 1344 2054 2067  696 4000  559\n",
      " 2127 2234 3271  956 4395 4033   91 2360 3771 3342  600 1723 4135  787\n",
      " 2623 4457  724  611]\n",
      "[1179 3971 3012 1131 3905 1982 3680 2896 3744 1964  832 2709 3353  716\n",
      " 3845 2657 2518 3803  528   84 1972 2017 3713 3942  757 3570 4455  978\n",
      " 2175 2292 2113  688 3252  417  946   99 1614  781 3379 1282 2964  150\n",
      "  374 2963 2493  929  192 1937 4283 3752 3574 4198 2400 3902 2537 1334\n",
      " 4358 1689 3318 3339 3162 1465  827 3511  126 1671 3632 2509 1539 3108\n",
      "   89  740 2622 1152 1604 2857 2444 3792 2139  435 1567 1115 3666 3354\n",
      " 3384    2 4470  766 3115 3217 1785  315 3118 4335 4451 2987 2141 3361\n",
      " 2935 1606 4464 1793 2941 1283  810 1619 2115 3780  393 3039 1221 4007\n",
      " 4364 2816 1258 2538 2375 2913 3176 1466 3821 1747 4070 3717  230 3220\n",
      " 2877 3988 3347 3344  692 3838 1171  963 3727 3894 3578 1673 2373 3284\n",
      " 4078 1058 4040 1071 1780  780 2235  752 1348 2869  319 1016 2887 2386\n",
      " 1860 1294 2827 4313 3013 1639  342 1796  866  336  769 1702 2263 3239\n",
      " 3152 1406 1931 3270 3510 4490  442  171 1757  392 3901 4339 2777  861\n",
      " 2026  152 3725 2491 1385 3720 1229 2260 2199 2901 2595 2668 3316 4147\n",
      " 1093  154  134 3654]\n",
      "[2505 1740 4497 1528  261 1142 2770 2243 2108  384 3764 3523  525 1910\n",
      " 3250  968 1302 4390 2455 2261 3509 3838 4375 3067  123 3870 3953 4437\n",
      "  137 3975 3929   41 1915 4093 2172  153  105  526 2136  810  713 4321\n",
      " 2809 1406  254 1940 3483 3053 4370  458 2213 1490 4236 2795 2032 3364\n",
      " 1750 4278  507 1381 1820 1052 3253 3356 2983 3215 3591 4441 1198 1037\n",
      "   90 2122 2389 2720 3967 1342 2252 3561 3812 2403   78 4206 2990 2538\n",
      "  594  647 2893 1895 2083 1208 1255 1955 1190 1108 3209  310 1415 3995\n",
      "  549 3105 2864 2564 2072  142 3612  711 4478  953  832  703 3860 3954\n",
      "  189  516 4002  120  992  168   62  521 1126 3357 3822 4427 1307 2787\n",
      " 4133 3621 3682 2332 1249 2291 1394 1311 1025 4205  228  719 3411 2070\n",
      " 4463 3572  159 3557 2991 3465 2287 1581 1041 3429 3408 1078 1666  745\n",
      " 2421 2000 3110  129 2514 2917 1057 4422 2228 2424 1056  910 3927 3309\n",
      "  683 4268 2149 1900 2833 1602 2844 3296 3459 1996 4358  256 2689 2425\n",
      "  217 1457 2469  406 1519 2736 3395 2192 4011   85 1894 2947 4056 1642\n",
      "  629 2822 2936 2546]\n",
      "[ 889 4194 2655  205 1863 1919 4401 3264  978  101 3837 3331  373 1794\n",
      " 1751 2413 3478 3445 2918 1695 1448 2488 2561 1825 1355  612 2342 3969\n",
      "  121 1284 2756 2101  327 1043 4446   94 1171 2929 2642 2205  652 2945\n",
      " 2158 1512  168 2825 3136 2531 2035 2610  677 1514 2284 2736 2691 1203\n",
      " 1028 2785 1954  374 1112 3578  132  364 1453 3873  752 4420 1058 1629\n",
      " 2305 2390 2454 4016 2741  725 1320 3911 2717 1106 3631 3210 2708 2402\n",
      " 3363 1705  347 3158 1107 4461  340 4185 2759  161   89 2814 3326 3700\n",
      " 4179   44  152 3137 3119  895  174 1617  558 4422 4040 2639  890 3038\n",
      " 1274 1883 2589 2473 2627 2166 2836   71 2870 3235 4470  576 1590 4157\n",
      " 1222 2086  102  370 2434 2314 4066 3146 3101 4245 1585 2527 1359 3152\n",
      " 1892 2245 1781 1498 1516  466 2327 3587 4081 1833 3981 1226  182 3250\n",
      " 1003  964  528 3717 2014  139 2424 3039 1766 2940 2624 3651 1491 4474\n",
      " 1156  646   45 4055  124 4206 1880 4262  721  809 2237 2688 3294 1647\n",
      "  846 3588 3062 1329 4153 4305  572   13  334 1118 1358 3236  406  692\n",
      "  195 3984 2141  149]\n",
      "[1073  635 4404 4146 2451 3447 2076   53 3448 2862   74  900  538 3997\n",
      "   57 3642 2688 4034 1287 3006 4419 1614 4488  979 3516 4354  298 4420\n",
      " 3772 4379 4135  204 1160 4328   25 4376  590 2453 1700 3131 3931 4067\n",
      " 1089 3436 2584   83  442  849 4090 1769 2309  893 3030 3729 2845 2072\n",
      "  840 3073 2070 4107 1271 1076  638  822 3557 2580 4290 2826 1702  647\n",
      " 4411 3152  608  468 4018 3930 1370 4108 3843 2321 2269 3207 3681 3182\n",
      "  113 3603 1414 1889 3483 1241 4199 3500 1342 2085 2907 1639 4025 1680\n",
      " 3324    9 3433  150 1908  870 1867  796  706 3014 1797  789  229 2127\n",
      " 2530 2542 3940 3244 4212  525 3965 3726 1298 1199 1736 2664  212 1965\n",
      " 3109 2056 1362  691   40 2637 1803 2184  948 2018 2405 1808  231 3829\n",
      " 4192 2899 2022 4500 1394  838 1967 4438 1096 2668 3663 3192 4133 1124\n",
      " 3619 1899 1197 4080  945 2063 1141 1087 4263 3948 2987 1387 4059 3111\n",
      " 4294 1859  549 3808  303 3102  826 1890 3625 2653 4105 3124 2392 1417\n",
      "  845 1915 1321  510 1177  784 1991 1066  564  210 1585 2906  694 2915\n",
      " 3605 4297 1149  636]\n",
      "[1438 2600 2040 1187 1171 3779 1727 3087 1602 1080 3572 3844 1192 1682\n",
      "  135 3325  110 4365 2297 2561  247   76 1700  249 1307  193 1968 3709\n",
      "  574 1445  555 3951 1241 3412 1795 2614  548 2663 2324   38 2946 1548\n",
      " 4069  171 4219 3429 1346 3821 3759 1554  326  184 1440 2367 4228 2781\n",
      " 1894 4498 4175 3688 1501 1113  307 4441 2919 3749 3340 1524 1901 2463\n",
      " 3590  964 2957 1276 1161 1532 1186 4446 4182 2415 2824 4196 3937 2515\n",
      "  209 2705 1111 1053 2579 2983 1117  444  773 1087  739 3820 4081  417\n",
      " 3216 2562 3300 3418  180 2485  627  234 4180 1859 2692 2017  891 4074\n",
      " 2584 3195 4257 3724 1934 2936 4070 2262 1839 3958  831 2054 2074  728\n",
      " 2348 3404 1484 4222 1698 3118 4384 1589  973 3838 1969 1995 2319 2951\n",
      " 2460 2147 3796 2248  755 1736 1819 2484 2575  217 3167 2314 2845 3605\n",
      " 1621 3737 3299 3805 1309 2729  321 1651  198  857 1427 4028   62   15\n",
      " 3603 3186 3068 1599 4244  901 4284 3408 3972 1876  892  350  740 4039\n",
      " 3785 1462 1957 4230 2964 3974 1873 3053 4292  419 1288 1571 3401 2671\n",
      "  597  624 4085 2769]\n",
      "[2835 3156  359  898 3730 3714  428 2516  238 2562  105 1730  515 1375\n",
      " 1322 4215 4023 3544  622 2786 3324 4398  690 2299  156 3781 4440 2036\n",
      " 3306 2580 3653 3465 2179 4390 1321 3351 1686  365 2496 1447 2450 1857\n",
      " 2778 1664   78 3892 1568 1058  520 2857 3519  395   66 4164 1587 3938\n",
      " 2132 1079 3794  771 4026 1113  415 3240 1896 3797 1613 2039 3463  283\n",
      " 3290 2124 1065  692 1625 3654 3258 1814  244 2836  878 1557 2461 4097\n",
      " 4105 1951 1371 3110 2071 1584 3321 2976 4129  700  558 1524 3460 4296\n",
      " 3303 1202 2537  749 2244 1416 3065 3442 1062 3143 3147 1095 3021 2952\n",
      " 3152 3823   67 3945 1307  513 1506 1520 1855  508 2203 3268 2685 1099\n",
      " 4450 1548 3172 2599 3417  176  198 1776 2474 1226 3736 2056  550  875\n",
      " 2364 2527  725 1219 3276  688 4465 1982 2074  142 4078  447 1977 1825\n",
      " 3015 2777 2212 4240  502 1239 3070 4159  189 1912  258  849 2454 2486\n",
      " 3916 2242 3190  748 2059  802 2190 2301 1415  988 1240 1242 2418 1654\n",
      " 3480 3378  467 3487  962   34 2196 2382 1818 3394  850 1962 3223 1980\n",
      " 3256 1883  869  920]\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_EXPERIMENTS = int(input(\"Number of experiments to run: \"))\n",
    "DATA_SIZE = int(input(\"Size of dataset: \"))\n",
    "NUM_MAX_ITER = int(input(\"Number of max iterations: \"))\n",
    "data = []\n",
    "\n",
    "for current_iter in range(NUM_OF_EXPERIMENTS):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = create_training_and_testing_data_sub(df, DATA_SIZE)\n",
    "\n",
    "    data.append([X_train, X_test, y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zBoSvysDiOSJ"
   },
   "outputs": [],
   "source": [
    "def find_classical_accuracy(x_train_, x_test_, y_train_, y_test_):\n",
    "\n",
    "    svc_clf = svm.SVC(random_state = 7)\n",
    "    svc_clf.fit(x_train_, y_train_)\n",
    "    labels_pred = svc_clf.predict(x_test_)\n",
    "\n",
    "    svc_accuracy = accuracy_score(y_test_, labels_pred)\n",
    "    svc_score = metrics.balanced_accuracy_score(y_true=y_test_, y_pred=labels_pred)\n",
    "    svc_f1_score = f1_score(y_test_, labels_pred)\n",
    "\n",
    "    return svc_accuracy, svc_score, svc_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "G9aJdyT_iR1i"
   },
   "outputs": [],
   "source": [
    "def find_classical_accuracy_dt(x_train_, x_test_, y_train_, y_test_):\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(x_train_, y_train)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    labels_pred = clf.predict(x_test_)\n",
    "\n",
    "    svc_accuracy = accuracy_score(y_test_, labels_pred)\n",
    "    svc_score = metrics.balanced_accuracy_score(y_true=y_test_, y_pred=labels_pred)\n",
    "    svc_f1_score = f1_score(y_test_, labels_pred)\n",
    "\n",
    "    return svc_accuracy, svc_score, svc_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "y-zxXK6IiWpe"
   },
   "outputs": [],
   "source": [
    "def find_classical_accuracy_rf(x_train_, x_test_, y_train_, y_test_):\n",
    "    rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    labels_pred = rfc.predict(x_test_)\n",
    "\n",
    "    svc_accuracy = accuracy_score(y_test_, labels_pred)\n",
    "    svc_score = metrics.balanced_accuracy_score(y_true=y_test_, y_pred=labels_pred)\n",
    "    svc_f1_score = f1_score(y_test_, labels_pred)\n",
    "\n",
    "    return svc_accuracy, svc_score, svc_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fog\n",
       "0    0.977126\n",
       "1    0.022874\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Fog'].value_counts(1)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fog\n",
       "0    4400\n",
       "1     103\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Fog'].value_counts(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brm0ZJDDicFe",
    "outputId": "c3682a5a-10c7-4b93-f5ce-cd0c15a32113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment no: 1\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 2\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 3\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 4\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 5\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 6\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 7\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 8\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 9\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 10\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 11\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 12\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 13\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 14\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 15\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 16\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 17\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 18\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 19\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 20\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 21\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 22\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 23\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 24\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 25\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 26\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 27\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 28\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 29\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 30\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 31\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 32\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 33\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 34\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 35\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 36\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 37\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 38\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 39\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 40\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 41\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 42\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 43\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 44\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 46\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 47\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 48\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 49\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 50\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 51\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 52\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 53\n",
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[20], line 12\u001b[0m\n",
      "    accuracy_svm, balanced_accuracy_svm, classical_f1_score = find_classical_accuracy(X_train, X_test, y_train, y_test)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[15], line 4\u001b[0m in \u001b[0;35mfind_classical_accuracy\u001b[0m\n",
      "    svc_clf.fit(x_train_, y_train_)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m in \u001b[0;35mwrapper\u001b[0m\n",
      "    return fit_method(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:199\u001b[0m in \u001b[0;35mfit\u001b[0m\n",
      "    y = self._validate_targets(y)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:743\u001b[1;36m in \u001b[1;35m_validate_targets\u001b[1;36m\n",
      "\u001b[1;33m    raise ValueError(\u001b[1;36m\n",
      "\u001b[1;31mValueError\u001b[0m\u001b[1;31m:\u001b[0m The number of classes has to be greater than one; got 1 class\n",
      "\n",
      "Use %tb to get the full traceback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".button {\n",
       "  border: none;\n",
       "  color: white;\n",
       "  padding: 4px 8px;\n",
       "  text-align: center;\n",
       "  text-decoration: none;\n",
       "  display: inline-block;\n",
       "  font-size: 12px;\n",
       "  margin: 4px 2px;\n",
       "  transition-duration: 0.2s;\n",
       "  cursor: pointer;\n",
       "}\n",
       ".iqx-button {\n",
       "  background-color: #0f62fe; \n",
       "  color: white; \n",
       "}\n",
       ".iqx-button:hover {\n",
       "  background-color: #0043ce;\n",
       "  color: white;\n",
       "}\n",
       "</style>\n",
       "<a href=\"https://stackoverflow.com/search?q=ValueError: The number of classes has to be greater than one; got 1 class\" target='_blank'><button class='button iqx-button'>Search for solution online</button></a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svc_acc = []\n",
    "svc_bacc = []\n",
    "svc_f1_score = []\n",
    "total_time_elapsed = 0\n",
    "\n",
    "for current_iter in range(NUM_OF_EXPERIMENTS):\n",
    "\n",
    "    print(f\"Current experiment no: {current_iter+1}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = data[current_iter][0], data[current_iter][1], data[current_iter][2], data[current_iter][3]\n",
    "\n",
    "    accuracy_svm, balanced_accuracy_svm, classical_f1_score = find_classical_accuracy(X_train, X_test, y_train, y_test)\n",
    "    svc_acc.append(accuracy_svm)\n",
    "    svc_bacc.append(balanced_accuracy_svm)\n",
    "    svc_f1_score.append(classical_f1_score)\n",
    "\n",
    "    print(f\"Accuracy, Balanced Accuracy and F1 Score Classical SVM: {accuracy_svm}, {balanced_accuracy_svm}, {classical_f1_score}\")\n",
    "\n",
    "    print(f\"-------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nj9AApQhio6B",
    "outputId": "0d736e1d-481b-4a2d-d3f1-48d44574b4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.975, 1.0, 0.95, 1.0, 0.95, 0.975, 0.95, 0.975, 1.0, 0.975, 0.95, 1.0, 0.975, 0.975, 0.975, 0.975, 1.0, 1.0, 0.975, 0.975, 1.0, 0.975, 0.95, 1.0, 0.95, 0.975, 0.975, 0.95, 0.975, 1.0, 0.95, 1.0, 1.0, 0.95, 0.975, 1.0, 0.925, 0.975, 1.0, 0.975, 0.925, 1.0, 0.975, 0.925, 0.975, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 0.975]\n",
      "For Classical SVM:\n",
      "Mean Accuracy:        0.9769230769230769\n",
      "Standard deviation:   0.021841955176154903\n",
      "Minimum Accuracy:     0.925\n",
      "Maximum Accuracy:     1.0\n"
     ]
    }
   ],
   "source": [
    "print(svc_acc)\n",
    "print(\"For Classical SVM:\")\n",
    "print(\"Mean Accuracy:       \", np.array(svc_acc).mean())\n",
    "print(\"Standard deviation:  \", np.array(svc_acc).std())\n",
    "print(\"Minimum Accuracy:    \", np.array(svc_acc).min())\n",
    "print(\"Maximum Accuracy:    \", np.array(svc_acc).max())\n",
    "svc_avg = np.array(svc_acc).mean()\n",
    "svc_min = np.array(svc_acc).min()\n",
    "svc_max = np.array(svc_acc).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "kYCBS069itLI",
    "outputId": "391029d6-cefa-44db-ceee-67d01fafe300"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_acc))\n",
    "plt.title('Accuracy Distribution for Classical SVM')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJWJpCjtiyMI",
    "outputId": "f3a189d3-e155-45cc-947f-d609c594e25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5]\n",
      "For Classical SVM:\n",
      "Mean Balanced Accuracy:        0.6826923076923077\n",
      "Standard deviation:   0.24076892356824833\n",
      "Minimum Balanced Accuracy:     0.5\n",
      "Maximum Balanced Accuracy:     1.0\n"
     ]
    }
   ],
   "source": [
    "print(svc_bacc)\n",
    "print(\"For Classical SVM:\")\n",
    "print(\"Mean Balanced Accuracy:       \", np.array(svc_bacc).mean())\n",
    "print(\"Standard deviation:  \", np.array(svc_bacc).std())\n",
    "print(\"Minimum Balanced Accuracy:    \", np.array(svc_bacc).min())\n",
    "print(\"Maximum Balanced Accuracy:    \", np.array(svc_bacc).max())\n",
    "svc_avg = np.array(svc_bacc).mean()\n",
    "svc_min = np.array(svc_bacc).min()\n",
    "svc_max = np.array(svc_bacc).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "nJ2UZkGmi1XH",
    "outputId": "cdfbfd62-2347-4b26-e849-1428bda2a8ba"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_bacc))\n",
    "plt.title('Balanced Accuracy Distribution for Classical SVM')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOtM6HHhi9OP",
    "outputId": "1fba9002-f1aa-42b4-a507-ed4ac4da83ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment no: 1\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.48717948717948717, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 2\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 3\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 4\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.95, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 5\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.4868421052631579, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 6\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.9743589743589743, 0.5\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 7\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.75, 0.6666666666666666\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 8\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.48717948717948717, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 9\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 10\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 11\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.75, 0.6666666666666666\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 12\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 13\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 14\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.48717948717948717, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 15\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.48717948717948717, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 16\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.48717948717948717, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 17\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 18\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 19\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 20\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.47435897435897434, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 21\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 22\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 23\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 1.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 24\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 25\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.75, 0.6666666666666666\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 26\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.47435897435897434, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 27\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.47435897435897434, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 28\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.75, 0.6666666666666666\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 29\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.48717948717948717, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 30\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.95, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 31\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.875, 0.4605263157894737, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 32\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 33\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 34\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 35\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.47435897435897434, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 36\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 37\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 38\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 39\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 40\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.9743589743589743, 0.5\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 41\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.6666666666666666, 0.5\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 42\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 43\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.9, 0.46153846153846156, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 44\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 45\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.875, 0.44871794871794873, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 46\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 47\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 48\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 49\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 50\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 51\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.925, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 52\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 54\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 55\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 56\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 57\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 58\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.48717948717948717, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 59\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 60\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 61\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.95, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 62\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 63\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 64\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.95, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 65\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.875, 0.44871794871794873, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 66\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.9, 0.46153846153846156, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 67\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 68\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 69\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 70\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 71\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 72\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 73\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 74\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 75\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.95, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 76\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.95, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 77\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 78\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.47435897435897434, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 79\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 80\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 81\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.6666666666666666, 0.5\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 82\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 83\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 84\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 85\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.875, 0.47297297297297297, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 86\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.9, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 87\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 88\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.4868421052631579, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 89\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.4868421052631579, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 90\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.47435897435897434, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 91\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.95, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 92\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 93\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 94\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 95\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 96\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.48717948717948717, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 97\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 1.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 98\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.47435897435897434, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 99\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 1.0\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Current experiment no: 100\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "svc_acc_dt = []\n",
    "svc_bacc_dt = []\n",
    "svc_f1_score_dt = []\n",
    "\n",
    "for current_iter in range(NUM_OF_EXPERIMENTS):\n",
    "\n",
    "    print(f\"Current experiment no: {current_iter+1}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = data[current_iter][0], data[current_iter][1], data[current_iter][2], data[current_iter][3]\n",
    "\n",
    "    accuracy_svm, balanced_accuracy_svm, classical_f1_score = find_classical_accuracy_dt(X_train, X_test, y_train, y_test)\n",
    "    svc_acc_dt.append(accuracy_svm)\n",
    "    svc_bacc_dt.append(balanced_accuracy_svm)\n",
    "    svc_f1_score_dt.append(classical_f1_score)\n",
    "\n",
    "    print(f\"Accuracy, Balanced Accuracy and F1 Score Classical SVM: {accuracy_svm}, {balanced_accuracy_svm}, {classical_f1_score}\")\n",
    "\n",
    "    print(f\"-----------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O73rIwZFjH_Q",
    "outputId": "4de398ad-69d1-4dcf-9b0e-d96567252415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95, 1.0, 0.95, 0.95, 0.925, 0.95, 0.975, 0.95, 1.0, 0.975, 0.975, 0.975, 0.975, 0.95, 0.95, 0.95, 0.975, 1.0, 0.975, 0.925, 1.0, 0.975, 1.0, 1.0, 0.975, 0.925, 0.925, 0.975, 0.95, 0.95, 0.875, 1.0, 0.975, 0.95, 0.925, 1.0, 0.925, 0.975, 1.0, 0.95, 0.95, 0.975, 0.9, 0.925, 0.875, 0.975, 1.0, 0.975, 0.975, 0.975, 0.925, 0.975, 1.0, 0.975, 0.95, 1.0, 0.975, 0.95, 1.0, 1.0, 0.95, 1.0, 0.975, 0.95, 0.875, 0.9, 1.0, 1.0, 1.0, 0.975, 0.975, 0.975, 0.975, 1.0, 0.95, 0.95, 1.0, 0.925, 0.975, 0.975, 0.95, 0.925, 1.0, 1.0, 0.875, 0.9, 0.975, 0.925, 0.925, 0.925, 0.95, 0.975, 0.975, 0.975, 1.0, 0.95, 1.0, 0.925, 1.0, 0.975]\n",
      "For Classical Decision Tree:\n",
      "Mean Accuracy:        0.9624999999999999\n",
      "Standard deviation:   0.032499999999999994\n",
      "Minimum Accuracy:     0.875\n",
      "Maximum Accuracy:     1.0\n"
     ]
    }
   ],
   "source": [
    "print(svc_acc_dt)\n",
    "print(\"For Classical Decision Tree:\")\n",
    "print(\"Mean Accuracy:       \", np.array(svc_acc_dt).mean())\n",
    "print(\"Standard deviation:  \", np.array(svc_acc_dt).std())\n",
    "print(\"Minimum Accuracy:    \", np.array(svc_acc_dt).min())\n",
    "print(\"Maximum Accuracy:    \", np.array(svc_acc_dt).max())\n",
    "svc_avg = np.array(svc_acc_dt).mean()\n",
    "svc_min = np.array(svc_acc_dt).min()\n",
    "svc_max = np.array(svc_acc_dt).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "6owOGASMwkHP",
    "outputId": "948e8e0d-12fd-4df2-9e78-7135009a247d"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_acc_dt))\n",
    "plt.title('Accuracy Distribution for Classical Decision Tree')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "kzwIgVnWwp55",
    "outputId": "9fbf5fcc-498e-47ae-f4d6-8ab7fbab365f"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_bacc_dt))\n",
    "plt.title('Balanced Accuracy Distribution for Classical Decision Tree')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dehVuCKSwvKL",
    "outputId": "3c0e04a0-51b1-44f4-991f-d4250e2e1b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment no: 1\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 3\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 5\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 6\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.9871794871794872, 0.6666666666666666\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 7\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.75, 0.6666666666666666\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 8\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 9\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 11\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 13\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 14\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 15\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 16\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 17\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 19\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 20\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 21\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 23\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.75, 0.6666666666666666\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 25\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 26\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 27\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 28\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 29\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.48717948717948717, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 31\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 33\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 34\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 35\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 37\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 38\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 39\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 41\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 43\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 44\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 45\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 47\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 49\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 51\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 52\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 53\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 55\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 57\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 58\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 59\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 61\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 63\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 65\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 66\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 67\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 69\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 71\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 73\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 75\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 77\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 78\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 79\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 81\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.6666666666666666, 0.5\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 82\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 83\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 85\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 86\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.9, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 87\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 89\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.95, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 90\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.925, 0.47435897435897434, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 91\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 93\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.975, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 95\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 97\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 1.0, 1.0, 1.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 98\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 99\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n",
      "Current experiment no: 100\n",
      "Accuracy, Balanced Accuracy and F1 Score Classical SVM: 0.975, 0.5, 0.0\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "svc_acc_rf = []\n",
    "svc_bacc_rf = []\n",
    "svc_f1_score_rf = []\n",
    "total_time_elapsed = 0\n",
    "\n",
    "for current_iter in range(NUM_OF_EXPERIMENTS):\n",
    "\n",
    "    print(f\"Current experiment no: {current_iter+1}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = data[current_iter][0], data[current_iter][1], data[current_iter][2], data[current_iter][3]\n",
    "\n",
    "    accuracy_svm, balanced_accuracy_svm, classical_f1_score = find_classical_accuracy_rf(X_train, X_test, y_train, y_test)\n",
    "    svc_acc_rf.append(accuracy_svm)\n",
    "    svc_bacc_rf.append(balanced_accuracy_svm)\n",
    "    svc_f1_score_rf.append(classical_f1_score)\n",
    "\n",
    "    print(f\"Accuracy, Balanced Accuracy and F1 Score Classical SVM: {accuracy_svm}, {balanced_accuracy_svm}, {classical_f1_score}\")\n",
    "\n",
    "    print(f\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIzQLAG9w0u7",
    "outputId": "1c532a76-707f-40f7-c9b2-1dd8a58fbf4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.975, 1.0, 0.95, 1.0, 0.95, 0.975, 0.975, 0.975, 1.0, 0.975, 0.95, 0.975, 0.975, 0.975, 0.975, 0.975, 1.0, 1.0, 0.975, 0.975, 1.0, 0.975, 0.975, 1.0, 0.95, 0.975, 0.975, 0.95, 0.95, 1.0, 0.95, 1.0, 1.0, 0.95, 0.975, 1.0, 0.925, 0.975, 1.0, 0.975, 0.925, 1.0, 0.975, 0.925, 0.975, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 0.95, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 0.95, 0.925, 1.0, 1.0, 0.925, 0.9, 1.0, 0.95, 0.95, 0.925, 1.0, 0.975, 1.0, 0.975, 1.0, 0.975, 1.0, 0.975, 0.975, 0.975]\n",
      "For Classical SVM:\n",
      "Mean Accuracy:        0.9794999999999999\n",
      "Standard deviation:   0.02328626204439004\n",
      "Minimum Accuracy:     0.9\n",
      "Maximum Accuracy:     1.0\n"
     ]
    }
   ],
   "source": [
    "print(svc_acc_rf)\n",
    "print(\"For Classical SVM:\")\n",
    "print(\"Mean Accuracy:       \", np.array(svc_acc_rf).mean())\n",
    "print(\"Standard deviation:  \", np.array(svc_acc_rf).std())\n",
    "print(\"Minimum Accuracy:    \", np.array(svc_acc_rf).min())\n",
    "print(\"Maximum Accuracy:    \", np.array(svc_acc_rf).max())\n",
    "svc_avg = np.array(svc_acc_rf).mean()\n",
    "svc_min = np.array(svc_acc_rf).min()\n",
    "svc_max = np.array(svc_acc_rf).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "euxLUiuEw6pd",
    "outputId": "4b595422-a9de-44fb-e133-660de91d8f08"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_acc_rf))\n",
    "plt.title('Accuracy Distribution for Classical Random Forest')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRsn399ZxANx",
    "outputId": "3100bfce-6a9a-431b-9de4-d0663aadf5eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 1.0, 0.5, 1.0, 0.5, 0.9871794871794872, 0.75, 0.5, 1.0, 0.5, 0.5, 0.975, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.75, 1.0, 0.5, 0.5, 0.5, 0.5, 0.48717948717948717, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.975, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 0.47435897435897434, 1.0, 0.5, 1.0, 0.975, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5]\n",
      "For Classical Random Forest:\n",
      "Mean Balanced Accuracy:        0.7504038461538463\n",
      "Standard deviation:   0.24591888584220706\n",
      "Minimum Balanced Accuracy:     0.47435897435897434\n",
      "Maximum Balanced Accuracy:     1.0\n"
     ]
    }
   ],
   "source": [
    "print(svc_bacc_rf)\n",
    "print(\"For Classical Random Forest:\")\n",
    "print(\"Mean Balanced Accuracy:       \", np.array(svc_bacc_rf).mean())\n",
    "print(\"Standard deviation:  \", np.array(svc_bacc_rf).std())\n",
    "print(\"Minimum Balanced Accuracy:    \", np.array(svc_bacc_rf).min())\n",
    "print(\"Maximum Balanced Accuracy:    \", np.array(svc_bacc_rf).max())\n",
    "svc_avg = np.array(svc_bacc_rf).mean()\n",
    "svc_min = np.array(svc_bacc_rf).min()\n",
    "svc_max = np.array(svc_bacc_rf).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Yh6SB2eXxEJb",
    "outputId": "a04fd032-df28-4824-ba5f-e9042639a0f1"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_bacc_rf))\n",
    "plt.title('Balanced Accuracy Distribution for Random Forest')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "aZym3oPwxKO1"
   },
   "outputs": [],
   "source": [
    "def find_closest_to_mean(arr):\n",
    "    mean = sum(arr) / len(arr)  # Calculate mean of the list\n",
    "\n",
    "    # Calculate the differences between each element and the mean, and store them in a tuple with their index\n",
    "    diff_indices = [(abs(x - mean), i) for i, x in enumerate(arr)]\n",
    "\n",
    "    # Sort the tuple by the difference values\n",
    "    sorted_diff_indices = sorted(diff_indices)\n",
    "\n",
    "    # Extract the indices of the two closest values\n",
    "    index1 = sorted_diff_indices[0][1]\n",
    "    index2 = sorted_diff_indices[1][1]\n",
    "    return [index1, index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "gZVIthWhxPk7"
   },
   "outputs": [],
   "source": [
    "def find_closest_to_max(arr):\n",
    "    max_val = max(arr)  # Calculate max of the list\n",
    "\n",
    "    # Calculate the differences between each element and the max, and store them in a tuple with their index\n",
    "    diff_indices = [(abs(x - max_val), i) for i, x in enumerate(arr)]\n",
    "\n",
    "    # Sort the tuple by the difference values\n",
    "    sorted_diff_indices = sorted(diff_indices)\n",
    "\n",
    "    # Extract the indices of the two closest values\n",
    "    index1 = sorted_diff_indices[0][1]\n",
    "    index2 = sorted_diff_indices[1][1]\n",
    "    return [index1, index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "LU3b0YK4xSxR"
   },
   "outputs": [],
   "source": [
    "def find_closest_to_min(arr):\n",
    "    min_val = min(arr)  # Calculate min of the list\n",
    "\n",
    "    # Calculate the differences between each element and the min, and store them in a tuple with their index\n",
    "    diff_indices = [(abs(x - min_val), i) for i, x in enumerate(arr)]\n",
    "\n",
    "    # Sort the tuple by the difference values\n",
    "    sorted_diff_indices = sorted(diff_indices)\n",
    "\n",
    "    # Extract the indices of the two closest values\n",
    "    index1 = sorted_diff_indices[0][1]\n",
    "    index2 = sorted_diff_indices[1][1]\n",
    "    return [index1, index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "7ymk8wIsxXWS"
   },
   "outputs": [],
   "source": [
    "fm_list = []\n",
    "names_fm = []\n",
    "def create_feature_maps(features_):\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Z'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Z')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['ZZ'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('ZZ')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['YY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('YY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Z', 'ZZ'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Z ZZ')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Y', 'YY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Y YY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['X', 'YY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('X YY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Z', 'YY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Z YY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Y', 'XY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Y XY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['X', 'XY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('X XY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Z', 'XY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Z XY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "b4ddIA3xxZ9a"
   },
   "outputs": [],
   "source": [
    "create_feature_maps(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement quantum-utils (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for quantum-utils\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install quantum-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Beq3niIQxfJy"
   },
   "outputs": [],
   "source": [
    "def train_and_fit_model(x_train_, x_test_, y_train_, y_test_, fm_):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Building Kernel\n",
    "    dse_feature_map = fm_\n",
    "\n",
    "    dse_backend = QuantumInstance(\n",
    "        Aer.get_backend('qasm_simulator'), shots=1024, seed_simulator=12345, seed_transpiler=12345\n",
    "    )\n",
    "\n",
    "    dse_kernel = QuantumKernel(feature_map=dse_feature_map, quantum_instance=dse_backend)\n",
    "    qsvc = QSVC(quantum_kernel=dse_kernel)\n",
    "    qsvc.fit(x_train_, y_train_)\n",
    "\n",
    "    # Predict the labels\n",
    "    labels_test = qsvc.predict(x_test_)\n",
    "\n",
    "    accuracy_test = metrics.accuracy_score(y_true=y_test_, y_pred=labels_test)\n",
    "    ba_score = metrics.balanced_accuracy_score(y_true=y_test_, y_pred=labels_test)\n",
    "    q_f1_score = f1_score(y_test_, labels_test)\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    return accuracy_test, ba_score, q_f1_score, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_f5xjvOx0tb",
    "outputId": "712c98f8-5e7b-4327-eb00-4714df9aaf74"
   },
   "outputs": [],
   "source": [
    "! pip install qiskit-aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.utils import QuantumInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "od4Vq9rTxn7U",
    "outputId": "f4669b59-26fc-47c0-8842-78661d74a847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Mean Performance: \n",
      "[0, 2]\n",
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[34], line 14\u001b[0m\n",
      "    acc, bacc, f1, elapsed = train_and_fit_model(X_train, X_test, y_train, y_test, fm)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[33], line 8\u001b[1;36m in \u001b[1;35mtrain_and_fit_model\u001b[1;36m\n",
      "\u001b[1;33m    dse_backend = QuantumInstance(\u001b[1;36m\n",
      "\u001b[1;31mNameError\u001b[0m\u001b[1;31m:\u001b[0m name 'QuantumInstance' is not defined\n",
      "\n",
      "Use %tb to get the full traceback.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".button {\n",
       "  border: none;\n",
       "  color: white;\n",
       "  padding: 4px 8px;\n",
       "  text-align: center;\n",
       "  text-decoration: none;\n",
       "  display: inline-block;\n",
       "  font-size: 12px;\n",
       "  margin: 4px 2px;\n",
       "  transition-duration: 0.2s;\n",
       "  cursor: pointer;\n",
       "}\n",
       ".iqx-button {\n",
       "  background-color: #0f62fe; \n",
       "  color: white; \n",
       "}\n",
       ".iqx-button:hover {\n",
       "  background-color: #0043ce;\n",
       "  color: white;\n",
       "}\n",
       "</style>\n",
       "<a href=\"https://stackoverflow.com/search?q=NameError: name 'QuantumInstance' is not defined\" target='_blank'><button class='button iqx-button'>Search for solution online</button></a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"For Mean Performance: \")\n",
    "indices_mean = find_closest_to_mean(svc_bacc)\n",
    "print(indices_mean)\n",
    "\n",
    "q_ba, q_a, q_f1 = [], [], []\n",
    "svc_ba, svc_a, svc_f1 = [], [], []\n",
    "dt_ba, dt_a, dt_f1 = [], [], []\n",
    "rf_ba, rf_a, rf_f1 = [], [], []\n",
    "\n",
    "for fm in fm_list:\n",
    "    qba, qa, qf = [], [], []\n",
    "    for idx in indices_mean:\n",
    "        X_train, X_test, y_train, y_test = data[idx]\n",
    "        acc, bacc, f1, elapsed = train_and_fit_model(X_train, X_test, y_train, y_test, fm)\n",
    "        print(f\"Accuracy, Balanced Accuracy, F1 Score, Elapsed Time: {acc}, {bacc}, {f1}, {elapsed}\")\n",
    "        qba.append(bacc)\n",
    "        qa.append(acc)\n",
    "        qf.append(f1)\n",
    "    q_ba.append(qba)\n",
    "    q_a.append(qa)\n",
    "    q_f1.append(qf)\n",
    "    svc_ba.append(svc_bacc[idx])\n",
    "    svc_a.append(svc_acc[idx])\n",
    "    svc_f1.append(svc_f1_score[idx])\n",
    "    dt_ba.append(svc_bacc_dt[idx])\n",
    "    dt_a.append(svc_acc_dt[idx])\n",
    "    dt_f1.append(svc_f1_score_dt[idx])\n",
    "    rf_ba.append(svc_bacc_rf[idx])\n",
    "    rf_a.append(svc_acc_rf[idx])\n",
    "    rf_f1.append(svc_f1_score_rf[idx])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Averge Balanced Accuracy for SVM: {sum(svc_ba)/len(svc_ba)}\")\n",
    "print(f\"Average Accuracy for SVM: {sum(svc_a)/len(svc_a)}\")\n",
    "print(f\"Average F1 Score for SVM: {sum(svc_f1)/len(svc_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Decision Tree: {sum(dt_ba)/len(dt_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Decision Tree: {sum(dt_a)/len(dt_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Decision Tree: {sum(dt_f1)/len(dt_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Random Forest: {sum(rf_ba)/len(rf_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Random Forest: {sum(rf_a)/len(rf_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Random Forest: {sum(rf_f1)/len(rf_f1)}\")\n",
    "print(\"\\n\");\n",
    "for i in range(len(fm_list)):\n",
    "    print(f\"Averge Balanced Accuracy for Pauli {names_fm[i]}: {sum(q_ba[i])/len(q_ba[i])}\")\n",
    "    print(f\"Average Accuracy for Pauli {names_fm[i]}: {sum(q_a[i])/len(q_a[i])}\")\n",
    "    print(f\"Average F1 Score for Pauli {names_fm[i]}: {sum(q_f1[i])/len(q_f1[i])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Oishik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "atCc8cIkypnU",
    "outputId": "378364da-3f0b-4075-f229-3b3c7fd4b1f2"
   },
   "outputs": [],
   "source": [
    "print(\"For Min Performance \")\n",
    "indices_min = find_closest_to_min(svc_bacc)\n",
    "print(indices_min)\n",
    "\n",
    "q_ba, q_a, q_f1 = [], [], []\n",
    "svc_ba, svc_a, svc_f1 = [], [], []\n",
    "dt_ba, dt_a, dt_f1 = [], [], []\n",
    "rf_ba, rf_a, rf_f1 = [], [], []\n",
    "\n",
    "for fm in fm_list:\n",
    "    qba, qa, qf = [], [], []\n",
    "    for idx in indices_min:\n",
    "        X_train, X_test, y_train, y_test = data[idx]\n",
    "        acc, bacc, f1, elapsed = train_and_fit_model(X_train, X_test, y_train, y_test, fm)\n",
    "        print(f\"Accuracy, Balanced Accuracy, F1 Score, Elapsed Time: {acc}, {bacc}, {f1}, {elapsed}\")\n",
    "        qba.append(bacc)\n",
    "        qa.append(acc)\n",
    "        qf.append(f1)\n",
    "    q_ba.append(qba)\n",
    "    q_a.append(qa)\n",
    "    q_f1.append(qf)\n",
    "    svc_ba.append(svc_bacc[idx])\n",
    "    svc_a.append(svc_acc[idx])\n",
    "    svc_f1.append(svc_f1_score[idx])\n",
    "    dt_ba.append(svc_bacc_dt[idx])\n",
    "    dt_a.append(svc_acc_dt[idx])\n",
    "    dt_f1.append(svc_f1_score_dt[idx])\n",
    "    rf_ba.append(svc_bacc_rf[idx])\n",
    "    rf_a.append(svc_acc_rf[idx])\n",
    "    rf_f1.append(svc_f1_score_rf[idx])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Averge Balanced Accuracy for SVM: {sum(svc_ba)/len(svc_ba)}\")\n",
    "print(f\"Average Accuracy for SVM: {sum(svc_a)/len(svc_a)}\")\n",
    "print(f\"Average F1 Score for SVM: {sum(svc_f1)/len(svc_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Decision Tree: {sum(dt_ba)/len(dt_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Decision Tree: {sum(dt_a)/len(dt_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Decision Tree: {sum(dt_f1)/len(dt_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Random Forest: {sum(rf_ba)/len(rf_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Random Forest: {sum(rf_a)/len(rf_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Random Forest: {sum(rf_f1)/len(rf_f1)}\")\n",
    "print(\"\\n\");\n",
    "for i in range(len(fm_list)):\n",
    "    print(f\"Averge Balanced Accuracy for Pauli {names_fm[i]}: {sum(q_ba[i])/len(q_ba[i])}\")\n",
    "    print(f\"Average Accuracy for Pauli {names_fm[i]}: {sum(q_a[i])/len(q_a[i])}\")\n",
    "    print(f\"Average F1 Score for Pauli {names_fm[i]}: {sum(q_f1[i])/len(q_f1[i])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"For Max Performance \")\n",
    "indices_max = find_closest_to_max(svc_bacc)\n",
    "print(indices_max)\n",
    "\n",
    "q_ba, q_a, q_f1 = [], [], []\n",
    "svc_ba, svc_a, svc_f1 = [], [], []\n",
    "dt_ba, dt_a, dt_f1 = [], [], []\n",
    "rf_ba, rf_a, rf_f1 = [], [], []\n",
    "\n",
    "for fm in fm_list:\n",
    "    qba, qa, qf = [], [], []\n",
    "    for idx in indices_max:\n",
    "        X_train, X_test, y_train, y_test = data[idx]\n",
    "        acc, bacc, f1, elapsed = train_and_fit_model(X_train, X_test, y_train, y_test, fm)\n",
    "        print(f\"Accuracy, Balanced Accuracy, F1 Score, Elapsed Time: {acc}, {bacc}, {f1}, {elapsed}\")\n",
    "        qba.append(bacc)\n",
    "        qa.append(acc)\n",
    "        qf.append(f1)\n",
    "    q_ba.append(qba)\n",
    "    q_a.append(qa)\n",
    "    q_f1.append(qf)\n",
    "    svc_ba.append(svc_bacc[idx])\n",
    "    svc_a.append(svc_acc[idx])\n",
    "    svc_f1.append(svc_f1_score[idx])\n",
    "    dt_ba.append(svc_bacc_dt[idx])\n",
    "    dt_a.append(svc_acc_dt[idx])\n",
    "    dt_f1.append(svc_f1_score_dt[idx])\n",
    "    rf_ba.append(svc_bacc_rf[idx])\n",
    "    rf_a.append(svc_acc_rf[idx])\n",
    "    rf_f1.append(svc_f1_score_rf[idx])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Averge Balanced Accuracy for SVM: {sum(svc_ba)/len(svc_ba)}\")\n",
    "print(f\"Average Accuracy for SVM: {sum(svc_a)/len(svc_a)}\")\n",
    "print(f\"Average F1 Score for SVM: {sum(svc_f1)/len(svc_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Decision Tree: {sum(dt_ba)/len(dt_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Decision Tree: {sum(dt_a)/len(dt_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Decision Tree: {sum(dt_f1)/len(dt_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Random Forest: {sum(rf_ba)/len(rf_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Random Forest: {sum(rf_a)/len(rf_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Random Forest: {sum(rf_f1)/len(rf_f1)}\")\n",
    "print(\"\\n\");\n",
    "for i in range(len(fm_list)):\n",
    "    print(f\"Averge Balanced Accuracy for Pauli {names_fm[i]}: {sum(q_ba[i])/len(q_ba[i])}\")\n",
    "    print(f\"Average Accuracy for Pauli {names_fm[i]}: {sum(q_a[i])/len(q_a[i])}\")\n",
    "    print(f\"Average F1 Score for Pauli {names_fm[i]}: {sum(q_f1[i])/len(q_f1[i])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Qiskit v1.0.1 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
