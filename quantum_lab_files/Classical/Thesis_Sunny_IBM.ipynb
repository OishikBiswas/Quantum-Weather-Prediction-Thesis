{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLLBQSi2e2vn",
    "outputId": "f1c71978-e425-4ce8-bb75-ec190df862d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit in /opt/conda/lib/python3.10/site-packages (0.45.3)\n",
      "Requirement already satisfied: qiskit-terra==0.45.3 in /opt/conda/lib/python3.10/site-packages (from qiskit) (0.45.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (2.8.2)\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (1.11.1)\n",
      "Requirement already satisfied: dill>=0.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (0.3.7)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (4.1.1)\n",
      "Requirement already satisfied: symengine!=0.10.0,>=0.9 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (0.9.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (4.9.0)\n",
      "Requirement already satisfied: numpy<2,>=1.17 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (1.23.5)\n",
      "Requirement already satisfied: ply>=3.10 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (3.11)\n",
      "Requirement already satisfied: rustworkx>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (0.13.0)\n",
      "Requirement already satisfied: psutil>=5 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (5.9.4)\n",
      "Requirement already satisfied: scipy>=1.5 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.3->qiskit) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.0->qiskit-terra==0.45.3->qiskit) (1.16.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from stevedore>=3.0.0->qiskit-terra==0.45.3->qiskit) (5.11.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.3->qiskit-terra==0.45.3->qiskit) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwIBVfBNfRq_",
    "outputId": "7312597e-eecf-4398-9751-4e07ec570ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit-machine-learning in /opt/conda/lib/python3.10/site-packages (0.6.1)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (65.5.1)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (0.3.7)\n",
      "Requirement already satisfied: scipy>=1.4 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (1.9.3)\n",
      "Requirement already satisfied: qiskit-terra>=0.22.2 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (0.45.3)\n",
      "Requirement already satisfied: fastdtw in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (0.3.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (1.23.5)\n",
      "Requirement already satisfied: psutil>=5 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (5.9.4)\n",
      "Requirement already satisfied: symengine!=0.10.0,>=0.9 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.22.2->qiskit-machine-learning) (0.9.2)\n",
      "Requirement already satisfied: ply>=3.10 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.22.2->qiskit-machine-learning) (3.11)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.22.2->qiskit-machine-learning) (4.9.0)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.22.2->qiskit-machine-learning) (4.1.1)\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.22.2->qiskit-machine-learning) (1.11.1)\n",
      "Requirement already satisfied: rustworkx>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.22.2->qiskit-machine-learning) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.22.2->qiskit-machine-learning) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->qiskit-machine-learning) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->qiskit-machine-learning) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.0->qiskit-terra>=0.22.2->qiskit-machine-learning) (1.16.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from stevedore>=3.0.0->qiskit-terra>=0.22.2->qiskit-machine-learning) (5.11.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.3->qiskit-terra>=0.22.2->qiskit-machine-learning) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install qiskit-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dItaSY4Teu1F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295/3445415176.py:21: DeprecationWarning: ``qiskit.algorithms`` has been migrated to an independent package: https://github.com/qiskit-community/qiskit-algorithms. The ``qiskit.algorithms`` import path is deprecated as of qiskit-terra 0.25.0 and will be removed no earlier than 3 months after the release date. Please run ``pip install qiskit_algorithms`` and use ``import qiskit_algorithms`` instead.\n",
      "  from qiskit.algorithms.optimizers import SPSA\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from qiskit import *\n",
    "\n",
    "# External imports\n",
    "from pylab import cm\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.visualization import circuit_drawer\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "\n",
    "from qiskit.circuit.library import PauliFeatureMap\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_machine_learning.kernels import TrainableFidelityQuantumKernel\n",
    "from qiskit_machine_learning.kernels.algorithms import QuantumKernelTrainer\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-JVSWhbye8R5",
    "outputId": "224bc1f0-8ff4-4da8-fb90-c1a3695d4045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[4], line 1\u001b[0m\n",
      "    df = pd.read_csv('Thesis Android US Dataset.csv')\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m in \u001b[0;35mwrapper\u001b[0m\n",
      "    return func(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m in \u001b[0;35mwrapper\u001b[0m\n",
      "    return func(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m in \u001b[0;35mread_csv\u001b[0m\n",
      "    return _read(filepath_or_buffer, kwds)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m in \u001b[0;35m_read\u001b[0m\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m in \u001b[0;35m__init__\u001b[0m\n",
      "    self._engine = self._make_engine(f, self.engine)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m in \u001b[0;35m_make_engine\u001b[0m\n",
      "    self.handles = get_handle(\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[1;36m in \u001b[1;35mget_handle\u001b[1;36m\n",
      "\u001b[1;33m    handle = open(\u001b[1;36m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m\u001b[1;31m:\u001b[0m [Errno 2] No such file or directory: 'Thesis Android US Dataset.csv'\n",
      "\n",
      "Use %tb to get the full traceback.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".button {\n",
       "  border: none;\n",
       "  color: white;\n",
       "  padding: 4px 8px;\n",
       "  text-align: center;\n",
       "  text-decoration: none;\n",
       "  display: inline-block;\n",
       "  font-size: 12px;\n",
       "  margin: 4px 2px;\n",
       "  transition-duration: 0.2s;\n",
       "  cursor: pointer;\n",
       "}\n",
       ".iqx-button {\n",
       "  background-color: #0f62fe; \n",
       "  color: white; \n",
       "}\n",
       ".iqx-button:hover {\n",
       "  background-color: #0043ce;\n",
       "  color: white;\n",
       "}\n",
       "</style>\n",
       "<a href=\"https://stackoverflow.com/search?q=FileNotFoundError: 2\" target='_blank'><button class='button iqx-button'>Search for solution online</button></a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('Thesis Android US Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "OKXRX6J6frL5",
    "outputId": "0f4ef2d7-9af0-448d-901f-4700c1b493a7"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Date'], inplace=True)\n",
    "#df.drop(columns=['Temperature(C)'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "T8soGqnIhlSy",
    "outputId": "e79fee2a-3a58-4384-bb9d-d580c1bddc82"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Time', 'State','Real State'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df2 = df.copy()\n",
    "df3 = df.copy()\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1.drop(columns=[ 'Cloudy','Sunny'], inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.drop(columns=['Sunny'], inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqKlg1nCh8iD"
   },
   "outputs": [],
   "source": [
    "def create_training_and_testing_data_sub(df_, DATA_SIZE_):\n",
    "    data_size = DATA_SIZE_\n",
    "\n",
    "    indices = np.random.choice(df3.index, size=data_size, replace=False)\n",
    "    subset_df = df3.loc[indices]\n",
    "\n",
    "    print(indices)\n",
    "\n",
    "    # get the values from the last column of the subset and store them in y_subset\n",
    "    y_subset = subset_df['Sunny'].values\n",
    "\n",
    "    # get the values from all other columns of the subset and store them in X_subset\n",
    "    x_subset = subset_df.iloc[:, :-1].values\n",
    "\n",
    "    # spltting the dataset into train and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_subset, y_subset, test_size = 0.2, random_state = 31)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfWXYJs-h-Pv",
    "outputId": "1804803f-1aae-4ec4-ee46-427368d8dfe7"
   },
   "outputs": [],
   "source": [
    "NUM_OF_EXPERIMENTS = int(input(\"Number of experiments to run: \"))\n",
    "DATA_SIZE = int(input(\"Size of dataset: \"))\n",
    "NUM_MAX_ITER = int(input(\"Number of max iterations: \"))\n",
    "data = []\n",
    "\n",
    "for current_iter in range(NUM_OF_EXPERIMENTS):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = create_training_and_testing_data_sub(df, DATA_SIZE)\n",
    "\n",
    "    data.append([X_train, X_test, y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBoSvysDiOSJ"
   },
   "outputs": [],
   "source": [
    "def find_classical_accuracy(x_train_, x_test_, y_train_, y_test_):\n",
    "\n",
    "    svc_clf = svm.SVC(random_state = 7)\n",
    "    svc_clf.fit(x_train_, y_train_)\n",
    "    labels_pred = svc_clf.predict(x_test_)\n",
    "\n",
    "    svc_accuracy = accuracy_score(y_test_, labels_pred)\n",
    "    svc_score = metrics.balanced_accuracy_score(y_true=y_test_, y_pred=labels_pred)\n",
    "    svc_f1_score = f1_score(y_test_, labels_pred)\n",
    "\n",
    "    return svc_accuracy, svc_score, svc_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9aJdyT_iR1i"
   },
   "outputs": [],
   "source": [
    "def find_classical_accuracy_dt(x_train_, x_test_, y_train_, y_test_):\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(x_train_, y_train)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    labels_pred = clf.predict(x_test_)\n",
    "\n",
    "    svc_accuracy = accuracy_score(y_test_, labels_pred)\n",
    "    svc_score = metrics.balanced_accuracy_score(y_true=y_test_, y_pred=labels_pred)\n",
    "    svc_f1_score = f1_score(y_test_, labels_pred)\n",
    "\n",
    "    return svc_accuracy, svc_score, svc_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-zxXK6IiWpe"
   },
   "outputs": [],
   "source": [
    "def find_classical_accuracy_rf(x_train_, x_test_, y_train_, y_test_):\n",
    "    rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    labels_pred = rfc.predict(x_test_)\n",
    "\n",
    "    svc_accuracy = accuracy_score(y_test_, labels_pred)\n",
    "    svc_score = metrics.balanced_accuracy_score(y_true=y_test_, y_pred=labels_pred)\n",
    "    svc_f1_score = f1_score(y_test_, labels_pred)\n",
    "\n",
    "    return svc_accuracy, svc_score, svc_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brm0ZJDDicFe",
    "outputId": "c3682a5a-10c7-4b93-f5ce-cd0c15a32113"
   },
   "outputs": [],
   "source": [
    "svc_acc = []\n",
    "svc_bacc = []\n",
    "svc_f1_score = []\n",
    "total_time_elapsed = 0\n",
    "\n",
    "for current_iter in range(NUM_OF_EXPERIMENTS):\n",
    "\n",
    "    print(f\"Current experiment no: {current_iter+1}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = data[current_iter][0], data[current_iter][1], data[current_iter][2], data[current_iter][3]\n",
    "\n",
    "    accuracy_svm, balanced_accuracy_svm, classical_f1_score = find_classical_accuracy(X_train, X_test, y_train, y_test)\n",
    "    svc_acc.append(accuracy_svm)\n",
    "    svc_bacc.append(balanced_accuracy_svm)\n",
    "    svc_f1_score.append(classical_f1_score)\n",
    "\n",
    "    print(f\"Accuracy, Balanced Accuracy and F1 Score Classical SVM: {accuracy_svm}, {balanced_accuracy_svm}, {classical_f1_score}\")\n",
    "\n",
    "    print(f\"-------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nj9AApQhio6B",
    "outputId": "0d736e1d-481b-4a2d-d3f1-48d44574b4a7"
   },
   "outputs": [],
   "source": [
    "print(svc_acc)\n",
    "print(\"For Classical SVM:\")\n",
    "print(\"Mean Accuracy:       \", np.array(svc_acc).mean())\n",
    "print(\"Standard deviation:  \", np.array(svc_acc).std())\n",
    "print(\"Minimum Accuracy:    \", np.array(svc_acc).min())\n",
    "print(\"Maximum Accuracy:    \", np.array(svc_acc).max())\n",
    "svc_avg = np.array(svc_acc).mean()\n",
    "svc_min = np.array(svc_acc).min()\n",
    "svc_max = np.array(svc_acc).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "kYCBS069itLI",
    "outputId": "391029d6-cefa-44db-ceee-67d01fafe300"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_acc))\n",
    "plt.title('Accuracy Distribution for Classical SVM')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJWJpCjtiyMI",
    "outputId": "f3a189d3-e155-45cc-947f-d609c594e25c"
   },
   "outputs": [],
   "source": [
    "print(svc_bacc)\n",
    "print(\"For Classical SVM:\")\n",
    "print(\"Mean Balanced Accuracy:       \", np.array(svc_bacc).mean())\n",
    "print(\"Standard deviation:  \", np.array(svc_bacc).std())\n",
    "print(\"Minimum Balanced Accuracy:    \", np.array(svc_bacc).min())\n",
    "print(\"Maximum Balanced Accuracy:    \", np.array(svc_bacc).max())\n",
    "svc_avg = np.array(svc_bacc).mean()\n",
    "svc_min = np.array(svc_bacc).min()\n",
    "svc_max = np.array(svc_bacc).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "nJ2UZkGmi1XH",
    "outputId": "cdfbfd62-2347-4b26-e849-1428bda2a8ba"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_bacc))\n",
    "plt.title('Balanced Accuracy Distribution for Classical SVM')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOtM6HHhi9OP",
    "outputId": "1fba9002-f1aa-42b4-a507-ed4ac4da83ed"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "svc_acc_dt = []\n",
    "svc_bacc_dt = []\n",
    "svc_f1_score_dt = []\n",
    "\n",
    "for current_iter in range(NUM_OF_EXPERIMENTS):\n",
    "\n",
    "    print(f\"Current experiment no: {current_iter+1}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = data[current_iter][0], data[current_iter][1], data[current_iter][2], data[current_iter][3]\n",
    "\n",
    "    accuracy_svm, balanced_accuracy_svm, classical_f1_score = find_classical_accuracy_dt(X_train, X_test, y_train, y_test)\n",
    "    svc_acc_dt.append(accuracy_svm)\n",
    "    svc_bacc_dt.append(balanced_accuracy_svm)\n",
    "    svc_f1_score_dt.append(classical_f1_score)\n",
    "\n",
    "    print(f\"Accuracy, Balanced Accuracy and F1 Score Classical SVM: {accuracy_svm}, {balanced_accuracy_svm}, {classical_f1_score}\")\n",
    "\n",
    "    print(f\"-----------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O73rIwZFjH_Q",
    "outputId": "4de398ad-69d1-4dcf-9b0e-d96567252415"
   },
   "outputs": [],
   "source": [
    "print(svc_acc_dt)\n",
    "print(\"For Classical Decision Tree:\")\n",
    "print(\"Mean Accuracy:       \", np.array(svc_acc_dt).mean())\n",
    "print(\"Standard deviation:  \", np.array(svc_acc_dt).std())\n",
    "print(\"Minimum Accuracy:    \", np.array(svc_acc_dt).min())\n",
    "print(\"Maximum Accuracy:    \", np.array(svc_acc_dt).max())\n",
    "svc_avg = np.array(svc_acc_dt).mean()\n",
    "svc_min = np.array(svc_acc_dt).min()\n",
    "svc_max = np.array(svc_acc_dt).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "6owOGASMwkHP",
    "outputId": "948e8e0d-12fd-4df2-9e78-7135009a247d"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_acc_dt))\n",
    "plt.title('Accuracy Distribution for Classical Decision Tree')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "kzwIgVnWwp55",
    "outputId": "9fbf5fcc-498e-47ae-f4d6-8ab7fbab365f"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_bacc_dt))\n",
    "plt.title('Balanced Accuracy Distribution for Classical Decision Tree')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dehVuCKSwvKL",
    "outputId": "3c0e04a0-51b1-44f4-991f-d4250e2e1b2e"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "svc_acc_rf = []\n",
    "svc_bacc_rf = []\n",
    "svc_f1_score_rf = []\n",
    "total_time_elapsed = 0\n",
    "\n",
    "for current_iter in range(NUM_OF_EXPERIMENTS):\n",
    "\n",
    "    print(f\"Current experiment no: {current_iter+1}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = data[current_iter][0], data[current_iter][1], data[current_iter][2], data[current_iter][3]\n",
    "\n",
    "    accuracy_svm, balanced_accuracy_svm, classical_f1_score = find_classical_accuracy_rf(X_train, X_test, y_train, y_test)\n",
    "    svc_acc_rf.append(accuracy_svm)\n",
    "    svc_bacc_rf.append(balanced_accuracy_svm)\n",
    "    svc_f1_score_rf.append(classical_f1_score)\n",
    "\n",
    "    print(f\"Accuracy, Balanced Accuracy and F1 Score Classical SVM: {accuracy_svm}, {balanced_accuracy_svm}, {classical_f1_score}\")\n",
    "\n",
    "    print(f\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIzQLAG9w0u7",
    "outputId": "1c532a76-707f-40f7-c9b2-1dd8a58fbf4e"
   },
   "outputs": [],
   "source": [
    "print(svc_acc_rf)\n",
    "print(\"For Classical SVM:\")\n",
    "print(\"Mean Accuracy:       \", np.array(svc_acc_rf).mean())\n",
    "print(\"Standard deviation:  \", np.array(svc_acc_rf).std())\n",
    "print(\"Minimum Accuracy:    \", np.array(svc_acc_rf).min())\n",
    "print(\"Maximum Accuracy:    \", np.array(svc_acc_rf).max())\n",
    "svc_avg = np.array(svc_acc_rf).mean()\n",
    "svc_min = np.array(svc_acc_rf).min()\n",
    "svc_max = np.array(svc_acc_rf).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "euxLUiuEw6pd",
    "outputId": "4b595422-a9de-44fb-e133-660de91d8f08"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_acc_rf))\n",
    "plt.title('Accuracy Distribution for Classical Random Forest')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRsn399ZxANx",
    "outputId": "3100bfce-6a9a-431b-9de4-d0663aadf5eb"
   },
   "outputs": [],
   "source": [
    "print(svc_bacc_rf)\n",
    "print(\"For Classical Random Forest:\")\n",
    "print(\"Mean Balanced Accuracy:       \", np.array(svc_bacc_rf).mean())\n",
    "print(\"Standard deviation:  \", np.array(svc_bacc_rf).std())\n",
    "print(\"Minimum Balanced Accuracy:    \", np.array(svc_bacc_rf).min())\n",
    "print(\"Maximum Balanced Accuracy:    \", np.array(svc_bacc_rf).max())\n",
    "svc_avg = np.array(svc_bacc_rf).mean()\n",
    "svc_min = np.array(svc_bacc_rf).min()\n",
    "svc_max = np.array(svc_bacc_rf).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Yh6SB2eXxEJb",
    "outputId": "a04fd032-df28-4824-ba5f-e9042639a0f1"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(svc_bacc_rf))\n",
    "plt.title('Balanced Accuracy Distribution for Random Forest')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZym3oPwxKO1"
   },
   "outputs": [],
   "source": [
    "def find_closest_to_mean(arr):\n",
    "    mean = sum(arr) / len(arr)  # Calculate mean of the list\n",
    "\n",
    "    # Calculate the differences between each element and the mean, and store them in a tuple with their index\n",
    "    diff_indices = [(abs(x - mean), i) for i, x in enumerate(arr)]\n",
    "\n",
    "    # Sort the tuple by the difference values\n",
    "    sorted_diff_indices = sorted(diff_indices)\n",
    "\n",
    "    # Extract the indices of the two closest values\n",
    "    index1 = sorted_diff_indices[0][1]\n",
    "    index2 = sorted_diff_indices[1][1]\n",
    "    return [index1, index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZVIthWhxPk7"
   },
   "outputs": [],
   "source": [
    "def find_closest_to_max(arr):\n",
    "    max_val = max(arr)  # Calculate max of the list\n",
    "\n",
    "    # Calculate the differences between each element and the max, and store them in a tuple with their index\n",
    "    diff_indices = [(abs(x - max_val), i) for i, x in enumerate(arr)]\n",
    "\n",
    "    # Sort the tuple by the difference values\n",
    "    sorted_diff_indices = sorted(diff_indices)\n",
    "\n",
    "    # Extract the indices of the two closest values\n",
    "    index1 = sorted_diff_indices[0][1]\n",
    "    index2 = sorted_diff_indices[1][1]\n",
    "    return [index1, index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LU3b0YK4xSxR"
   },
   "outputs": [],
   "source": [
    "def find_closest_to_min(arr):\n",
    "    min_val = min(arr)  # Calculate min of the list\n",
    "\n",
    "    # Calculate the differences between each element and the min, and store them in a tuple with their index\n",
    "    diff_indices = [(abs(x - min_val), i) for i, x in enumerate(arr)]\n",
    "\n",
    "    # Sort the tuple by the difference values\n",
    "    sorted_diff_indices = sorted(diff_indices)\n",
    "\n",
    "    # Extract the indices of the two closest values\n",
    "    index1 = sorted_diff_indices[0][1]\n",
    "    index2 = sorted_diff_indices[1][1]\n",
    "    return [index1, index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ymk8wIsxXWS"
   },
   "outputs": [],
   "source": [
    "fm_list = []\n",
    "names_fm = []\n",
    "def create_feature_maps(features_):\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Z'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Z')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['ZZ'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('ZZ')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['YY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('YY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Z', 'ZZ'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Z ZZ')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Y', 'YY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Y YY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['X', 'YY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('X YY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Z', 'YY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Z YY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Y', 'XY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Y XY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['X', 'XY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('X XY')\n",
    "    feature_map = PauliFeatureMap(features_, reps=2, paulis=['Z', 'XY'], entanglement=\"linear\")\n",
    "    fm_list.append(feature_map)\n",
    "    names_fm.append('Z XY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4ddIA3xxZ9a"
   },
   "outputs": [],
   "source": [
    "create_feature_maps(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Beq3niIQxfJy"
   },
   "outputs": [],
   "source": [
    "def train_and_fit_model(x_train_, x_test_, y_train_, y_test_, fm_):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Building Kernel\n",
    "    dse_feature_map = fm_\n",
    "\n",
    "    dse_backend = QuantumInstance(\n",
    "        Aer.get_backend('qasm_simulator'), shots=1024, seed_simulator=12345, seed_transpiler=12345\n",
    "    )\n",
    "\n",
    "    dse_kernel = QuantumKernel(feature_map=dse_feature_map, quantum_instance=dse_backend)\n",
    "    qsvc = QSVC(quantum_kernel=dse_kernel)\n",
    "    qsvc.fit(x_train_, y_train_)\n",
    "\n",
    "    # Predict the labels\n",
    "    labels_test = qsvc.predict(x_test_)\n",
    "\n",
    "    accuracy_test = metrics.accuracy_score(y_true=y_test_, y_pred=labels_test)\n",
    "    ba_score = metrics.balanced_accuracy_score(y_true=y_test_, y_pred=labels_test)\n",
    "    q_f1_score = f1_score(y_test_, labels_test)\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    return accuracy_test, ba_score, q_f1_score, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_f5xjvOx0tb",
    "outputId": "712c98f8-5e7b-4327-eb00-4714df9aaf74"
   },
   "outputs": [],
   "source": [
    "! pip install qiskit-aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.utils import QuantumInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"For Mean Performance: \")\n",
    "indices_mean = find_closest_to_mean(svc_bacc)\n",
    "print(indices_mean)\n",
    "\n",
    "q_ba, q_a, q_f1 = [], [], []\n",
    "svc_ba, svc_a, svc_f1 = [], [], []\n",
    "dt_ba, dt_a, dt_f1 = [], [], []\n",
    "rf_ba, rf_a, rf_f1 = [], [], []\n",
    "\n",
    "for fm in fm_list:\n",
    "    qba, qa, qf = [], [], []\n",
    "    for idx in indices_mean:\n",
    "        X_train, X_test, y_train, y_test = data[idx]\n",
    "        acc, bacc, f1, elapsed = train_and_fit_model(X_train, X_test, y_train, y_test, fm)\n",
    "        print(f\"Accuracy, Balanced Accuracy, F1 Score, Elapsed Time: {acc}, {bacc}, {f1}, {elapsed}\")\n",
    "        qba.append(bacc)\n",
    "        qa.append(acc)\n",
    "        qf.append(f1)\n",
    "    q_ba.append(qba)\n",
    "    q_a.append(qa)\n",
    "    q_f1.append(qf)\n",
    "    svc_ba.append(svc_bacc[idx])\n",
    "    svc_a.append(svc_acc[idx])\n",
    "    svc_f1.append(svc_f1_score[idx])\n",
    "    dt_ba.append(svc_bacc_dt[idx])\n",
    "    dt_a.append(svc_acc_dt[idx])\n",
    "    dt_f1.append(svc_f1_score_dt[idx])\n",
    "    rf_ba.append(svc_bacc_rf[idx])\n",
    "    rf_a.append(svc_acc_rf[idx])\n",
    "    rf_f1.append(svc_f1_score_rf[idx])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Averge Balanced Accuracy for SVM: {sum(svc_ba)/len(svc_ba)}\")\n",
    "print(f\"Average Accuracy for SVM: {sum(svc_a)/len(svc_a)}\")\n",
    "print(f\"Average F1 Score for SVM: {sum(svc_f1)/len(svc_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Decision Tree: {sum(dt_ba)/len(dt_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Decision Tree: {sum(dt_a)/len(dt_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Decision Tree: {sum(dt_f1)/len(dt_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Random Forest: {sum(rf_ba)/len(rf_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Random Forest: {sum(rf_a)/len(rf_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Random Forest: {sum(rf_f1)/len(rf_f1)}\")\n",
    "print(\"\\n\");\n",
    "for i in range(len(fm_list)):\n",
    "    print(f\"Averge Balanced Accuracy for Pauli {names_fm[i]}: {sum(q_ba[i])/len(q_ba[i])}\")\n",
    "    print(f\"Average Accuracy for Pauli {names_fm[i]}: {sum(q_a[i])/len(q_a[i])}\")\n",
    "    print(f\"Average F1 Score for Pauli {names_fm[i]}: {sum(q_f1[i])/len(q_f1[i])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Oishik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "atCc8cIkypnU",
    "outputId": "378364da-3f0b-4075-f229-3b3c7fd4b1f2"
   },
   "outputs": [],
   "source": [
    "print(\"For Min Performance \")\n",
    "indices_min = find_closest_to_min(svc_bacc)\n",
    "print(indices_min)\n",
    "\n",
    "q_ba, q_a, q_f1 = [], [], []\n",
    "svc_ba, svc_a, svc_f1 = [], [], []\n",
    "dt_ba, dt_a, dt_f1 = [], [], []\n",
    "rf_ba, rf_a, rf_f1 = [], [], []\n",
    "\n",
    "for fm in fm_list:\n",
    "    qba, qa, qf = [], [], []\n",
    "    for idx in indices_min:\n",
    "        X_train, X_test, y_train, y_test = data[idx]\n",
    "        acc, bacc, f1, elapsed = train_and_fit_model(X_train, X_test, y_train, y_test, fm)\n",
    "        print(f\"Accuracy, Balanced Accuracy, F1 Score, Elapsed Time: {acc}, {bacc}, {f1}, {elapsed}\")\n",
    "        qba.append(bacc)\n",
    "        qa.append(acc)\n",
    "        qf.append(f1)\n",
    "    q_ba.append(qba)\n",
    "    q_a.append(qa)\n",
    "    q_f1.append(qf)\n",
    "    svc_ba.append(svc_bacc[idx])\n",
    "    svc_a.append(svc_acc[idx])\n",
    "    svc_f1.append(svc_f1_score[idx])\n",
    "    dt_ba.append(svc_bacc_dt[idx])\n",
    "    dt_a.append(svc_acc_dt[idx])\n",
    "    dt_f1.append(svc_f1_score_dt[idx])\n",
    "    rf_ba.append(svc_bacc_rf[idx])\n",
    "    rf_a.append(svc_acc_rf[idx])\n",
    "    rf_f1.append(svc_f1_score_rf[idx])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Averge Balanced Accuracy for SVM: {sum(svc_ba)/len(svc_ba)}\")\n",
    "print(f\"Average Accuracy for SVM: {sum(svc_a)/len(svc_a)}\")\n",
    "print(f\"Average F1 Score for SVM: {sum(svc_f1)/len(svc_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Decision Tree: {sum(dt_ba)/len(dt_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Decision Tree: {sum(dt_a)/len(dt_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Decision Tree: {sum(dt_f1)/len(dt_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Random Forest: {sum(rf_ba)/len(rf_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Random Forest: {sum(rf_a)/len(rf_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Random Forest: {sum(rf_f1)/len(rf_f1)}\")\n",
    "print(\"\\n\");\n",
    "for i in range(len(fm_list)):\n",
    "    print(f\"Averge Balanced Accuracy for Pauli {names_fm[i]}: {sum(q_ba[i])/len(q_ba[i])}\")\n",
    "    print(f\"Average Accuracy for Pauli {names_fm[i]}: {sum(q_a[i])/len(q_a[i])}\")\n",
    "    print(f\"Average F1 Score for Pauli {names_fm[i]}: {sum(q_f1[i])/len(q_f1[i])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"For Max Performance \")\n",
    "indices_max = find_closest_to_max(svc_bacc)\n",
    "print(indices_max)\n",
    "\n",
    "q_ba, q_a, q_f1 = [], [], []\n",
    "svc_ba, svc_a, svc_f1 = [], [], []\n",
    "dt_ba, dt_a, dt_f1 = [], [], []\n",
    "rf_ba, rf_a, rf_f1 = [], [], []\n",
    "\n",
    "for fm in fm_list:\n",
    "    qba, qa, qf = [], [], []\n",
    "    for idx in indices_max:\n",
    "        X_train, X_test, y_train, y_test = data[idx]\n",
    "        acc, bacc, f1, elapsed = train_and_fit_model(X_train, X_test, y_train, y_test, fm)\n",
    "        print(f\"Accuracy, Balanced Accuracy, F1 Score, Elapsed Time: {acc}, {bacc}, {f1}, {elapsed}\")\n",
    "        qba.append(bacc)\n",
    "        qa.append(acc)\n",
    "        qf.append(f1)\n",
    "    q_ba.append(qba)\n",
    "    q_a.append(qa)\n",
    "    q_f1.append(qf)\n",
    "    svc_ba.append(svc_bacc[idx])\n",
    "    svc_a.append(svc_acc[idx])\n",
    "    svc_f1.append(svc_f1_score[idx])\n",
    "    dt_ba.append(svc_bacc_dt[idx])\n",
    "    dt_a.append(svc_acc_dt[idx])\n",
    "    dt_f1.append(svc_f1_score_dt[idx])\n",
    "    rf_ba.append(svc_bacc_rf[idx])\n",
    "    rf_a.append(svc_acc_rf[idx])\n",
    "    rf_f1.append(svc_f1_score_rf[idx])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Averge Balanced Accuracy for SVM: {sum(svc_ba)/len(svc_ba)}\")\n",
    "print(f\"Average Accuracy for SVM: {sum(svc_a)/len(svc_a)}\")\n",
    "print(f\"Average F1 Score for SVM: {sum(svc_f1)/len(svc_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Decision Tree: {sum(dt_ba)/len(dt_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Decision Tree: {sum(dt_a)/len(dt_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Decision Tree: {sum(dt_f1)/len(dt_f1)}\")\n",
    "print(\"\\n\");\n",
    "print(f\"Averge Balanced Accuracy for Random Forest: {sum(rf_ba)/len(rf_ba)}\")\n",
    "print(f\"Average Accuracy for Pauli Random Forest: {sum(rf_a)/len(rf_a)}\")\n",
    "print(f\"Average F1 Score for Pauli Random Forest: {sum(rf_f1)/len(rf_f1)}\")\n",
    "print(\"\\n\");\n",
    "for i in range(len(fm_list)):\n",
    "    print(f\"Averge Balanced Accuracy for Pauli {names_fm[i]}: {sum(q_ba[i])/len(q_ba[i])}\")\n",
    "    print(f\"Average Accuracy for Pauli {names_fm[i]}: {sum(q_a[i])/len(q_a[i])}\")\n",
    "    print(f\"Average F1 Score for Pauli {names_fm[i]}: {sum(q_f1[i])/len(q_f1[i])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Z2XH9yGzcbz"
   },
   "outputs": [],
   "source": [
    "from qiskit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "rsoN8dmLzwzh",
    "outputId": "ee383020-cca0-496f-c2be-c37dd17cfe6e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provider = IBMQ.get_provider(hub='ibm-q', group='open', project='main')\n",
    "provider.backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Using 3 features Price, Open, High: \")\n",
    "sz = []\n",
    "svm_acc = []\n",
    "qsvm_acc = []\n",
    "for data_size in range(20, 80, 10):\n",
    "    print(\"for size\", data_size)\n",
    "    sz.append(data_size)\n",
    "    x = df.iloc[:data_size, 0:-1]\n",
    "    y = df.iloc[:data_size, -1]\n",
    "    # spltting the dataset into train and test set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 31)\n",
    "    from sklearn import svm\n",
    "    svc_clf = svm.SVC(random_state = 7)\n",
    "    svc_clf.fit(x_train, y_train)\n",
    "    svc_score = svc_clf.score(x_test, y_test)\n",
    "    print(f\"svm classification score: {svc_score}\")\n",
    "    svm_acc.append(svc_score)\n",
    "    import qiskit\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.cluster import SpectralClustering\n",
    "    from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "    from qiskit import BasicAer\n",
    "    from qiskit.circuit.library import ZZFeatureMap\n",
    "    from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "    from qiskit_machine_learning.algorithms import QSVC\n",
    "    from qiskit_machine_learning.kernels import QuantumKernel\n",
    "    from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "\n",
    "    seed = 12345\n",
    "    algorithm_globals.random_seed = seed\n",
    "    # Building Kernel\n",
    "    dse_feature_map = ZZFeatureMap(feature_dimension=4, reps=2, entanglement=\"linear\")\n",
    "\n",
    "    dse_backend = QuantumInstance(\n",
    "        BasicAer.get_backend('qasm_simulator'), shots=1024, seed_simulator=seed, seed_transpiler=seed\n",
    "    )\n",
    "\n",
    "    dse_kernel = QuantumKernel(feature_map=dse_feature_map, quantum_instance=dse_backend)\n",
    "    dse_svc = SVC(kernel=dse_kernel.evaluate)\n",
    "    dse_svc.fit(x_train, y_train)\n",
    "    dse_score = dse_svc.score(x_test, y_test)\n",
    "\n",
    "    print(f\"qsvm classification test score: {dse_score}\")\n",
    "    qsvm_acc.append(dse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "total = 50\n",
    "for cnt in range(total):\n",
    "    for idx in range(len(sz)):\n",
    "        data_size = sz[idx]\n",
    "        print(\"for size\", data_size)\n",
    "        st = random.randint(0, 200-data_size)\n",
    "        x = df.iloc[st:st+data_size, 0:-1]\n",
    "        y = df.iloc[st:st+data_size, -1]\n",
    "        # spltting the dataset into train and test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 31)\n",
    "        from sklearn import svm\n",
    "        svc_clf = svm.SVC(random_state = 7)\n",
    "        svc_clf.fit(x_train, y_train)\n",
    "        svc_score = svc_clf.score(x_test, y_test)\n",
    "        print(f\"svm classification score: {svc_score}\")\n",
    "        svm_acc[idx] = svm_acc[idx] + svc_score\n",
    "        import qiskit\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "\n",
    "        from sklearn.svm import SVC\n",
    "        from sklearn.cluster import SpectralClustering\n",
    "        from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "        from qiskit import BasicAer\n",
    "        from qiskit.circuit.library import ZZFeatureMap\n",
    "        from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "        from qiskit_machine_learning.algorithms import QSVC\n",
    "        from qiskit_machine_learning.kernels import QuantumKernel\n",
    "        from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "\n",
    "        seed = 12345\n",
    "        algorithm_globals.random_seed = seed\n",
    "        # Building Kernel\n",
    "        dse_feature_map = ZZFeatureMap(feature_dimension=4, reps=2, entanglement=\"linear\")\n",
    "\n",
    "        dse_backend = QuantumInstance(\n",
    "            BasicAer.get_backend('qasm_simulator'), shots=1024, seed_simulator=seed, seed_transpiler=seed\n",
    "        )\n",
    "\n",
    "        dse_kernel = QuantumKernel(feature_map=dse_feature_map, quantum_instance=dse_backend)\n",
    "        dse_svc = SVC(kernel=dse_kernel.evaluate)\n",
    "        dse_svc.fit(x_train, y_train)\n",
    "        dse_score = dse_svc.score(x_test, y_test)\n",
    "\n",
    "        print(f\"qsvm classification test score: {dse_score}\")\n",
    "        qsvm_acc[idx] = qsvm_acc[idx] + dse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(svm_acc)\n",
    "print(qsvm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(svm_acc)\n",
    "print(qsvm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx in range(len(sz)):\n",
    "    print(idx, svm_acc[idx]/32, '\\t\\t', qsvm_acc[idx]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sz = [20, 30, 40, 50, 60]\n",
    "svm_acc = [0.5, 0.8333333333333334, 0.75, 0.7, 0.5]\n",
    "qsvm_acc = [.25, .5, .25, .6, 0.4166666666666667]\n",
    "import random\n",
    "total = 32\n",
    "for cnt in range(total):\n",
    "    print(\"current iteration: \", cnt)\n",
    "    for idx in range(len(sz)):\n",
    "        data_size = sz[idx]\n",
    "        print(\"for size\", data_size)\n",
    "        st = random.randint(0, 200-data_size)\n",
    "        x = df.iloc[st:st+data_size, 0:-1]\n",
    "        y = df.iloc[st:st+data_size, -1]\n",
    "        # spltting the dataset into train and test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 31)\n",
    "        from sklearn import svm\n",
    "        svc_clf = svm.SVC(random_state = 7)\n",
    "        svc_clf.fit(x_train, y_train)\n",
    "        svc_score = svc_clf.score(x_test, y_test)\n",
    "        print(f\"svm classification score: {svc_score}\")\n",
    "        svm_acc[idx] = svm_acc[idx] + svc_score\n",
    "        import qiskit\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "\n",
    "        from sklearn.svm import SVC\n",
    "        from sklearn.cluster import SpectralClustering\n",
    "        from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "        from qiskit import BasicAer\n",
    "        from qiskit.circuit.library import ZZFeatureMap\n",
    "        from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "        from qiskit_machine_learning.algorithms import QSVC\n",
    "        from qiskit_machine_learning.kernels import QuantumKernel\n",
    "        from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "\n",
    "        seed = 12345\n",
    "        algorithm_globals.random_seed = seed\n",
    "        # Building Kernel\n",
    "        dse_feature_map = ZZFeatureMap(feature_dimension=4, reps=2, entanglement=\"linear\")\n",
    "\n",
    "        dse_backend = QuantumInstance(\n",
    "            BasicAer.get_backend('qasm_simulator'), shots=1024, seed_simulator=seed, seed_transpiler=seed\n",
    "        )\n",
    "\n",
    "        dse_kernel = QuantumKernel(feature_map=dse_feature_map, quantum_instance=dse_backend)\n",
    "        dse_svc = SVC(kernel=dse_kernel.evaluate)\n",
    "        dse_svc.fit(x_train, y_train)\n",
    "        dse_score = dse_svc.score(x_test, y_test)\n",
    "\n",
    "        print(f\"qsvm classification test score: {dse_score}\")\n",
    "        qsvm_acc[idx] = qsvm_acc[idx] + dse_score\n",
    "    print(\"=============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(svm_acc, qsvm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx in range(len(sz)):\n",
    "    print(idx, svm_acc[idx]/32, '\\t\\t', qsvm_acc[idx]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Qiskit v1.0.1 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
